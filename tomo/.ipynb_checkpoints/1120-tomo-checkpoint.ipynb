{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow import set_random_seed\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.wrappers.scikit_learn import KerasClassifier,KerasRegressor\n",
    "from sklearn.grid_search import GridSearchCV \n",
    "from keras import regularizers\n",
    "import pydot\n",
    "import graphviz\n",
    "from IPython.display import SVG\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.读取-划分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def importdata():\n",
    "    path = r\"C:\\Users\\hasee\\workspace\\workspace\\tomo\\data2.txt\"\n",
    "    df = pd.read_table(path)\n",
    "    columns = df.columns\n",
    "    #print(columns)\n",
    "\n",
    "    dfdata = df[['latgpsutm', 'lnggpsutm', 'lnglacutm', 'latlacutm']]\n",
    "    #print(len(dfdata))\n",
    "    dfdata = dfdata.drop_duplicates()#删去重复项\n",
    "    #print(len(dfdata))\n",
    "    return dfdata\n",
    "\n",
    "df = importdata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机70%训练集切分-方法1："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = shuffle(df)\n",
    "df1 = df.set_index([list(range(len(df1)))])\n",
    "index = int(len(df1)*0.7)\n",
    "df1_train=df1[:index]\n",
    "df1_test=df1[index:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机70%训练集切分-方法2："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train=df.sample(frac=0.7)\n",
    "df_train=df_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['latgpsutm', 'lnggpsutm', 'lnglacutm', 'latlacutm']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=df_train[['lnglacutm', 'latlacutm']].as_matrix()\n",
    "y_train=df_train[['latgpsutm', 'lnggpsutm']].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  353272.057 ,  3451367.8369],\n",
       "       [  357161.5617,  3462181.514 ],\n",
       "       [  352815.7743,  3456243.1191],\n",
       "       ..., \n",
       "       [  356961.2242,  3462713.0734],\n",
       "       [  351431.9022,  3452487.3429],\n",
       "       [  353368.9606,  3451370.178 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "def NN_model(optimizer='adam',hidden_units=100,dropout_rate=0.3,L2_rate=.001):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(hidden_units,activation='relu',input_dim=2,kernel_regularizer=regularizers.l2(L2_rate)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(2,activation='relu',kernel_regularizer=regularizers.l2(L2_rate)))\n",
    "    \n",
    "    model.compile(loss='mean_squared_error',optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold=StratifiedKFold(n_splits=5,random_state=42)\n",
    "#nn_reg=KerasRegressor(build_fn=NN_model,nb_epoch=40,batch_size=50,verbose=-1)\n",
    "#nn_reg.fit(X_train,y_train)\n",
    "nn_model=NN_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 893 samples, validate on 224 samples\n",
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "nn_model.fit(X_train,y_train,epochs=30,validation_split=0.2,batch_size=50,verbose=-1)#callbacks='early_stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X=df1_test[['lnglacutm', 'latlacutm']].iloc[0:2].as_matrix()\n",
    "test_y=df1_test[['latgpsutm', 'lnggpsutm']].iloc[0:2].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_reg.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
