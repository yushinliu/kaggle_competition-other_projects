{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning:\n",
      "\n",
      "This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#all packages which will be used\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import time\n",
    "import random\n",
    "\n",
    "#plot\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from matplotlib.axes import Axes\n",
    "\n",
    "#sklearn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "#from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.svm import LinearSVC\n",
    "#to plot more than 2 dimensions \n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "#scipy\n",
    "from scipy.stats import chisquare\n",
    "from scipy.stats import chi2\n",
    "from scipy.spatial import distance\n",
    "\n",
    "#good performance classifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "#math\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set=pd.read_csv(\"C:\\\\Users\\\\hasee\\\\workspace\\\\lab\\\\patRecDat\\\\forStudents\\\\medData\\\\train_set.csv\")\n",
    "X_val=pd.read_csv(\"C:\\\\Users\\\\hasee\\\\workspace\\\\lab\\\\patRecDat\\\\forStudents\\\\medData\\\\val_feature.csv\")\n",
    "y_val=pd.read_csv(\"C:\\\\Users\\\\hasee\\\\workspace\\\\lab\\\\patRecDat\\\\forStudents\\\\medData\\\\val_label.csv\")\n",
    "X_train=train_set.drop([\"label\"],axis=1)\n",
    "y_train=train_set[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Nearest Mean algorithm\n",
    "def nn_predict(X_val,X_train,y_train):\n",
    "    y_pred=[]\n",
    "    y_proba_1=[]\n",
    "    y_proba_2=[]\n",
    "    class_1=X_train[y_train==1]\n",
    "    class_2=X_train[y_train==2]\n",
    "    mean_1=np.array(class_1.mean()).reshape(1,-1)\n",
    "    mean_2=np.array(class_2.mean()).reshape(1,-1)\n",
    "    cov_1=np.matrix(class_1.cov())\n",
    "    cov_2=np.matrix(class_2.cov())\n",
    "    print(\"KNN start\")\n",
    "    start=time.time()\n",
    "    dis_1=distance.cdist(X_val,mean_1,metric='mahalanobis',V=cov_1).ravel()\n",
    "    dis_2=distance.cdist(X_val,mean_2,metric='mahalanobis',V=cov_2).ravel()\n",
    "# get the k nearest mahalanobis distance\n",
    "    for index in range(len(X_val)):\n",
    "        if index%1000==0:\n",
    "            print(\"the index is %d and time is %5.1f second\"%(index,(time.time()-start)))\n",
    "        if dis_1[index]<dis_2[index]:\n",
    "                y_pred.append(np.float64(1.0)) #added the weight to the vote\n",
    "        else:\n",
    "                y_pred.append(np.float64(2.0))\n",
    "        y_proba_1.append(dis_2[index]/(dis_1[index]+dis_2[index]))\n",
    "        y_proba_2.append(dis_1[index]/(dis_1[index]+dis_2[index]))\n",
    "    print(\"KNN STOP\")\n",
    "    y_pred=pd.Series(y_pred)\n",
    "    return y_pred,y_proba_1,y_proba_2\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn_predict(X_val,X_train,y_train,k_value,weight):\n",
    "    assert weight in ['uniform','distance']\n",
    "    if weight == 'distance':\n",
    "        y_pred=[]\n",
    "        y_proba_1=[]\n",
    "        y_proba_2=[]\n",
    "        cov_train=np.matrix(X_train.cov())\n",
    "        print(\"KNN start\")\n",
    "        start=time.time()\n",
    "        for test_index in range(len(X_val)):\n",
    "            if test_index%100==0:\n",
    "                print(\"the X_val is %d and time is %5.1f minute\"%(test_index,(time.time()-start)/60))\n",
    "            good=0\n",
    "            bad=0\n",
    "            sample=np.array(X_val.iloc[test_index]).reshape(1,-1)\n",
    "            m_dis=pd.Series((distance.cdist(X_train,sample,metric='mahalanobis',V=cov_train)).ravel())\\\n",
    "            .sort_values(ascending=True)#average computing time 0.12s\n",
    "            dis_set=m_dis[:k_value]# get the k nearest mahalanobis distance\n",
    "            for index in dis_set.index:\n",
    "                if y_train.loc[index] == 1.0:\n",
    "                    good += 1/dis_set.loc[index] #added the weight to the vote\n",
    "                else:\n",
    "                    bad += 1/dis_set.loc[index]\n",
    "            if good > bad :\n",
    "                y_pred.append(np.float64(1.0))\n",
    "            else:\n",
    "                y_pred.append(np.float64(2.0))\n",
    "            y_proba_1.append(good/(good+bad))\n",
    "            y_proba_2.append(bad/(good+bad))\n",
    "        print(\"KNN STOP\")\n",
    "        y_pred=pd.Series(y_pred)\n",
    "    if weight == 'distance':\n",
    "        y_pred=[]\n",
    "        y_proba_1=[]\n",
    "        y_proba_2=[]\n",
    "        cov_train=np.matrix(X_train.cov())\n",
    "        print(\"KNN start\")\n",
    "        start=time.time()\n",
    "        for test_index in range(len(X_val)):\n",
    "            if test_index%100==0:\n",
    "                print(\"the X_val is %d and time is %5.1f minute\"%(test_index,(time.time()-start)/60))\n",
    "            good=0\n",
    "            bad=0\n",
    "            sample=np.array(X_val.iloc[test_index]).reshape(1,-1)\n",
    "            m_dis=pd.Series((distance.cdist(X_train,sample,metric='mahalanobis',V=cov_train)).ravel())\\\n",
    "            .sort_values(ascending=True)#average computing time 0.12s\n",
    "            dis_set=m_dis[:k_value]# get the k nearest mahalanobis distance\n",
    "            for index in dis_set.index:\n",
    "                if y_train.loc[index] == 1.0:\n",
    "                    good += 1 #without weight\n",
    "                else:\n",
    "                    bad += 1\n",
    "            if good > bad :\n",
    "                y_pred.append(np.float64(1.0))\n",
    "            else:\n",
    "                y_pred.append(np.float64(2.0))\n",
    "            y_proba_1.append(good/(good+bad))\n",
    "            y_proba_2.append(bad/(good+bad))\n",
    "        print(\"KNN STOP\")\n",
    "        y_pred=pd.Series(y_pred)\n",
    "    return y_pred,y_proba_1,y_proba_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODE= 'SVM'  # random forest: 'RF', SVM: 'SVM', Nearest Neighbors: 'NN' , k nearest neighbours:'KNN', XGB: 'XGB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now the svm model C value is 1\n",
      "now the svm model C value is 1 has the score 0.975893182075\n",
      "now the svm model C value is 1is the best\n",
      "now the svm model C value is 10\n",
      "now the svm model C value is 10 has the score 0.975815208863\n",
      "now the svm model C value is 100\n",
      "now the svm model C value is 100 has the score 0.975846680562\n",
      "now the svm model C value is 1000\n",
      "now the svm model C value is 1000 has the score 0.952612408337\n"
     ]
    }
   ],
   "source": [
    "BEST_SCORE=0\n",
    "assert MODE in ['SVM', 'RF','XGB','KNN']\n",
    "if MODE == 'KNN':\n",
    "    for weight in ['distance','uniform']:\n",
    "        for k_value in [3,4,5,6,7]:\n",
    "            print(\"now the knn model is \"+weight+\" and the k_value is \"+str(k_value))\n",
    "            y_pred_knn,y_proba_1_knn,y_proba_2_knn=knn_predict(X_val,X_train,y_train,k_value,weight=weight)\n",
    "            y_score=f1_score(y_val,y_pred)\n",
    "            print(\"the knn model is \"+weight+\" and the k_value is \"+str(k_value)+\" has the score \"+str(y_score))\n",
    "            if y_score > BEST_SCORE:\n",
    "                BEST_SCORE = y_score\n",
    "                print(\"knn model \"+weight+\" and k_value \"+str(k_value)+\"is the best\")\n",
    "if MODE == 'SVM' :\n",
    "    for C in [1,10,100,1000]:\n",
    "        print(\"now the svm model C value is \"+str(C))\n",
    "        svm_clf=LinearSVC(loss='hinge',dual=True,C=C,random_state=42)\n",
    "        #parameter 'dual' , due to the http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n",
    "        # dual = False better if n_samples>n_features\n",
    "        svm_clf.fit(X_train,y_train)\n",
    "        y_pred=svm_clf.predict(X_val)\n",
    "        y_score=f1_score(y_val,y_pred)\n",
    "        print(\"now the svm model C value is \"+str(C)+\" has the score \"+str(y_score))\n",
    "        if y_score > BEST_SCORE:\n",
    "            BEST_SCORE = y_score\n",
    "            print(\"now the svm model C value is \"+str(C)+\" is the best\")\n",
    "            \n",
    "        \n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
