{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x=tf.Variable(3,'x')\n",
    "y=tf.Variable(4,'y')\n",
    "f=x*x*y+y+2\n",
    "sess=tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result=sess.run(f)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or alternative , we can use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result=f.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and actually you can create a init node to initialize all the varivables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()  # initialize all the variables\n",
    "    result=f.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession() #it's a default session\n",
    "init.run()\n",
    "result=f.eval()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1=tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph=tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2=tf.Variable(2)\n",
    "\n",
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and more multiple sessions do not share variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w=tf.constant(3)\n",
    "x=w + 2\n",
    "y=x + 5\n",
    "z=x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, z_val= sess.run([y,z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearRegression with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "m,n=housing[\"data\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "housing_data_bias=np.c_[np.ones((m,1)),housing[\"data\"]]\n",
    "X=tf.constant(housing_data_bias,dtype=tf.float32,name=\"X\")\n",
    "y=tf.constant(housing[\"target\"].reshape(-1,1),dtype=tf.float32,name=\"y\")\n",
    "XT=tf.transpose(X)\n",
    "theta=tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)),XT),y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value=theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.74651413e+01],\n",
       "       [  4.35734153e-01],\n",
       "       [  9.33829229e-03],\n",
       "       [ -1.06622010e-01],\n",
       "       [  6.44106984e-01],\n",
       "       [ -4.25131839e-06],\n",
       "       [ -3.77322501e-03],\n",
       "       [ -4.26648885e-01],\n",
       "       [ -4.40514028e-01]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent need data to be normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 mse= 2.75443\n",
      "Epoch 100 mse= 0.632222\n",
      "Epoch 200 mse= 0.57278\n",
      "Epoch 300 mse= 0.558501\n",
      "Epoch 400 mse= 0.54907\n",
      "Epoch 500 mse= 0.542288\n",
      "Epoch 600 mse= 0.537379\n",
      "Epoch 700 mse= 0.533822\n",
      "Epoch 800 mse= 0.531243\n",
      "Epoch 900 mse= 0.529371\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "#initialize\n",
    "X=tf.constant(scaled_housing_data_plus_bias,dtype=tf.float32,name=\"X\")\n",
    "y=tf.constant(housing[\"target\"].reshape(-1,1),dtype=tf.float32,name=\"y\")\n",
    "theta=tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0,seed=42),name=\"theta\")\n",
    "y_pred=tf.matmul(X,theta,name=\"prediction\")\n",
    "error=y_pred-y\n",
    "mse=tf.reduce_mean(tf.square(error),name=\"mse\")\n",
    "gradients=(2/m)*tf.matmul(tf.transpose(X),error)\n",
    "training_op=tf.assign(theta,theta-learning_rate*gradients)\n",
    "#set up initializer\n",
    "init=tf.global_variables_initializer()\n",
    "#run the tensorflow\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch%100==0:\n",
    "            print(\"Epoch\",epoch,\"mse=\",mse.eval())\n",
    "        sess.run(training_op)\n",
    "        \n",
    "    best_theta=theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.06855226e+00],\n",
       "       [  7.74078071e-01],\n",
       "       [  1.31192401e-01],\n",
       "       [ -1.17845066e-01],\n",
       "       [  1.64778143e-01],\n",
       "       [  7.44081335e-04],\n",
       "       [ -3.91945131e-02],\n",
       "       [ -8.61356676e-01],\n",
       "       [ -8.23479772e-01]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we can use autodiff to make the code sufficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Mse= 2.75443\n",
      "Epoch 100 Mse= 0.527928\n",
      "Epoch 200 Mse= 0.524498\n",
      "Epoch 300 Mse= 0.524334\n",
      "Epoch 400 Mse= 0.524323\n",
      "Epoch 500 Mse= 0.524321\n",
      "Epoch 600 Mse= 0.524321\n",
      "Epoch 700 Mse= 0.524321\n",
      "Epoch 800 Mse= 0.524321\n",
      "Epoch 900 Mse= 0.524321\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.1\n",
    "#initialize\n",
    "X=tf.constant(scaled_housing_data_plus_bias,dtype=tf.float32,name=\"X\")\n",
    "y=tf.constant(housing[\"target\"].reshape(-1,1),dtype=tf.float32,name=\"y\")\n",
    "theta=tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0,seed=42),name=\"theta\")\n",
    "y_pred=tf.matmul(X,theta,name=\"prediction\")\n",
    "error=y_pred-y\n",
    "mse=tf.reduce_mean(tf.square(error),name=\"mse\")\n",
    "gradients=tf.gradients(mse,[theta])[0] #gradient's shape is (9,1)\n",
    "training_op=tf.assign(theta,theta-learning_rate*gradients)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch%100==0 :\n",
    "            print(\"Epoch\",epoch,\"Mse=\",mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta=theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How could you find the partial derivatives of the following function with regards to a and b?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_func(a, b):\n",
    "    z = 0\n",
    "    for i in range(100):\n",
    "        z = a * np.cos(z + i) + z * np.sin(b - i)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: -0.212537\n",
      "grad [-1.1388495, 0.19671397]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "a = tf.Variable(0.2, name=\"a\")\n",
    "b = tf.Variable(0.3, name=\"b\")\n",
    "z = tf.constant(0.0, name=\"z0\")\n",
    "for i in range(100):\n",
    "    z=a*tf.cos(z+i)+z*tf.sin(b-i)\n",
    "grad=tf.gradients(z,[a,b])\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(\"z:\",z.eval())\n",
    "    print(\"grad\",sess.run(grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and you can use a gradient descent optimizer to calcaulate the gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Mse= 2.75443\n",
      "Epoch 100 Mse= 0.524343\n",
      "Epoch 200 Mse= 0.524321\n",
      "Epoch 300 Mse= 0.524321\n",
      "Epoch 400 Mse= 0.524321\n",
      "Epoch 500 Mse= 0.524321\n",
      "Epoch 600 Mse= 0.524321\n",
      "Epoch 700 Mse= 0.524321\n",
      "Epoch 800 Mse= 0.524321\n",
      "Epoch 900 Mse= 0.524321\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.1\n",
    "#initialize\n",
    "X=tf.constant(scaled_housing_data_plus_bias,dtype=tf.float32,name=\"X\")\n",
    "y=tf.constant(housing[\"target\"].reshape(-1,1),dtype=tf.float32,name=\"y\")\n",
    "theta=tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0,seed=42),name=\"theta\")\n",
    "y_pred=tf.matmul(X,theta,name=\"prediction\")\n",
    "error=y_pred-y\n",
    "mse=tf.reduce_mean(tf.square(error),name=\"mse\")\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=0.9)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch%100 == 0 :\n",
    "            print(\"Epoch\",epoch,\"Mse=\",mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta=theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in deep learning the input and output always change ,so we use the placeholder node and can change the value of node in session execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.,  7.,  8.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=tf.placeholder(tf.float32,shape=(None,3))\n",
    "B=A + 5\n",
    "with tf.Session() as sess:\n",
    "    B_val_1=B.eval(feed_dict={A:[[1,2,3]]})\n",
    "    B_val_2=B.eval(feed_dict={A:[[4,5,6],[7,8,9]]})\n",
    "\n",
    "B_val_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C=np.array([[1,2,3]])\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(1,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow for mini-batch gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def fetch_batch(epoch, batch_id, batch_size):\n",
    "    np.random.seed(epoch)\n",
    "    shuffle_indice=np.random.permutation(m)\n",
    "    X_scaled=scaled_housing_data_plus_bias[shuffle_indice]\n",
    "    y_scaled=housing[\"target\"].reshape(-1,1)[shuffle_indice]\n",
    "    if batch_id < n_batches-1 :\n",
    "        X_batch=X_scaled[batch_id*batch_size:(batch_id+1)*batch_size]\n",
    "        y_batch=y_scaled[batch_id*batch_size:(batch_id+1)*batch_size]\n",
    "    if batch_id==n_batches-1:\n",
    "        X_batch=X_scaled[(batch_id-1)*batch_size:m]\n",
    "        y_batch=y_scaled[(batch_id-1)*batch_size:m]\n",
    "    return X_batch,y_batch\n",
    "        \n",
    "    \n",
    "n_epochs=10\n",
    "learning_rate=0.01\n",
    "batch_size=100\n",
    "n_batches=int(np.ceil(m/100))\n",
    "#initialize\n",
    "X=tf.placeholder(tf.float32,shape=(None, n+1),name=\"X\")\n",
    "y=tf.placeholder(tf.float32,shape=(None,1),name=\"y\")\n",
    "theta=tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0,seed=42),name=\"theta\")\n",
    "y_pred=tf.matmul(X,theta,name=\"prediction\")\n",
    "error=y_pred-y\n",
    "mse=tf.reduce_mean(tf.square(error),name=\"mse\")\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=0.9)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "#execution phase\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_id in range(n_batches):\n",
    "            X_batch,y_batch=fetch_batch(epoch, batch_id, batch_size)\n",
    "            #print(\"Epoch\",epoch,\"mse=\",mse.eval(feed_dict={X:X_batch,y:y_batch}))\n",
    "            sess.run(training_op,feed_dict={X:X_batch,y:y_batch})\n",
    "    best_theta=theta.eval()\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([51, 92, 14, 71, 60, 20, 82, 86, 74, 74])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "np.random.randint(100,size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Visualizing graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = b\"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.8661761457749352&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 9\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\t\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 87654321\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;random_uniform/max&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;random_uniform/RandomUniform&quot;\\n  input: &quot;random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;random_uniform/mul&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 9\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;theta&quot;\\n  input: &quot;random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;theta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;prediction&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;theta/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;prediction&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mse&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Square&quot;\\n  input: &quot;Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\001\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/mse_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Square&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/mse_grad/Reshape&quot;\\n  input: &quot;gradients/mse_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;Square&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/mse_grad/Shape_1&quot;\\n  input: &quot;gradients/mse_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/mse_grad/Shape_2&quot;\\n  input: &quot;gradients/mse_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/mse_grad/Prod_1&quot;\\n  input: &quot;gradients/mse_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;gradients/mse_grad/Prod&quot;\\n  input: &quot;gradients/mse_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/mse_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mse_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/mse_grad/Tile&quot;\\n  input: &quot;gradients/mse_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/mse_grad/truediv&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/Square_grad/mul/x&quot;\\n  input: &quot;sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/mse_grad/truediv&quot;\\n  input: &quot;gradients/Square_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;prediction&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/sub_grad/Shape&quot;\\n  input: &quot;gradients/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Square_grad/mul_1&quot;\\n  input: &quot;gradients/sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sub_grad/Sum&quot;\\n  input: &quot;gradients/sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Square_grad/mul_1&quot;\\n  input: &quot;gradients/sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradients/sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sub_grad/Neg&quot;\\n  input: &quot;gradients/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/sub_grad/Reshape&quot;\\n  input: &quot;^gradients/sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sub_grad/Reshape&quot;\\n  input: &quot;^gradients/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sub_grad/Reshape_1&quot;\\n  input: &quot;^gradients/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/prediction_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  input: &quot;theta/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/prediction_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/prediction_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/prediction_grad/MatMul&quot;\\n  input: &quot;^gradients/prediction_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/prediction_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/prediction_grad/MatMul&quot;\\n  input: &quot;^gradients/prediction_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/prediction_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/prediction_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/prediction_grad/MatMul_1&quot;\\n  input: &quot;^gradients/prediction_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/prediction_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta/Momentum/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 9\\n          }\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta/Momentum&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 9\\n        }\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta/Momentum/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;theta/Momentum&quot;\\n  input: &quot;theta/Momentum/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;theta/Momentum/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;theta/Momentum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Momentum/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.009999999776482582\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Momentum/momentum&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.8999999761581421\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Momentum/update_theta/ApplyMomentum&quot;\\n  op: &quot;ApplyMomentum&quot;\\n  input: &quot;theta&quot;\\n  input: &quot;theta/Momentum&quot;\\n  input: &quot;Momentum/learning_rate&quot;\\n  input: &quot;gradients/prediction_grad/tuple/control_dependency_1&quot;\\n  input: &quot;Momentum/momentum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@theta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;use_nesterov&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Momentum&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^Momentum/update_theta/ApplyMomentum&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^theta/Assign&quot;\\n  input: &quot;^theta/Momentum/Assign&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.8661761457749352&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we try to use tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"C:\\\\Users\\\\hasee\\\\workspace\\\\Kaggle\\\\handson\\\\Part2\\\\Chapter9\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use timedate to make the file unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:                                                        \n",
    "    sess.run(init)                                                                \n",
    "\n",
    "    for epoch in range(n_epochs):                                                \n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open cmd and type to open tensorboard:** tensorboard --logdir tf_logs/ **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Name Scops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"C:\\\\Users\\\\hasee\\\\workspace\\\\Kaggle\\\\handson\\\\Part2\\\\Chapter9\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "with tf.name_scope(\"loss\") as scope:\n",
    "    error = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "with tf.Session() as sess:                                                        \n",
    "    sess.run(init)                                                                \n",
    "\n",
    "    for epoch in range(n_epochs):                                                \n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()  \n",
    "    \n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a graph that adds the output of two rectified linear units\n",
    "(ReLU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first use a function to implement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "def RELU(X):\n",
    "    w_shape=(int(X.get_shape()[1]),1)\n",
    "    w=tf.Variable(tf.random_normal(w_shape,1,seed=42),name=\"w\")\n",
    "    b=tf.Variable(0.0,name=\"bias\")\n",
    "    z=tf.add(tf.matmul(X,w),b,name=\"z\")\n",
    "    return tf.maximum(z,0.,name=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.52571678]]\n"
     ]
    }
   ],
   "source": [
    "n_features=3\n",
    "X=tf.placeholder(tf.float32,shape=(None,n_features),name=\"X\")\n",
    "relus=[RELU(X) for i in range(5)]\n",
    "output=tf.add_n(relus,name=\"output\") #tf.add_n([add1 add2])= add1+add2\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(output.eval(feed_dict={X:[[1,1,1]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array([1,2,3])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(\"logs/relu2\", tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and also you can add name scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "def RELU(X):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        w_shape=(int(X.get_shape()[1]),1)\n",
    "        w=tf.Variable(tf.random_normal(w_shape,1,seed=42),name=\"w\")\n",
    "        b=tf.Variable(0.0,name=\"bias\")\n",
    "        z=tf.add(tf.matmul(X,w),b,name=\"z\")\n",
    "        return tf.maximum(z,0.,name=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.52571678]]\n"
     ]
    }
   ],
   "source": [
    "n_features=3\n",
    "X=tf.placeholder(tf.float32,shape=(None,n_features),name=\"X\")\n",
    "relus=[RELU(X) for i in range(5)]\n",
    "output=tf.add_n(relus,name=\"output\") #tf.add_n([add1 add2])= add1+add2\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(output.eval(feed_dict={X:[[1,1,1]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter(\"logs/relu3\", tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Extra Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try to use tensorflow to implement logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "m = 1000\n",
    "X_moons, y_moons = make_moons(m, noise=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28ffc317198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X_moons[y_moons == 1, 0], X_moons[y_moons == 1, 1], 'go', label=\"Positive\")\n",
    "plt.plot(X_moons[y_moons == 0, 0], X_moons[y_moons == 0, 1], 'r^', label=\"Negative\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_moons_with_bias=np.c_[np.ones((m,1)),X_moons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_moons_with_bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_moons_column_vector=y_moons.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ratio=0.2\n",
    "test_size=int(m*test_ratio)\n",
    "X_train=X_moons_with_bias[:-test_size]\n",
    "X_test=X_moons_with_bias[-test_size:]\n",
    "y_train=y_moons_column_vector[:-test_size]\n",
    "y_test=y_moons_column_vector[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Random_batch(X,y,batch_size):\n",
    "    #X_shuffle=np.random.permutation(X)\n",
    "    #y_shuffle=np.random.permutation(y)\n",
    "    #X_batch=X_shuffle[:batch_size]\n",
    "    #y_batch=y_shuffle[:batch_size]\n",
    "    #return X_batch,y_batch\n",
    "    shuffle_indice=np.random.randint(0,len(X),batch_size)\n",
    "    X_batch=X[shuffle_indice]\n",
    "    y_batch=y[shuffle_indice]\n",
    "    return X_batch,y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we start tensorflow code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 0.877019\n",
      "Epoch 100 loss 0.35205\n",
      "Epoch 200 loss 0.310993\n",
      "Epoch 300 loss 0.29464\n",
      "Epoch 400 loss 0.286309\n",
      "Epoch 500 loss 0.281046\n",
      "Epoch 600 loss 0.278434\n",
      "Epoch 700 loss 0.27638\n",
      "Epoch 800 loss 0.275664\n",
      "Epoch 900 loss 0.275004\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "np.random.seed(42)\n",
    "#graph phase\n",
    "learning_rate=0.01\n",
    "\n",
    "n_features=2\n",
    "X=tf.placeholder(tf.float32,shape=(None,n_features+1),name=\"X\")\n",
    "y=tf.placeholder(tf.float32,shape=(None,1),name=\"y\")\n",
    "theta=tf.Variable(tf.random_uniform([n_features+1,1],-1.0,1.0,seed=42),name=\"theta\")\n",
    "logit=tf.matmul(X,theta)\n",
    "#y_pred=1/(1+tf.exp(-logit))\n",
    "y_pred=tf.sigmoid(logit)\n",
    "epsilon=1e-7\n",
    "#loss=-tf.reduce_mean(y*tf.log(y_pred+epsilon)+(1-y)*tf.log(1-y_pred+epilson))\n",
    "loss=tf.losses.log_loss(y,y_pred)\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op=optimizer.minimize(loss)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "#Execution phase\n",
    "\n",
    "n_epochs=1000\n",
    "batch_size=50\n",
    "n_batches=int(np.ceil(m/batch_size))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for batch in range(n_batches):\n",
    "            X_batch,y_batch=Random_batch(X_train,y_train,batch_size)\n",
    "            sess.run(training_op,feed_dict={X:X_batch,y:y_batch})\n",
    "        loss_val=loss.eval(feed_dict={X:X_test,y:y_test})\n",
    "        if epoch%100==0 :\n",
    "            print(\"Epoch\",epoch,\"loss\",loss_val)\n",
    "            \n",
    "    y_pred_val = y_pred.eval(feed_dict={X: X_test, y: y_test})\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=[1,2,3]\n",
    "X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.54818761],\n",
       "       [ 0.70775223],\n",
       "       [ 0.5182308 ],\n",
       "       [ 0.99098408],\n",
       "       [ 0.50884157]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_out=(y_pred_val>=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86274509803921573"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision_score(y_test, y_pred_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88888888888888884"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,y_pred_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87562189054726369"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that looks pretty bad, doesn't it? But let's not forget that the Logistic Regression model has a linear decision boundary, so this is actually close to the best we can do with this model (unless we add more features, as we will show in a second).\n",
    "Now let's start over, but this time we will add all the bells and whistles, as listed in the exercise:\n",
    "- Define the graph within a logistic_regression() function that can be reused easily.\n",
    "- Save checkpoints using a Saver at regular intervals during training, and save the final model at the end of training.\n",
    "- Restore the last checkpoint upon startup if training was interrupted.\n",
    "- Define the graph using nice scopes so the graph looks good in TensorBoard.\n",
    "- Add summaries to visualize the learning curves in TensorBoard.\n",
    "- Try tweaking some hyperparameters such as the learning rate or the mini-batch size and look at the shape of the learning curve.\n",
    "\n",
    "Before we start, we will add 4 more features to the inputs: ${x_1}^2$, ${x_2}^2$, ${x_1}^3$ and ${x_2}^3$. This was not part of the exercise, but it will demonstrate how adding features can improve the model. We will do this manually, but you could also add them using sklearn.preprocessing.PolynomialFeatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_feature=PolynomialFeatures(degree=2,include_bias=False)\n",
    "X_poly_train=poly_feature.fit_transform(X_train)\n",
    "X_poly_test=poly_feature.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 9)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_poly_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def Logistic_regression(X,y,learning_rate,initializer=None):\n",
    "    n_inputs_including_bias=int(X.get_shape()[1])#in tensorflow should use get_shape()\n",
    "    with tf.name_scope(\"Logistic_regression\"):\n",
    "        with tf.name_scope(\"model\"):\n",
    "            if initializer is None:\n",
    "                initializer=tf.random_uniform([n_inputs_including_bias,1],-1.0,1.0,seed=42)\n",
    "            theta=tf.Variable(initializer,name=\"theta\")\n",
    "            logit=tf.matmul(X,theta,name=\"logit\")\n",
    "            y_prob=tf.sigmoid(logit)\n",
    "        with tf.name_scope(\"train\"):\n",
    "            loss=tf.losses.log_loss(y,y_prob,scope=\"loss\")\n",
    "            optimizer=tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "            traning_op=optimizer.minimize(loss)\n",
    "            loss_summary=tf.summary.scalar(\"log_loss\",loss)\n",
    "        with tf.name_scope(\"init\"):\n",
    "            init=tf.global_variables_initializer()\n",
    "        with tf.name_scope(\"save\"):\n",
    "            saver = tf.train.Saver()\n",
    "    return y_prob, loss, training_op, loss_summary, init, saver\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def log_dir(prefix=\"\"):\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    root_logdir = \"tf_log_reg\"\n",
    "    if prefix:\n",
    "        prefix += \"-\"\n",
    "    name = prefix + \"run-\" + now\n",
    "    return \"{}/{}/\".format(root_logdir, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#graph phase\n",
    "n_features=9\n",
    "logdir=log_dir(\"logreg\")\n",
    "learining_rate=0.01\n",
    "\n",
    "X=tf.placeholder(tf.float32,shape=(None,n_features),name=\"X\")\n",
    "y=tf.placeholder(tf.float32,shape=(None,1),name=\"y\")\n",
    "\n",
    "y_prob, loss, training_op, loss_summary, init, saver=Logistic_regression(X,y,learning_rate=learning_rate)\n",
    "\n",
    "file_writer = tf.summary.FileWriter(logdir,tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Fetch argument <tf.Operation 'GradientDescent' type=NoOp> cannot be interpreted as a Tensor. (Operation name: \"GradientDescent\"\nop: \"NoOp\"\ninput: \"^GradientDescent/update_theta/ApplyGradientDescent\"\n is not an element of this graph.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    269\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[1;32m--> 270\u001b[1;33m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[0;32m    271\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   2707\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2708\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   2791\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2792\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Operation %s is not an element of this graph.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2793\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Operation name: \"GradientDescent\"\nop: \"NoOp\"\ninput: \"^GradientDescent/update_theta/ApplyGradientDescent\"\n is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-73804f10d307>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mRandom_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_poly_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mloss_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_summary\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX_poly_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mfile_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1107\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1108\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m-> 1109\u001b[1;33m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m   1110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \"\"\"\n\u001b[0;32m    412\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m     \u001b[1;31m# Did not find anything.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    275\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[1;32m--> 277\u001b[1;33m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[0;32m    278\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[1;31mValueError\u001b[0m: Fetch argument <tf.Operation 'GradientDescent' type=NoOp> cannot be interpreted as a Tensor. (Operation name: \"GradientDescent\"\nop: \"NoOp\"\ninput: \"^GradientDescent/update_theta/ApplyGradientDescent\"\n is not an element of this graph.)"
     ]
    }
   ],
   "source": [
    "#execution phase\n",
    "import os\n",
    "n_epochs = 10001\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "checkpoint_path = \"C:\\\\Users\\\\hasee\\\\workspace\\\\Kaggle\\\\handson\\\\Part2\\\\Chapter9\\\\tmp\\\\my_logreg_model.ckpt\"\n",
    "checkpoint_epoch_path = checkpoint_path + \".epoch\"\n",
    "final_model_path = \"C:\\\\Users\\\\hasee\\\\workspace\\\\Kaggle\\\\handson\\\\Part2\\\\Chapter9\\\\my_logreg_model\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if os.path.isfile(checkpoint_epoch_path):\n",
    "        # if the checkpoint file exists, restore the model and load the epoch number\n",
    "        with open(checkpoint_epoch_path, \"rb\") as f:\n",
    "            start_epoch = int(f.read())\n",
    "        print(\"Training was interrupted. Continuing at epoch\", start_epoch)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        sess.run(init)\n",
    "        \n",
    "    for epoch in range(start_epoch,n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch= Random_batch(X_poly_train,y_train,batch_size)\n",
    "            sess.run(training_op,feed_dict={X:X_batch,y:y_batch})\n",
    "        loss_val,summary_str=sess.run([loss,loss_summary],feed_dict={X:X_poly_test,y:y_test})\n",
    "        file_writer.add_summary(summary_str,epoch)\n",
    "        if epoch%500==0:\n",
    "            print(\"Epoch:\",epoch,\"loss\",loss_val)\n",
    "            saver.save(sess,checkpoint_path)\n",
    "            with open(checkpoint_epoch_path, \"wb\") as f:\n",
    "                f.write(b\"%d\" % (epoch + 1))\n",
    "    \n",
    "    saver.save(sess,final_model_path)\n",
    "    y_prob_val=y_prob.eval(feed_dict={X:X_poly_test,y:y_test})\n",
    "    os.remove(checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
