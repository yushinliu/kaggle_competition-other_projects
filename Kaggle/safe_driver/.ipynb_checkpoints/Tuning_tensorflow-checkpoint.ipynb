{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "test_dat = pd.read_csv(base_path + 'test.csv')\n",
    "train_dat = pd.read_csv(base_path + 'train.csv')\n",
    "submission = pd.read_csv(base_path + 'sample_submission.csv')\n",
    "\n",
    "train_y = train_dat['target']\n",
    "train_x = train_dat.drop(['target', 'id'], axis = 1)\n",
    "test_dat = test_dat.drop(['id'], axis = 1)\n",
    "\n",
    "merged_dat = pd.concat([train_x, test_dat],axis=0)\n",
    "\n",
    "#change data to float32\n",
    "for c, dtype in zip(merged_dat.columns, merged_dat.dtypes): \n",
    "    if dtype == np.float64:     \n",
    "        merged_dat[c] = merged_dat[c].astype(np.float32)\n",
    "\n",
    "#one hot encode the categoricals\n",
    "cat_features = [col for col in merged_dat.columns if col.endswith('cat')]\n",
    "for column in cat_features:\n",
    "    temp=pd.get_dummies(pd.Series(merged_dat[column]))\n",
    "    merged_dat=pd.concat([merged_dat,temp],axis=1)\n",
    "    merged_dat=merged_dat.drop([column],axis=1)\n",
    "\n",
    "#standardize the scale of the numericals\n",
    "numeric_features = [col for col in merged_dat.columns if '_calc_' in  str(col)]\n",
    "numeric_features = [col for col in numeric_features if '_bin' not in str(col)]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_numerics = scaler.fit_transform(merged_dat[numeric_features])\n",
    "scaled_num_df = pd.DataFrame(scaled_numerics, columns =numeric_features )\n",
    "\n",
    "\n",
    "merged_dat = merged_dat.drop(numeric_features, axis=1)\n",
    "\n",
    "merged_dat = np.concatenate((merged_dat.values,scaled_num_df), axis = 1)\n",
    "\n",
    "train_x = merged_dat[:train_x.shape[0]]\n",
    "test_dat = merged_dat[train_x.shape[0]:]\n",
    "\n",
    "\n",
    "config = tf.contrib.learn.RunConfig(tf_random_seed=42)\n",
    "\n",
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(train_x)\n",
    "\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[150,150,150], n_classes=2,\n",
    "                                         feature_columns=feature_cols, config=config)\n",
    "\n",
    "dnn_clf.fit(train_x, train_y, batch_size=50, steps=40000)\n",
    "\n",
    "dnn_y_pred = dnn_clf.predict_proba(test_dat)\n",
    "dnn_y_pred_train = dnn_clf.predict_proba(train_x)\n",
    "\n",
    "\n",
    "dnn_out = list(dnn_y_pred)\n",
    "\n",
    "dnn_output = submission\n",
    "dnn_output['target'] = [x[1] for x in dnn_out]\n",
    "\n",
    "\n",
    "dnn_output.to_csv(base_path + 'test_dnn_predictions.csv', index=False, float_format='%.4f')\n",
    "\n",
    "train = pd.read_csv(base_path + 'train.csv')\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = train['id']\n",
    "sub['target'] = [x[1] for x in list(dnn_y_pred_train)]\n",
    "sub.to_csv(base_path + 'train_dnn_predictions.csv', index=False, float_format='%.4f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
