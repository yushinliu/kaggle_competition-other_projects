{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_path = \"C:\\\\Users\\\\hasee\\\\workspace\\\\Kaggle\\\\safe_driver\\\\\" # your folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "test_dat = pd.read_csv(base_path + 'test.csv')\n",
    "train_dat = pd.read_csv(base_path + 'train.csv')\n",
    "submission = pd.read_csv(base_path + 'sample_submission.csv')\n",
    "\n",
    "train_y = train_dat['target']\n",
    "train_x = train_dat.drop(['target', 'id'], axis = 1)\n",
    "test_dat = test_dat.drop(['id'], axis = 1)\n",
    "\n",
    "merged_dat = pd.concat([train_x, test_dat],axis=0)\n",
    "\n",
    "#change data to float32\n",
    "for c, dtype in zip(merged_dat.columns, merged_dat.dtypes): \n",
    "    if dtype == np.float64:     \n",
    "        merged_dat[c] = merged_dat[c].astype(np.float32)\n",
    "\n",
    "#one hot encode the categoricals\n",
    "cat_features = [col for col in merged_dat.columns if col.endswith('cat')]\n",
    "for column in cat_features:\n",
    "    temp=pd.get_dummies(pd.Series(merged_dat[column]))\n",
    "    merged_dat=pd.concat([merged_dat,temp],axis=1)\n",
    "    merged_dat=merged_dat.drop([column],axis=1)\n",
    "\n",
    "#standardize the scale of the numericals\n",
    "numeric_features = [col for col in merged_dat.columns if '_calc_' in  str(col)]\n",
    "numeric_features = [col for col in numeric_features if '_bin' not in str(col)]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_numerics = scaler.fit_transform(merged_dat[numeric_features])\n",
    "scaled_num_df = pd.DataFrame(scaled_numerics, columns =numeric_features )\n",
    "\n",
    "\n",
    "merged_dat = merged_dat.drop(numeric_features, axis=1)\n",
    "\n",
    "merged_dat = np.concatenate((merged_dat.values,scaled_num_df), axis = 1)\n",
    "\n",
    "train_x = merged_dat[:train_x.shape[0]]\n",
    "test_dat = merged_dat[train_x.shape[0]:]\n",
    "\n",
    "\n",
    "config = tf.contrib.learn.RunConfig(tf_random_seed=42)\n",
    "\n",
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(train_x)\n",
    "\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[150,150,150], n_classes=2,\n",
    "                                         feature_columns=feature_cols, config=config)\n",
    "\n",
    "dnn_clf.fit(train_x, train_y, batch_size=50, steps=40000)\n",
    "\n",
    "dnn_y_pred = dnn_clf.predict_proba(test_dat)\n",
    "dnn_y_pred_train = dnn_clf.predict_proba(train_x)\n",
    "\n",
    "\n",
    "dnn_out = list(dnn_y_pred)\n",
    "\n",
    "dnn_output = submission\n",
    "dnn_output['target'] = [x[1] for x in dnn_out]\n",
    "\n",
    "\n",
    "dnn_output.to_csv(base_path + 'test_dnn_predictions.csv', index=False, float_format='%.4f')\n",
    "\n",
    "train = pd.read_csv(base_path + 'train.csv')\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = train['id']\n",
    "sub['target'] = [x[1] for x in list(dnn_y_pred_train)]\n",
    "sub.to_csv(base_path + 'train_dnn_predictions.csv', index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
