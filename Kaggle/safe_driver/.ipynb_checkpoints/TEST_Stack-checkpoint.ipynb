{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Work with data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "work with data and output to a new data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ps_ind_16_bin ps_ind_17_bin\n",
      "ps_ind_16_bin ps_ind_18_bin\n",
      "ps_ind_17_bin ps_ind_16_bin\n",
      "ps_ind_17_bin ps_ind_18_bin\n",
      "ps_ind_18_bin ps_ind_16_bin\n",
      "ps_ind_18_bin ps_ind_17_bin\n"
     ]
    }
   ],
   "source": [
    "base_path = \"C:\\\\Users\\\\hasee\\\\workspace\\\\Kaggle\\\\safe_driver\\\\\" # your folder\n",
    "\n",
    "import pandas as pd\n",
    "train=pd.read_csv(base_path + 'train.csv')\n",
    "test=pd.read_csv(base_path + 'test.csv')\n",
    "\n",
    "train['ps_ind_0609_bin'] = train.apply(lambda x: 1 if x['ps_ind_06_bin'] == 1 else (2 if x['ps_ind_07_bin'] == 1 else \n",
    "(\n",
    "3 if x['ps_ind_08_bin'] == 1 else (4 if x['ps_ind_09_bin'] == 1 else 5)\n",
    "\n",
    ")), axis = 1) #use lambda to define a function more easy and samplified than 'def'\n",
    "\n",
    "test['ps_ind_0609_bin'] = test.apply(lambda x: 1 if x['ps_ind_06_bin'] == 1 else (2 if x['ps_ind_07_bin'] == 1 else \n",
    "(\n",
    "3 if x['ps_ind_08_bin'] == 1 else (4 if x['ps_ind_09_bin'] == 1 else 5)\n",
    "\n",
    ")), axis = 1)\n",
    "\n",
    "train.drop(['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin'], axis = 1, inplace = True)\n",
    "\n",
    "test.drop(['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin'], axis = 1, inplace = True)\n",
    "\n",
    "train['ps_car_13'] = (train['ps_car_13']*train['ps_car_13']* 48400).round(0)#round(0)小数点后一位四舍五入\n",
    "\n",
    "test['ps_car_13'] = (test['ps_car_13']*test['ps_car_13']* 48400).round(0)\n",
    "\n",
    "train['ps_car_12'] = (train['ps_car_12']*train['ps_car_12']).round(4) * 10000#round(4)小数点后三位四舍五入\n",
    "\n",
    "test['ps_car_12'] = (test['ps_car_12']*test['ps_car_12']).round(4) * 10000\n",
    "\n",
    "for c in train[[c for c in train.columns if 'bin' in c]].columns:\n",
    "    for cc in train[[c for c in train.columns if 'bin' in c]].columns:\n",
    "            if train[train[cc] * train[c] == 0].shape[0] == train.shape[0]:\n",
    "                print(c, cc)\n",
    "\n",
    "train['ps_ind_161718_bin'] = train.apply(lambda x: 1 if x['ps_ind_16_bin'] == 1 else\n",
    "                                        (2 if x['ps_ind_17_bin'] == 1 else 3), axis = 1\n",
    "                                        ) #18->1,16->2,17->3\n",
    "\n",
    "test['ps_ind_161718_bin'] = test.apply(lambda x: 1 if x['ps_ind_16_bin'] == 1 else\n",
    "                                        (2 if x['ps_ind_17_bin'] == 1 else 3), axis = 1\n",
    "                                        )\n",
    "\n",
    "train.drop(['ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin'], axis = 1, inplace = True)\n",
    "\n",
    "test.drop(['ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin'], axis = 1, inplace = True)\n",
    "\n",
    "train.to_csv(base_path + 'train_p.csv', index = False)\n",
    "\n",
    "test.to_csv(base_path + 'test_p.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>ps_ind_11_bin</th>\n",
       "      <th>ps_ind_12_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "      <th>ps_ind_0609_bin</th>\n",
       "      <th>ps_ind_161718_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595182</th>\n",
       "      <td>1487945</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595183</th>\n",
       "      <td>1487951</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595184</th>\n",
       "      <td>1487952</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595185</th>\n",
       "      <td>1487954</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595186</th>\n",
       "      <td>1487957</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595187</th>\n",
       "      <td>1487958</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595188</th>\n",
       "      <td>1487962</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595189</th>\n",
       "      <td>1487963</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595190</th>\n",
       "      <td>1487964</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595191</th>\n",
       "      <td>1487968</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595192</th>\n",
       "      <td>1487973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595193</th>\n",
       "      <td>1487975</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595194</th>\n",
       "      <td>1487976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595195</th>\n",
       "      <td>1487980</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595196</th>\n",
       "      <td>1487983</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595197</th>\n",
       "      <td>1487988</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595198</th>\n",
       "      <td>1487990</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595199</th>\n",
       "      <td>1487992</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595200</th>\n",
       "      <td>1487994</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595201</th>\n",
       "      <td>1487996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595202</th>\n",
       "      <td>1488001</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595203</th>\n",
       "      <td>1488005</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595204</th>\n",
       "      <td>1488008</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595205</th>\n",
       "      <td>1488009</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595206</th>\n",
       "      <td>1488011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595207</th>\n",
       "      <td>1488013</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595208</th>\n",
       "      <td>1488016</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595209</th>\n",
       "      <td>1488017</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595210</th>\n",
       "      <td>1488021</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595211</th>\n",
       "      <td>1488027</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>595212 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0             7       0          2              2          5              1   \n",
       "1             9       0          1              1          7              0   \n",
       "2            13       0          5              4          9              1   \n",
       "3            16       0          0              1          2              0   \n",
       "4            17       0          0              2          0              1   \n",
       "5            19       0          5              1          4              0   \n",
       "6            20       0          2              1          3              1   \n",
       "7            22       0          5              1          4              0   \n",
       "8            26       0          5              1          3              1   \n",
       "9            28       1          1              1          2              0   \n",
       "10           34       0          5              2          2              0   \n",
       "11           35       0          2              1          3              1   \n",
       "12           36       0          2              1          1              1   \n",
       "13           43       0          1              1          3              1   \n",
       "14           46       0          5              1         11              0   \n",
       "15           48       0          5              1          3              1   \n",
       "16           50       0          1              2          1              0   \n",
       "17           58       0          5              1          6              0   \n",
       "18           61       0          5              1          8              0   \n",
       "19           64       1          0              1          2              1   \n",
       "20           65       0          0              1          2              0   \n",
       "21           66       0          0              1          5              1   \n",
       "22           72       0          5              3          6              1   \n",
       "23           74       0          2              1          2              1   \n",
       "24           77       0          0              1          2              0   \n",
       "25           78       0          0              1          7              0   \n",
       "26           79       0          0              1          4              1   \n",
       "27           80       0          4              1          6              0   \n",
       "28           84       1          0              2          0              1   \n",
       "29           85       0          3              2          2              0   \n",
       "...         ...     ...        ...            ...        ...            ...   \n",
       "595182  1487945       0          0              1          2              0   \n",
       "595183  1487951       0          1              1          9              0   \n",
       "595184  1487952       0          1              1          5              0   \n",
       "595185  1487954       0          0              2          8              1   \n",
       "595186  1487957       0          0              1          3              1   \n",
       "595187  1487958       0          0              1          7              0   \n",
       "595188  1487962       0          2              1          3              0   \n",
       "595189  1487963       0          3              1          9              0   \n",
       "595190  1487964       0          1              2          3              0   \n",
       "595191  1487968       0          5              1          3              0   \n",
       "595192  1487973       0          0              1          1              0   \n",
       "595193  1487975       0          0              2          0              0   \n",
       "595194  1487976       0          0              1          7              1   \n",
       "595195  1487980       0          0              3          3              1   \n",
       "595196  1487983       0          1              1          2              0   \n",
       "595197  1487988       0          1              1          7              1   \n",
       "595198  1487990       0          5              1          7              1   \n",
       "595199  1487992       0          3              1          3              1   \n",
       "595200  1487994       0          1              1          1              0   \n",
       "595201  1487996       0          0              2          2              1   \n",
       "595202  1488001       0          4              1          3              0   \n",
       "595203  1488005       0          3              2          3              1   \n",
       "595204  1488008       0          1              2          2              1   \n",
       "595205  1488009       0          0              3          6              1   \n",
       "595206  1488011       0          0              1          2              0   \n",
       "595207  1488013       0          3              1         10              0   \n",
       "595208  1488016       0          5              1          3              0   \n",
       "595209  1488017       0          1              1         10              0   \n",
       "595210  1488021       0          5              2          3              1   \n",
       "595211  1488027       0          0              1          8              0   \n",
       "\n",
       "        ps_ind_05_cat  ps_ind_10_bin  ps_ind_11_bin  ps_ind_12_bin  \\\n",
       "0                   0              0              0              0   \n",
       "1                   0              0              0              0   \n",
       "2                   0              0              0              0   \n",
       "3                   0              0              0              0   \n",
       "4                   0              0              0              0   \n",
       "5                   0              0              0              0   \n",
       "6                   0              0              0              0   \n",
       "7                   0              0              0              0   \n",
       "8                   0              0              0              0   \n",
       "9                   0              0              0              0   \n",
       "10                  0              0              0              0   \n",
       "11                  0              0              0              0   \n",
       "12                  0              0              0              0   \n",
       "13                  0              0              0              0   \n",
       "14                  0              0              0              0   \n",
       "15                  0              0              0              0   \n",
       "16                  0              0              0              0   \n",
       "17                  1              0              0              0   \n",
       "18                  0              0              0              0   \n",
       "19                  0              0              0              0   \n",
       "20                  0              0              0              0   \n",
       "21                  4              0              0              0   \n",
       "22                  3              0              0              0   \n",
       "23                  0              0              0              0   \n",
       "24                  0              0              0              0   \n",
       "25                  0              0              0              0   \n",
       "26                  0              0              0              0   \n",
       "27                  0              0              0              0   \n",
       "28                  4              0              0              0   \n",
       "29                  0              0              0              0   \n",
       "...               ...            ...            ...            ...   \n",
       "595182              0              0              0              0   \n",
       "595183              0              0              0              0   \n",
       "595184              0              0              0              0   \n",
       "595185              0              0              0              0   \n",
       "595186              0              0              0              0   \n",
       "595187              4              0              0              0   \n",
       "595188              0              0              0              0   \n",
       "595189              0              0              0              0   \n",
       "595190              0              0              0              0   \n",
       "595191              0              0              0              0   \n",
       "595192              0              0              0              0   \n",
       "595193             -1              0              0              0   \n",
       "595194              0              0              0              0   \n",
       "595195              0              0              0              0   \n",
       "595196              0              0              0              0   \n",
       "595197              0              0              0              0   \n",
       "595198              0              0              0              0   \n",
       "595199              0              0              0              0   \n",
       "595200              3              0              0              0   \n",
       "595201              0              0              0              0   \n",
       "595202              0              0              0              0   \n",
       "595203              0              0              0              0   \n",
       "595204              0              0              0              0   \n",
       "595205              0              0              0              0   \n",
       "595206              0              0              0              0   \n",
       "595207              0              0              0              0   \n",
       "595208              0              0              0              0   \n",
       "595209              0              0              0              0   \n",
       "595210              0              0              0              0   \n",
       "595211              0              0              0              0   \n",
       "\n",
       "              ...          ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0             ...                   5           8               0   \n",
       "1             ...                   1           9               0   \n",
       "2             ...                   7           7               0   \n",
       "3             ...                   4           9               0   \n",
       "4             ...                   1           3               0   \n",
       "5             ...                   0           9               0   \n",
       "6             ...                   0          10               0   \n",
       "7             ...                   3           6               1   \n",
       "8             ...                   1           5               0   \n",
       "9             ...                   0           6               0   \n",
       "10            ...                   3           6               0   \n",
       "11            ...                   1          10               0   \n",
       "12            ...                   3           8               0   \n",
       "13            ...                   4           3               0   \n",
       "14            ...                   3           9               0   \n",
       "15            ...                   6           7               0   \n",
       "16            ...                   1           8               0   \n",
       "17            ...                   3           9               0   \n",
       "18            ...                   6           5               0   \n",
       "19            ...                   1          11               0   \n",
       "20            ...                   2           4               0   \n",
       "21            ...                   3           8               0   \n",
       "22            ...                   3           5               0   \n",
       "23            ...                   3           9               0   \n",
       "24            ...                   2           8               0   \n",
       "25            ...                   4           4               0   \n",
       "26            ...                   4           3               0   \n",
       "27            ...                   2          11               0   \n",
       "28            ...                   0           8               0   \n",
       "29            ...                   4           7               0   \n",
       "...           ...                 ...         ...             ...   \n",
       "595182        ...                   5           8               0   \n",
       "595183        ...                   3           7               0   \n",
       "595184        ...                   3           9               0   \n",
       "595185        ...                   1          11               0   \n",
       "595186        ...                   2           9               0   \n",
       "595187        ...                   4           9               0   \n",
       "595188        ...                   6           6               0   \n",
       "595189        ...                   8           4               0   \n",
       "595190        ...                   4           6               0   \n",
       "595191        ...                   1          11               0   \n",
       "595192        ...                   5           5               0   \n",
       "595193        ...                   3           5               0   \n",
       "595194        ...                   4          12               0   \n",
       "595195        ...                   2           5               0   \n",
       "595196        ...                   1          11               1   \n",
       "595197        ...                   3           6               0   \n",
       "595198        ...                   2          14               0   \n",
       "595199        ...                   1          10               0   \n",
       "595200        ...                   3          12               0   \n",
       "595201        ...                   2           6               1   \n",
       "595202        ...                   2           6               0   \n",
       "595203        ...                   1           6               0   \n",
       "595204        ...                   3           9               0   \n",
       "595205        ...                   2           6               1   \n",
       "595206        ...                   1           7               0   \n",
       "595207        ...                   9           6               0   \n",
       "595208        ...                   3           8               1   \n",
       "595209        ...                   2           6               0   \n",
       "595210        ...                   4           2               0   \n",
       "595211        ...                   3           8               0   \n",
       "\n",
       "        ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0                    1               1               0               0   \n",
       "1                    1               1               0               1   \n",
       "2                    1               1               0               1   \n",
       "3                    0               0               0               0   \n",
       "4                    0               0               1               1   \n",
       "5                    1               0               1               1   \n",
       "6                    1               0               0               1   \n",
       "7                    0               1               0               1   \n",
       "8                    1               0               0               0   \n",
       "9                    1               0               0               1   \n",
       "10                   1               1               0               1   \n",
       "11                   1               0               1               0   \n",
       "12                   0               1               0               0   \n",
       "13                   0               1               0               1   \n",
       "14                   0               0               0               1   \n",
       "15                   1               1               0               1   \n",
       "16                   0               1               0               0   \n",
       "17                   1               1               0               0   \n",
       "18                   0               0               1               0   \n",
       "19                   1               1               0               1   \n",
       "20                   1               0               0               1   \n",
       "21                   0               0               0               1   \n",
       "22                   0               0               0               0   \n",
       "23                   1               0               1               0   \n",
       "24                   1               1               1               0   \n",
       "25                   0               1               1               0   \n",
       "26                   1               1               1               0   \n",
       "27                   1               0               1               0   \n",
       "28                   1               1               0               0   \n",
       "29                   1               0               0               0   \n",
       "...                ...             ...             ...             ...   \n",
       "595182               0               0               1               1   \n",
       "595183               1               1               0               1   \n",
       "595184               0               0               0               0   \n",
       "595185               1               0               1               0   \n",
       "595186               0               1               1               0   \n",
       "595187               1               1               0               0   \n",
       "595188               1               1               0               0   \n",
       "595189               1               0               1               1   \n",
       "595190               0               1               0               0   \n",
       "595191               0               1               1               0   \n",
       "595192               1               1               0               1   \n",
       "595193               1               0               1               0   \n",
       "595194               1               1               0               0   \n",
       "595195               1               0               0               1   \n",
       "595196               1               0               0               1   \n",
       "595197               0               1               1               1   \n",
       "595198               1               1               0               0   \n",
       "595199               0               1               0               1   \n",
       "595200               0               1               0               0   \n",
       "595201               1               0               1               1   \n",
       "595202               1               1               0               1   \n",
       "595203               0               0               0               0   \n",
       "595204               1               0               0               1   \n",
       "595205               0               1               0               0   \n",
       "595206               1               1               0               0   \n",
       "595207               1               1               0               1   \n",
       "595208               0               1               0               1   \n",
       "595209               0               1               0               0   \n",
       "595210               1               1               1               0   \n",
       "595211               1               0               0               0   \n",
       "\n",
       "        ps_calc_20_bin  ps_ind_0609_bin  ps_ind_161718_bin  \n",
       "0                    1                2                  2  \n",
       "1                    0                3                  3  \n",
       "2                    0                3                  1  \n",
       "3                    0                1                  1  \n",
       "4                    0                1                  1  \n",
       "5                    1                4                  1  \n",
       "6                    0                2                  1  \n",
       "7                    0                1                  1  \n",
       "8                    1                3                  1  \n",
       "9                    0                2                  3  \n",
       "10                   1                3                  1  \n",
       "11                   0                2                  1  \n",
       "12                   1                3                  1  \n",
       "13                   0                2                  1  \n",
       "14                   0                4                  3  \n",
       "15                   0                2                  3  \n",
       "16                   0                3                  1  \n",
       "17                   0                1                  1  \n",
       "18                   0                1                  1  \n",
       "19                   0                1                  1  \n",
       "20                   0                1                  3  \n",
       "21                   0                1                  1  \n",
       "22                   1                2                  1  \n",
       "23                   0                2                  1  \n",
       "24                   0                1                  3  \n",
       "25                   1                1                  1  \n",
       "26                   1                3                  1  \n",
       "27                   0                4                  1  \n",
       "28                   0                1                  1  \n",
       "29                   0                1                  1  \n",
       "...                ...              ...                ...  \n",
       "595182               0                1                  1  \n",
       "595183               0                1                  1  \n",
       "595184               1                1                  3  \n",
       "595185               0                3                  1  \n",
       "595186               0                2                  1  \n",
       "595187               1                4                  1  \n",
       "595188               0                1                  1  \n",
       "595189               0                1                  3  \n",
       "595190               0                1                  1  \n",
       "595191               1                3                  2  \n",
       "595192               1                2                  1  \n",
       "595193               0                2                  1  \n",
       "595194               0                2                  3  \n",
       "595195               1                2                  3  \n",
       "595196               1                1                  3  \n",
       "595197               0                2                  3  \n",
       "595198               0                4                  3  \n",
       "595199               0                3                  1  \n",
       "595200               0                1                  1  \n",
       "595201               0                4                  1  \n",
       "595202               0                2                  1  \n",
       "595203               0                2                  2  \n",
       "595204               0                2                  1  \n",
       "595205               0                2                  1  \n",
       "595206               0                4                  1  \n",
       "595207               1                4                  1  \n",
       "595208               1                4                  1  \n",
       "595209               0                1                  1  \n",
       "595210               0                3                  1  \n",
       "595211               0                1                  1  \n",
       "\n",
       "[595212 rows x 54 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<scipy.stats._distn_infrastructure.rv_frozen at 0x2ba00030d68>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal, uniform\n",
    "reciprocal(0.01,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_path = \"C:\\\\Users\\\\hasee\\\\workspace\\\\Kaggle\\\\safe_driver\\\\\" # your folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. XGBOOST and LGB from kaggle kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files...\n",
      "(595212, 34) (892816, 33)\n",
      " xgb kfold: 1  of  5 : \n",
      "[0]\ttrain-gini:0.197799\tvalid-gini:0.207655\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-gini:0.246897\tvalid-gini:0.240157\n",
      "[200]\ttrain-gini:0.275545\tvalid-gini:0.257312\n",
      "[300]\ttrain-gini:0.29678\tvalid-gini:0.269755\n",
      "[400]\ttrain-gini:0.310673\tvalid-gini:0.276489\n",
      "[500]\ttrain-gini:0.320901\tvalid-gini:0.278977\n",
      "[600]\ttrain-gini:0.329141\tvalid-gini:0.280097\n",
      "[700]\ttrain-gini:0.336405\tvalid-gini:0.280587\n",
      "[800]\ttrain-gini:0.343045\tvalid-gini:0.280984\n",
      "Stopping. Best iteration:\n",
      "[771]\ttrain-gini:0.341095\tvalid-gini:0.281079\n",
      "\n",
      " xgb kfold: 2  of  5 : \n",
      "[0]\ttrain-gini:0.198356\tvalid-gini:0.192375\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-gini:0.24577\tvalid-gini:0.236371\n",
      "[200]\ttrain-gini:0.275215\tvalid-gini:0.258596\n",
      "[300]\ttrain-gini:0.296048\tvalid-gini:0.272702\n",
      "[400]\ttrain-gini:0.31036\tvalid-gini:0.279561\n",
      "[500]\ttrain-gini:0.32114\tvalid-gini:0.283797\n",
      "[600]\ttrain-gini:0.329687\tvalid-gini:0.285912\n",
      "[700]\ttrain-gini:0.337354\tvalid-gini:0.287243\n",
      "[800]\ttrain-gini:0.344323\tvalid-gini:0.287973\n",
      "[900]\ttrain-gini:0.35077\tvalid-gini:0.288352\n",
      "[1000]\ttrain-gini:0.356924\tvalid-gini:0.288808\n",
      "[1100]\ttrain-gini:0.362878\tvalid-gini:0.289027\n",
      "Stopping. Best iteration:\n",
      "[1048]\ttrain-gini:0.359909\tvalid-gini:0.289092\n",
      "\n",
      " xgb kfold: 3  of  5 : \n",
      "[0]\ttrain-gini:0.200545\tvalid-gini:0.198622\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-gini:0.247332\tvalid-gini:0.23636\n",
      "[200]\ttrain-gini:0.277516\tvalid-gini:0.257322\n",
      "[300]\ttrain-gini:0.296926\tvalid-gini:0.268403\n",
      "[400]\ttrain-gini:0.310743\tvalid-gini:0.275201\n",
      "[500]\ttrain-gini:0.321514\tvalid-gini:0.278785\n",
      "[600]\ttrain-gini:0.330365\tvalid-gini:0.280344\n",
      "[700]\ttrain-gini:0.337994\tvalid-gini:0.28122\n",
      "[800]\ttrain-gini:0.34449\tvalid-gini:0.281854\n",
      "[900]\ttrain-gini:0.350971\tvalid-gini:0.281799\n",
      "Stopping. Best iteration:\n",
      "[837]\ttrain-gini:0.346793\tvalid-gini:0.282116\n",
      "\n",
      " xgb kfold: 4  of  5 : \n",
      "[0]\ttrain-gini:0.202689\tvalid-gini:0.188857\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-gini:0.244913\tvalid-gini:0.229628\n",
      "[200]\ttrain-gini:0.273604\tvalid-gini:0.25641\n",
      "[300]\ttrain-gini:0.29431\tvalid-gini:0.27303\n",
      "[400]\ttrain-gini:0.308443\tvalid-gini:0.281004\n",
      "[500]\ttrain-gini:0.31903\tvalid-gini:0.285223\n",
      "[600]\ttrain-gini:0.327534\tvalid-gini:0.287751\n",
      "[700]\ttrain-gini:0.334278\tvalid-gini:0.28884\n",
      "[800]\ttrain-gini:0.340869\tvalid-gini:0.289622\n",
      "[900]\ttrain-gini:0.347494\tvalid-gini:0.289535\n",
      "Stopping. Best iteration:\n",
      "[800]\ttrain-gini:0.340869\tvalid-gini:0.289622\n",
      "\n",
      " xgb kfold: 5  of  5 : \n",
      "[0]\ttrain-gini:0.197274\tvalid-gini:0.184964\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 100 rounds.\n",
      "[100]\ttrain-gini:0.250455\tvalid-gini:0.236182\n",
      "[200]\ttrain-gini:0.277817\tvalid-gini:0.253042\n",
      "[300]\ttrain-gini:0.299169\tvalid-gini:0.264445\n",
      "[400]\ttrain-gini:0.312651\tvalid-gini:0.269982\n",
      "[500]\ttrain-gini:0.322889\tvalid-gini:0.272654\n",
      "[600]\ttrain-gini:0.330796\tvalid-gini:0.273829\n",
      "[700]\ttrain-gini:0.337801\tvalid-gini:0.274321\n",
      "[800]\ttrain-gini:0.344723\tvalid-gini:0.275069\n",
      "[900]\ttrain-gini:0.35063\tvalid-gini:0.275662\n",
      "[1000]\ttrain-gini:0.356721\tvalid-gini:0.27593\n",
      "[1100]\ttrain-gini:0.362201\tvalid-gini:0.276318\n",
      "[1200]\ttrain-gini:0.367729\tvalid-gini:0.276557\n",
      "Stopping. Best iteration:\n",
      "[1188]\ttrain-gini:0.367162\tvalid-gini:0.276652\n",
      "\n",
      " lgb kfold: 1  of  5 : \n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.626011\tvalid_0's gini: 0.252021\n",
      "[200]\tvalid_0's auc: 0.62734\tvalid_0's gini: 0.254681\n",
      "[300]\tvalid_0's auc: 0.630215\tvalid_0's gini: 0.26043\n",
      "[400]\tvalid_0's auc: 0.633273\tvalid_0's gini: 0.266546\n",
      "[500]\tvalid_0's auc: 0.636406\tvalid_0's gini: 0.272813\n",
      "[600]\tvalid_0's auc: 0.638351\tvalid_0's gini: 0.276701\n",
      "[700]\tvalid_0's auc: 0.639459\tvalid_0's gini: 0.278918\n",
      "[800]\tvalid_0's auc: 0.640385\tvalid_0's gini: 0.280769\n",
      "[900]\tvalid_0's auc: 0.640713\tvalid_0's gini: 0.281426\n",
      "[1000]\tvalid_0's auc: 0.641134\tvalid_0's gini: 0.282267\n",
      "[1100]\tvalid_0's auc: 0.641154\tvalid_0's gini: 0.282308\n",
      "[1200]\tvalid_0's auc: 0.64135\tvalid_0's gini: 0.282699\n",
      "Early stopping, best iteration is:\n",
      "[1175]\tvalid_0's auc: 0.641425\tvalid_0's gini: 0.28285\n",
      " lgb kfold: 2  of  5 : \n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.625642\tvalid_0's gini: 0.251285\n",
      "[200]\tvalid_0's auc: 0.627719\tvalid_0's gini: 0.255437\n",
      "[300]\tvalid_0's auc: 0.630554\tvalid_0's gini: 0.261108\n",
      "[400]\tvalid_0's auc: 0.635109\tvalid_0's gini: 0.270217\n",
      "[500]\tvalid_0's auc: 0.638003\tvalid_0's gini: 0.276006\n",
      "[600]\tvalid_0's auc: 0.640499\tvalid_0's gini: 0.280997\n",
      "[700]\tvalid_0's auc: 0.642247\tvalid_0's gini: 0.284494\n",
      "[800]\tvalid_0's auc: 0.642808\tvalid_0's gini: 0.285616\n",
      "[900]\tvalid_0's auc: 0.643377\tvalid_0's gini: 0.286754\n",
      "[1000]\tvalid_0's auc: 0.643697\tvalid_0's gini: 0.287395\n",
      "[1100]\tvalid_0's auc: 0.643938\tvalid_0's gini: 0.287876\n",
      "[1200]\tvalid_0's auc: 0.644144\tvalid_0's gini: 0.288287\n",
      "[1300]\tvalid_0's auc: 0.644345\tvalid_0's gini: 0.288689\n",
      "[1400]\tvalid_0's auc: 0.644338\tvalid_0's gini: 0.288676\n",
      "Early stopping, best iteration is:\n",
      "[1308]\tvalid_0's auc: 0.644389\tvalid_0's gini: 0.288777\n",
      " lgb kfold: 3  of  5 : \n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.623474\tvalid_0's gini: 0.246948\n",
      "[200]\tvalid_0's auc: 0.6257\tvalid_0's gini: 0.251399\n",
      "[300]\tvalid_0's auc: 0.629008\tvalid_0's gini: 0.258015\n",
      "[400]\tvalid_0's auc: 0.63255\tvalid_0's gini: 0.265099\n",
      "[500]\tvalid_0's auc: 0.635755\tvalid_0's gini: 0.27151\n",
      "[600]\tvalid_0's auc: 0.638344\tvalid_0's gini: 0.276688\n",
      "[700]\tvalid_0's auc: 0.639833\tvalid_0's gini: 0.279666\n",
      "[800]\tvalid_0's auc: 0.640759\tvalid_0's gini: 0.281517\n",
      "[900]\tvalid_0's auc: 0.640963\tvalid_0's gini: 0.281926\n",
      "[1000]\tvalid_0's auc: 0.640874\tvalid_0's gini: 0.281748\n",
      "Early stopping, best iteration is:\n",
      "[903]\tvalid_0's auc: 0.640974\tvalid_0's gini: 0.281949\n",
      " lgb kfold: 4  of  5 : \n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.623858\tvalid_0's gini: 0.247715\n",
      "[200]\tvalid_0's auc: 0.626575\tvalid_0's gini: 0.253151\n",
      "[300]\tvalid_0's auc: 0.629667\tvalid_0's gini: 0.259333\n",
      "[400]\tvalid_0's auc: 0.634474\tvalid_0's gini: 0.268948\n",
      "[500]\tvalid_0's auc: 0.638738\tvalid_0's gini: 0.277475\n",
      "[600]\tvalid_0's auc: 0.64153\tvalid_0's gini: 0.283059\n",
      "[700]\tvalid_0's auc: 0.643578\tvalid_0's gini: 0.287157\n",
      "[800]\tvalid_0's auc: 0.644564\tvalid_0's gini: 0.289128\n",
      "[900]\tvalid_0's auc: 0.645251\tvalid_0's gini: 0.290502\n",
      "[1000]\tvalid_0's auc: 0.645639\tvalid_0's gini: 0.291277\n",
      "[1100]\tvalid_0's auc: 0.645861\tvalid_0's gini: 0.291722\n",
      "[1200]\tvalid_0's auc: 0.646085\tvalid_0's gini: 0.292171\n",
      "[1300]\tvalid_0's auc: 0.646202\tvalid_0's gini: 0.292403\n",
      "[1400]\tvalid_0's auc: 0.646012\tvalid_0's gini: 0.292024\n",
      "Early stopping, best iteration is:\n",
      "[1303]\tvalid_0's auc: 0.646217\tvalid_0's gini: 0.292434\n",
      " lgb kfold: 5  of  5 : \n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's auc: 0.623122\tvalid_0's gini: 0.246246\n",
      "[200]\tvalid_0's auc: 0.625663\tvalid_0's gini: 0.251325\n",
      "[300]\tvalid_0's auc: 0.627953\tvalid_0's gini: 0.255907\n",
      "[400]\tvalid_0's auc: 0.630813\tvalid_0's gini: 0.261626\n",
      "[500]\tvalid_0's auc: 0.63352\tvalid_0's gini: 0.267039\n",
      "[600]\tvalid_0's auc: 0.635694\tvalid_0's gini: 0.271388\n",
      "[700]\tvalid_0's auc: 0.637136\tvalid_0's gini: 0.274272\n",
      "[800]\tvalid_0's auc: 0.637901\tvalid_0's gini: 0.275802\n",
      "[900]\tvalid_0's auc: 0.638385\tvalid_0's gini: 0.276769\n",
      "[1000]\tvalid_0's auc: 0.638567\tvalid_0's gini: 0.277133\n",
      "[1100]\tvalid_0's auc: 0.638367\tvalid_0's gini: 0.276734\n",
      "Early stopping, best iteration is:\n",
      "[1019]\tvalid_0's auc: 0.638591\tvalid_0's gini: 0.277182\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.024816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.027369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    target\n",
       "0   0  0.024816\n",
       "1   1  0.027369"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import gc\n",
    "\n",
    "print('loading files...')\n",
    "train = pd.read_csv(base_path+'train_p.csv', na_values=-1)\n",
    "test = pd.read_csv(base_path+'test_p.csv', na_values=-1)\n",
    "col_to_drop = train.columns[train.columns.str.startswith('ps_calc_')]\n",
    "train = train.drop(col_to_drop, axis=1)  \n",
    "test = test.drop(col_to_drop, axis=1)  \n",
    "\n",
    "for c in train.select_dtypes(include=['float64']).columns:\n",
    "    train[c]=train[c].astype(np.float32)\n",
    "    test[c]=test[c].astype(np.float32)\n",
    "for c in train.select_dtypes(include=['int64']).columns[2:]:\n",
    "    train[c]=train[c].astype(np.int8)\n",
    "    test[c]=test[c].astype(np.int8)    \n",
    "\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "# custom objective function (similar to auc)\n",
    "\n",
    "def gini(y, pred):\n",
    "    g = np.asarray(np.c_[y, pred, np.arange(len(y)) ], dtype=np.float)\n",
    "    g = g[np.lexsort((g[:,2], -1*g[:,1]))]\n",
    "    gs = g[:,0].cumsum().sum() / g[:,0].sum()\n",
    "    gs -= (len(y) + 1) / 2.\n",
    "    return gs / len(y)\n",
    "\n",
    "def gini_xgb(pred, y):\n",
    "    y = y.get_label()\n",
    "    return 'gini', gini(y, pred) / gini(y, y)\n",
    "\n",
    "def gini_lgb(preds, dtrain):\n",
    "    y = list(dtrain.get_label())\n",
    "    score = gini(y, preds) / gini(y, y)\n",
    "    return 'gini', score, True\n",
    "\n",
    "# xgb\n",
    "params = {'eta': 0.02, 'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, \n",
    "          'objective': 'binary:logistic', 'eval_metric': 'auc', 'silent': True}\n",
    "\n",
    "X = train.drop(['id', 'target'], axis=1)\n",
    "features = X.columns\n",
    "X = X.values\n",
    "y = train['target'].values\n",
    "sub=test['id'].to_frame()\n",
    "sub['target']=0\n",
    "\n",
    "sub_train = train['id'].to_frame()\n",
    "sub_train['target']=0\n",
    "\n",
    "nrounds=10**6  # need to change to 2000\n",
    "kfold = 5  # need to change to 5\n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=0)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(' xgb kfold: {}  of  {} : '.format(i+1, kfold))\n",
    "    X_train, X_valid = X[train_index], X[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    d_train = xgb.DMatrix(X_train, y_train) \n",
    "    d_valid = xgb.DMatrix(X_valid, y_valid) \n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    xgb_model = xgb.train(params, d_train, nrounds, watchlist, early_stopping_rounds=100, \n",
    "                          feval=gini_xgb, maximize=True, verbose_eval=100)\n",
    "    sub['target'] += xgb_model.predict(xgb.DMatrix(test[features].values), \n",
    "                        ntree_limit=xgb_model.best_ntree_limit+50) / (kfold)\n",
    "    \n",
    "    sub_train['target'] += xgb_model.predict(xgb.DMatrix(train[features].values), \n",
    "                        ntree_limit=xgb_model.best_ntree_limit+50) / (kfold)\n",
    "    \n",
    "gc.collect()\n",
    "sub.head(2)\n",
    "\n",
    "sub.to_csv(base_path+'test_sub_xgb.csv', index=False, float_format='%.5f')\n",
    "sub_train.to_csv(base_path+'train_sub_xgb.csv', index=False, float_format='%.5f')\n",
    "\n",
    "\n",
    "# lgb\n",
    "sub['target']=0\n",
    "sub_train['target']=0\n",
    "\n",
    "params = {'metric': 'auc', 'learning_rate' : 0.01, 'max_depth':8, 'max_bin':10,  'objective': 'binary', \n",
    "          'feature_fraction': 0.8,'bagging_fraction':0.9,'bagging_freq':5,  'min_data': 500}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=1)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(' lgb kfold: {}  of  {} : '.format(i+1, kfold))\n",
    "    X_train, X_eval = X[train_index], X[test_index]\n",
    "    y_train, y_eval = y[train_index], y[test_index]\n",
    "    lgb_model = lgb.train(params, lgb.Dataset(X_train, label=y_train), nrounds, \n",
    "                  lgb.Dataset(X_eval, label=y_eval), verbose_eval=100, \n",
    "                  feval=gini_lgb, early_stopping_rounds=100)\n",
    "    sub['target'] += lgb_model.predict(test[features].values, \n",
    "                        num_iteration=lgb_model.best_iteration) / (kfold)\n",
    "    sub_train['target'] += lgb_model.predict(train[features].values, \n",
    "                        num_iteration=lgb_model.best_iteration) / (kfold)\n",
    "    \n",
    "sub.to_csv(base_path+'test_sub_lgb.csv', index=False, float_format='%.5f') \n",
    "sub_train.to_csv(base_path+'train_sub_lgb.csv', index=False, float_format='%.5f')\n",
    "\n",
    "gc.collect()\n",
    "sub.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "32\n",
      "(446409, 136) (148803, 136)\n",
      "Borders for float features generated\n",
      "0:\tlearn 0.5667875974\ttest 0.5683331273\tbestTest 0.5683331273\t\ttotal: 1.31s\tremaining: 26m 6s\n",
      "1:\tlearn 0.5881921875\ttest 0.5872694273\tbestTest 0.5872694273\t\ttotal: 2.65s\tremaining: 26m 28s\n",
      "2:\tlearn 0.597508791\ttest 0.5972637307\tbestTest 0.5972637307\t\ttotal: 3.86s\tremaining: 25m 41s\n",
      "3:\tlearn 0.6002220266\ttest 0.5989313579\tbestTest 0.5989313579\t\ttotal: 5.22s\tremaining: 26m 1s\n",
      "4:\tlearn 0.6015715897\ttest 0.599143837\tbestTest 0.599143837\t\ttotal: 6.75s\tremaining: 26m 53s\n",
      "5:\tlearn 0.60544167\ttest 0.6017176914\tbestTest 0.6017176914\t\ttotal: 8.19s\tremaining: 27m 10s\n",
      "6:\tlearn 0.610625581\ttest 0.6067543792\tbestTest 0.6067543792\t\ttotal: 9.54s\tremaining: 27m 5s\n",
      "7:\tlearn 0.6154705192\ttest 0.6114803142\tbestTest 0.6114803142\t\ttotal: 10.9s\tremaining: 27m 5s\n",
      "8:\tlearn 0.6156096948\ttest 0.6120950395\tbestTest 0.6120950395\t\ttotal: 12s\tremaining: 26m 29s\n",
      "9:\tlearn 0.6197561479\ttest 0.6165373276\tbestTest 0.6165373276\t\ttotal: 13.4s\tremaining: 26m 29s\n",
      "10:\tlearn 0.6207843323\ttest 0.6168289326\tbestTest 0.6168289326\t\ttotal: 14.7s\tremaining: 26m 31s\n",
      "11:\tlearn 0.6194328458\ttest 0.6154728847\tbestTest 0.6168289326\t\ttotal: 16.1s\tremaining: 26m 35s\n",
      "12:\tlearn 0.6202662349\ttest 0.6167448147\tbestTest 0.6168289326\t\ttotal: 17.5s\tremaining: 26m 39s\n",
      "13:\tlearn 0.6211716307\ttest 0.6173462877\tbestTest 0.6173462877\t\ttotal: 18.9s\tremaining: 26m 38s\n",
      "14:\tlearn 0.6211911252\ttest 0.6174962165\tbestTest 0.6174962165\t\ttotal: 20.2s\tremaining: 26m 37s\n",
      "15:\tlearn 0.622322697\ttest 0.6180517357\tbestTest 0.6180517357\t\ttotal: 21.6s\tremaining: 26m 39s\n",
      "16:\tlearn 0.6222718317\ttest 0.6178862593\tbestTest 0.6180517357\t\ttotal: 23.1s\tremaining: 26m 45s\n",
      "17:\tlearn 0.6235956888\ttest 0.6193753815\tbestTest 0.6193753815\t\ttotal: 24.3s\tremaining: 26m 34s\n",
      "18:\tlearn 0.6234851883\ttest 0.6185899966\tbestTest 0.6193753815\t\ttotal: 25.6s\tremaining: 26m 33s\n",
      "19:\tlearn 0.6240095465\ttest 0.6190096568\tbestTest 0.6193753815\t\ttotal: 27s\tremaining: 26m 32s\n",
      "20:\tlearn 0.6250438087\ttest 0.6197756429\tbestTest 0.6197756429\t\ttotal: 28.3s\tremaining: 26m 31s\n",
      "21:\tlearn 0.6247048608\ttest 0.6195435338\tbestTest 0.6197756429\t\ttotal: 29.7s\tremaining: 26m 32s\n",
      "22:\tlearn 0.6251868952\ttest 0.619870231\tbestTest 0.619870231\t\ttotal: 31.1s\tremaining: 26m 32s\n",
      "23:\tlearn 0.6245769608\ttest 0.6188554031\tbestTest 0.619870231\t\ttotal: 32.6s\tremaining: 26m 35s\n",
      "24:\tlearn 0.6246969031\ttest 0.6189176526\tbestTest 0.619870231\t\ttotal: 34s\tremaining: 26m 36s\n",
      "25:\tlearn 0.6248911829\ttest 0.618906426\tbestTest 0.619870231\t\ttotal: 35.4s\tremaining: 26m 38s\n",
      "26:\tlearn 0.6262727299\ttest 0.6201557077\tbestTest 0.6201557077\t\ttotal: 36.8s\tremaining: 26m 40s\n",
      "27:\tlearn 0.6265785764\ttest 0.6205906017\tbestTest 0.6205906017\t\ttotal: 38.2s\tremaining: 26m 40s\n",
      "28:\tlearn 0.6266521077\ttest 0.6203601727\tbestTest 0.6205906017\t\ttotal: 39.6s\tremaining: 26m 38s\n",
      "29:\tlearn 0.6266438747\ttest 0.6203213571\tbestTest 0.6205906017\t\ttotal: 41s\tremaining: 26m 38s\n",
      "30:\tlearn 0.6264818319\ttest 0.6198710808\tbestTest 0.6205906017\t\ttotal: 42.2s\tremaining: 26m 33s\n",
      "31:\tlearn 0.6262716274\ttest 0.6201008071\tbestTest 0.6205906017\t\ttotal: 43.6s\tremaining: 26m 33s\n",
      "32:\tlearn 0.6262849817\ttest 0.620089563\tbestTest 0.6205906017\t\ttotal: 44.6s\tremaining: 26m 16s\n",
      "33:\tlearn 0.6256507579\ttest 0.6196154891\tbestTest 0.6205906017\t\ttotal: 45.8s\tremaining: 26m 11s\n",
      "34:\tlearn 0.625978815\ttest 0.6196081668\tbestTest 0.6205906017\t\ttotal: 47.2s\tremaining: 26m 11s\n",
      "35:\tlearn 0.6259950803\ttest 0.6197769096\tbestTest 0.6205906017\t\ttotal: 48.5s\tremaining: 26m 7s\n",
      "36:\tlearn 0.6258109031\ttest 0.6193871902\tbestTest 0.6205906017\t\ttotal: 49.9s\tremaining: 26m 8s\n",
      "37:\tlearn 0.6257811638\ttest 0.6195453261\tbestTest 0.6205906017\t\ttotal: 51.3s\tremaining: 26m 7s\n",
      "38:\tlearn 0.6255084196\ttest 0.6194792463\tbestTest 0.6205906017\t\ttotal: 52.1s\tremaining: 25m 52s\n",
      "39:\tlearn 0.6257218828\ttest 0.61960154\tbestTest 0.6205906017\t\ttotal: 53.5s\tremaining: 25m 51s\n",
      "40:\tlearn 0.6256851284\ttest 0.6198085966\tbestTest 0.6205906017\t\ttotal: 54.4s\tremaining: 25m 38s\n",
      "41:\tlearn 0.6267677522\ttest 0.6207738919\tbestTest 0.6207738919\t\ttotal: 55.8s\tremaining: 25m 38s\n",
      "42:\tlearn 0.62672633\ttest 0.620650445\tbestTest 0.6207738919\t\ttotal: 57.2s\tremaining: 25m 40s\n",
      "43:\tlearn 0.6266475981\ttest 0.6206318889\tbestTest 0.6207738919\t\ttotal: 58.1s\tremaining: 25m 26s\n",
      "44:\tlearn 0.6268082046\ttest 0.6210223259\tbestTest 0.6210223259\t\ttotal: 59.5s\tremaining: 25m 25s\n",
      "45:\tlearn 0.6269058093\ttest 0.6212887338\tbestTest 0.6212887338\t\ttotal: 1m\tremaining: 25m 22s\n",
      "46:\tlearn 0.6271627143\ttest 0.6216019214\tbestTest 0.6216019214\t\ttotal: 1m 2s\tremaining: 25m 24s\n",
      "47:\tlearn 0.626884478\ttest 0.6212869979\tbestTest 0.6216019214\t\ttotal: 1m 3s\tremaining: 25m 27s\n",
      "48:\tlearn 0.6274289306\ttest 0.6216595238\tbestTest 0.6216595238\t\ttotal: 1m 5s\tremaining: 25m 35s\n",
      "49:\tlearn 0.6272301655\ttest 0.621520305\tbestTest 0.6216595238\t\ttotal: 1m 6s\tremaining: 25m 35s\n",
      "50:\tlearn 0.6274581931\ttest 0.6219005519\tbestTest 0.6219005519\t\ttotal: 1m 8s\tremaining: 25m 38s\n",
      "51:\tlearn 0.6275821591\ttest 0.6224973985\tbestTest 0.6224973985\t\ttotal: 1m 9s\tremaining: 25m 37s\n",
      "52:\tlearn 0.6276466485\ttest 0.6225954092\tbestTest 0.6225954092\t\ttotal: 1m 11s\tremaining: 25m 38s\n",
      "53:\tlearn 0.6276727706\ttest 0.6225945807\tbestTest 0.6225954092\t\ttotal: 1m 12s\tremaining: 25m 29s\n",
      "54:\tlearn 0.6275570081\ttest 0.6224029784\tbestTest 0.6225954092\t\ttotal: 1m 13s\tremaining: 25m 33s\n",
      "55:\tlearn 0.6275540929\ttest 0.6223976377\tbestTest 0.6225954092\t\ttotal: 1m 15s\tremaining: 25m 36s\n",
      "56:\tlearn 0.627540455\ttest 0.6226229509\tbestTest 0.6226229509\t\ttotal: 1m 16s\tremaining: 25m 36s\n",
      "57:\tlearn 0.627756478\ttest 0.622686981\tbestTest 0.622686981\t\ttotal: 1m 18s\tremaining: 25m 38s\n",
      "58:\tlearn 0.6277682389\ttest 0.6226727707\tbestTest 0.622686981\t\ttotal: 1m 19s\tremaining: 25m 29s\n",
      "59:\tlearn 0.6278004312\ttest 0.6227059234\tbestTest 0.6227059234\t\ttotal: 1m 20s\tremaining: 25m 23s\n",
      "60:\tlearn 0.6276533376\ttest 0.6226214314\tbestTest 0.6227059234\t\ttotal: 1m 21s\tremaining: 25m 21s\n",
      "61:\tlearn 0.627626734\ttest 0.6225552103\tbestTest 0.6227059234\t\ttotal: 1m 22s\tremaining: 25m 20s\n",
      "62:\tlearn 0.6276868012\ttest 0.6226838631\tbestTest 0.6227059234\t\ttotal: 1m 24s\tremaining: 25m 22s\n",
      "63:\tlearn 0.6275787518\ttest 0.6226309136\tbestTest 0.6227059234\t\ttotal: 1m 25s\tremaining: 25m 22s\n",
      "64:\tlearn 0.628202739\ttest 0.6230033391\tbestTest 0.6230033391\t\ttotal: 1m 27s\tremaining: 25m 24s\n",
      "65:\tlearn 0.6284446144\ttest 0.6233006102\tbestTest 0.6233006102\t\ttotal: 1m 28s\tremaining: 25m 26s\n",
      "66:\tlearn 0.6285336031\ttest 0.6233341505\tbestTest 0.6233341505\t\ttotal: 1m 30s\tremaining: 25m 22s\n",
      "67:\tlearn 0.6287092287\ttest 0.6235641789\tbestTest 0.6235641789\t\ttotal: 1m 31s\tremaining: 25m 20s\n",
      "68:\tlearn 0.6289950997\ttest 0.6236655208\tbestTest 0.6236655208\t\ttotal: 1m 32s\tremaining: 25m 19s\n",
      "69:\tlearn 0.6292479016\ttest 0.6240209362\tbestTest 0.6240209362\t\ttotal: 1m 34s\tremaining: 25m 17s\n",
      "70:\tlearn 0.6290363261\ttest 0.6238634219\tbestTest 0.6240209362\t\ttotal: 1m 35s\tremaining: 25m 12s\n",
      "71:\tlearn 0.6290654316\ttest 0.6238905189\tbestTest 0.6240209362\t\ttotal: 1m 36s\tremaining: 25m 12s\n",
      "72:\tlearn 0.6289891654\ttest 0.6236650644\tbestTest 0.6240209362\t\ttotal: 1m 37s\tremaining: 25m 11s\n",
      "73:\tlearn 0.6290059768\ttest 0.6236917647\tbestTest 0.6240209362\t\ttotal: 1m 39s\tremaining: 25m 10s\n",
      "74:\tlearn 0.628982076\ttest 0.6237699922\tbestTest 0.6240209362\t\ttotal: 1m 40s\tremaining: 25m 5s\n",
      "75:\tlearn 0.6291786973\ttest 0.6239020949\tbestTest 0.6240209362\t\ttotal: 1m 41s\tremaining: 25m 5s\n",
      "76:\tlearn 0.6290823671\ttest 0.6237670013\tbestTest 0.6240209362\t\ttotal: 1m 43s\tremaining: 25m 3s\n",
      "77:\tlearn 0.6289686616\ttest 0.6237859904\tbestTest 0.6240209362\t\ttotal: 1m 44s\tremaining: 25m 3s\n",
      "78:\tlearn 0.6288704892\ttest 0.6237173202\tbestTest 0.6240209362\t\ttotal: 1m 45s\tremaining: 24m 57s\n",
      "79:\tlearn 0.6289026148\ttest 0.6237167874\tbestTest 0.6240209362\t\ttotal: 1m 46s\tremaining: 24m 56s\n",
      "80:\tlearn 0.6292501129\ttest 0.6241527834\tbestTest 0.6241527834\t\ttotal: 1m 48s\tremaining: 24m 58s\n",
      "81:\tlearn 0.6294138464\ttest 0.6241804275\tbestTest 0.6241804275\t\ttotal: 1m 50s\tremaining: 25m 1s\n",
      "82:\tlearn 0.6294249077\ttest 0.6242301216\tbestTest 0.6242301216\t\ttotal: 1m 51s\tremaining: 25m 1s\n",
      "83:\tlearn 0.6297061651\ttest 0.6242867516\tbestTest 0.6242867516\t\ttotal: 1m 53s\tremaining: 25m 1s\n",
      "84:\tlearn 0.6296789039\ttest 0.6242499566\tbestTest 0.6242867516\t\ttotal: 1m 54s\tremaining: 25m 2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85:\tlearn 0.6297687489\ttest 0.6242778133\tbestTest 0.6242867516\t\ttotal: 1m 55s\tremaining: 24m 58s\n",
      "86:\tlearn 0.6300750147\ttest 0.624640682\tbestTest 0.624640682\t\ttotal: 1m 57s\tremaining: 24m 59s\n",
      "87:\tlearn 0.6301831106\ttest 0.6247233395\tbestTest 0.6247233395\t\ttotal: 1m 58s\tremaining: 24m 58s\n",
      "88:\tlearn 0.6302458951\ttest 0.6246841803\tbestTest 0.6247233395\t\ttotal: 2m\tremaining: 24m 58s\n",
      "89:\tlearn 0.630453703\ttest 0.6247504365\tbestTest 0.6247504365\t\ttotal: 2m 1s\tremaining: 24m 57s\n",
      "90:\tlearn 0.6303485665\ttest 0.6246547938\tbestTest 0.6247504365\t\ttotal: 2m 2s\tremaining: 24m 56s\n",
      "91:\tlearn 0.6303926294\ttest 0.6247328502\tbestTest 0.6247504365\t\ttotal: 2m 4s\tremaining: 24m 56s\n",
      "92:\tlearn 0.6307363355\ttest 0.6250978891\tbestTest 0.6250978891\t\ttotal: 2m 5s\tremaining: 24m 55s\n",
      "93:\tlearn 0.6307424936\ttest 0.6251101185\tbestTest 0.6251101185\t\ttotal: 2m 7s\tremaining: 24m 54s\n",
      "94:\tlearn 0.630742502\ttest 0.6250741317\tbestTest 0.6251101185\t\ttotal: 2m 8s\tremaining: 24m 52s\n",
      "95:\tlearn 0.6311150584\ttest 0.6254170792\tbestTest 0.6254170792\t\ttotal: 2m 9s\tremaining: 24m 51s\n",
      "96:\tlearn 0.6313508181\ttest 0.625779428\tbestTest 0.625779428\t\ttotal: 2m 11s\tremaining: 24m 50s\n",
      "97:\tlearn 0.6313482652\ttest 0.6257112052\tbestTest 0.625779428\t\ttotal: 2m 12s\tremaining: 24m 50s\n",
      "98:\tlearn 0.6313256031\ttest 0.625665873\tbestTest 0.625779428\t\ttotal: 2m 13s\tremaining: 24m 49s\n",
      "99:\tlearn 0.6313516\ttest 0.625694634\tbestTest 0.625779428\t\ttotal: 2m 15s\tremaining: 24m 46s\n",
      "100:\tlearn 0.6316198409\ttest 0.6260826213\tbestTest 0.6260826213\t\ttotal: 2m 16s\tremaining: 24m 44s\n",
      "101:\tlearn 0.6316000587\ttest 0.626062411\tbestTest 0.6260826213\t\ttotal: 2m 17s\tremaining: 24m 43s\n",
      "102:\tlearn 0.6316396621\ttest 0.6260758539\tbestTest 0.6260826213\t\ttotal: 2m 19s\tremaining: 24m 42s\n",
      "103:\tlearn 0.63174649\ttest 0.6261735618\tbestTest 0.6261735618\t\ttotal: 2m 20s\tremaining: 24m 42s\n",
      "104:\tlearn 0.6316560138\ttest 0.626141174\tbestTest 0.6261735618\t\ttotal: 2m 22s\tremaining: 24m 42s\n",
      "105:\tlearn 0.631803939\ttest 0.6262607063\tbestTest 0.6262607063\t\ttotal: 2m 23s\tremaining: 24m 42s\n",
      "106:\tlearn 0.6318307919\ttest 0.6262641328\tbestTest 0.6262641328\t\ttotal: 2m 25s\tremaining: 24m 41s\n",
      "107:\tlearn 0.6318633229\ttest 0.6264086295\tbestTest 0.6264086295\t\ttotal: 2m 26s\tremaining: 24m 40s\n",
      "108:\tlearn 0.6321113373\ttest 0.6265917809\tbestTest 0.6265917809\t\ttotal: 2m 27s\tremaining: 24m 38s\n",
      "109:\tlearn 0.6322627527\ttest 0.6267413493\tbestTest 0.6267413493\t\ttotal: 2m 29s\tremaining: 24m 37s\n",
      "110:\tlearn 0.6324216405\ttest 0.6268013955\tbestTest 0.6268013955\t\ttotal: 2m 30s\tremaining: 24m 37s\n",
      "111:\tlearn 0.6324495922\ttest 0.6267953709\tbestTest 0.6268013955\t\ttotal: 2m 32s\tremaining: 24m 37s\n",
      "112:\tlearn 0.6324570862\ttest 0.6267961941\tbestTest 0.6268013955\t\ttotal: 2m 33s\tremaining: 24m 35s\n",
      "113:\tlearn 0.6324993085\ttest 0.6268888757\tbestTest 0.6268888757\t\ttotal: 2m 34s\tremaining: 24m 34s\n",
      "114:\tlearn 0.6325231287\ttest 0.6269590433\tbestTest 0.6269590433\t\ttotal: 2m 36s\tremaining: 24m 32s\n",
      "115:\tlearn 0.6325580866\ttest 0.6269778054\tbestTest 0.6269778054\t\ttotal: 2m 37s\tremaining: 24m 27s\n",
      "116:\tlearn 0.6325125041\ttest 0.6269278326\tbestTest 0.6269778054\t\ttotal: 2m 38s\tremaining: 24m 25s\n",
      "117:\tlearn 0.6327026653\ttest 0.6271182157\tbestTest 0.6271182157\t\ttotal: 2m 39s\tremaining: 24m 23s\n",
      "118:\tlearn 0.6327801265\ttest 0.6271670632\tbestTest 0.6271670632\t\ttotal: 2m 41s\tremaining: 24m 22s\n",
      "119:\tlearn 0.6327406017\ttest 0.6270996\tbestTest 0.6271670632\t\ttotal: 2m 42s\tremaining: 24m 21s\n",
      "120:\tlearn 0.6329203664\ttest 0.6272397108\tbestTest 0.6272397108\t\ttotal: 2m 43s\tremaining: 24m 20s\n",
      "121:\tlearn 0.6330167458\ttest 0.6273425514\tbestTest 0.6273425514\t\ttotal: 2m 45s\tremaining: 24m 19s\n",
      "122:\tlearn 0.6332174959\ttest 0.6275215296\tbestTest 0.6275215296\t\ttotal: 2m 46s\tremaining: 24m 18s\n",
      "123:\tlearn 0.6332685121\ttest 0.6276503289\tbestTest 0.6276503289\t\ttotal: 2m 48s\tremaining: 24m 18s\n",
      "124:\tlearn 0.6333059503\ttest 0.6277042934\tbestTest 0.6277042934\t\ttotal: 2m 49s\tremaining: 24m 17s\n",
      "125:\tlearn 0.6333176855\ttest 0.6276642177\tbestTest 0.6277042934\t\ttotal: 2m 50s\tremaining: 24m 14s\n",
      "126:\tlearn 0.6333289449\ttest 0.6276947646\tbestTest 0.6277042934\t\ttotal: 2m 51s\tremaining: 24m 12s\n",
      "127:\tlearn 0.6334232989\ttest 0.6277639857\tbestTest 0.6277639857\t\ttotal: 2m 53s\tremaining: 24m 11s\n",
      "128:\tlearn 0.6335478214\ttest 0.6278663621\tbestTest 0.6278663621\t\ttotal: 2m 54s\tremaining: 24m 10s\n",
      "129:\tlearn 0.6335389021\ttest 0.6278956242\tbestTest 0.6278956242\t\ttotal: 2m 56s\tremaining: 24m 8s\n",
      "130:\tlearn 0.6337540947\ttest 0.6281122849\tbestTest 0.6281122849\t\ttotal: 2m 57s\tremaining: 24m 8s\n",
      "131:\tlearn 0.6337722613\ttest 0.6281697032\tbestTest 0.6281697032\t\ttotal: 2m 58s\tremaining: 24m 8s\n",
      "132:\tlearn 0.6339899114\ttest 0.6282732335\tbestTest 0.6282732335\t\ttotal: 3m\tremaining: 24m 6s\n",
      "133:\tlearn 0.6340674031\ttest 0.6282943305\tbestTest 0.6282943305\t\ttotal: 3m 1s\tremaining: 24m 7s\n",
      "134:\tlearn 0.6341017658\ttest 0.6283115551\tbestTest 0.6283115551\t\ttotal: 3m 3s\tremaining: 24m 6s\n",
      "135:\tlearn 0.6341502222\ttest 0.6283575024\tbestTest 0.6283575024\t\ttotal: 3m 4s\tremaining: 24m 5s\n",
      "136:\tlearn 0.6342561349\ttest 0.6284200702\tbestTest 0.6284200702\t\ttotal: 3m 6s\tremaining: 24m 4s\n",
      "137:\tlearn 0.6344495096\ttest 0.6285533435\tbestTest 0.6285533435\t\ttotal: 3m 7s\tremaining: 24m 4s\n",
      "138:\tlearn 0.6345191615\ttest 0.6286041694\tbestTest 0.6286041694\t\ttotal: 3m 9s\tremaining: 24m 3s\n",
      "139:\tlearn 0.6344901275\ttest 0.6285828986\tbestTest 0.6286041694\t\ttotal: 3m 10s\tremaining: 24m\n",
      "140:\tlearn 0.6345304838\ttest 0.6286569697\tbestTest 0.6286569697\t\ttotal: 3m 11s\tremaining: 23m 59s\n",
      "141:\tlearn 0.6346341231\ttest 0.6286929318\tbestTest 0.6286929318\t\ttotal: 3m 13s\tremaining: 23m 59s\n",
      "142:\tlearn 0.6347214983\ttest 0.6287198331\tbestTest 0.6287198331\t\ttotal: 3m 14s\tremaining: 23m 58s\n",
      "143:\tlearn 0.6346607234\ttest 0.6286645539\tbestTest 0.6287198331\t\ttotal: 3m 15s\tremaining: 23m 54s\n",
      "144:\tlearn 0.6349493185\ttest 0.6288493817\tbestTest 0.6288493817\t\ttotal: 3m 17s\tremaining: 23m 53s\n",
      "145:\tlearn 0.6351067731\ttest 0.6289739222\tbestTest 0.6289739222\t\ttotal: 3m 18s\tremaining: 23m 52s\n",
      "146:\tlearn 0.635253106\ttest 0.629180949\tbestTest 0.629180949\t\ttotal: 3m 19s\tremaining: 23m 50s\n",
      "147:\tlearn 0.6353501992\ttest 0.6292638217\tbestTest 0.6292638217\t\ttotal: 3m 21s\tremaining: 23m 49s\n",
      "148:\tlearn 0.6353742693\ttest 0.6292846776\tbestTest 0.6292846776\t\ttotal: 3m 22s\tremaining: 23m 48s\n",
      "149:\tlearn 0.6354582489\ttest 0.629294366\tbestTest 0.629294366\t\ttotal: 3m 23s\tremaining: 23m 46s\n",
      "150:\tlearn 0.6354700707\ttest 0.6293273813\tbestTest 0.6293273813\t\ttotal: 3m 25s\tremaining: 23m 45s\n",
      "151:\tlearn 0.6354396326\ttest 0.6292741453\tbestTest 0.6293273813\t\ttotal: 3m 26s\tremaining: 23m 43s\n",
      "152:\tlearn 0.6356319922\ttest 0.6294208628\tbestTest 0.6294208628\t\ttotal: 3m 27s\tremaining: 23m 42s\n",
      "153:\tlearn 0.6357646398\ttest 0.6294693434\tbestTest 0.6294693434\t\ttotal: 3m 29s\tremaining: 23m 41s\n",
      "154:\tlearn 0.6359396646\ttest 0.6295937218\tbestTest 0.6295937218\t\ttotal: 3m 30s\tremaining: 23m 40s\n",
      "155:\tlearn 0.6361331686\ttest 0.6297380979\tbestTest 0.6297380979\t\ttotal: 3m 32s\tremaining: 23m 38s\n",
      "156:\tlearn 0.636107491\ttest 0.6297058695\tbestTest 0.6297380979\t\ttotal: 3m 33s\tremaining: 23m 37s\n",
      "157:\tlearn 0.6363111065\ttest 0.6298517715\tbestTest 0.6298517715\t\ttotal: 3m 34s\tremaining: 23m 36s\n",
      "158:\tlearn 0.636485125\ttest 0.6299670463\tbestTest 0.6299670463\t\ttotal: 3m 36s\tremaining: 23m 35s\n",
      "159:\tlearn 0.6364583431\ttest 0.6299242104\tbestTest 0.6299670463\t\ttotal: 3m 37s\tremaining: 23m 34s\n",
      "160:\tlearn 0.6366822649\ttest 0.6300270627\tbestTest 0.6300270627\t\ttotal: 3m 39s\tremaining: 23m 33s\n",
      "161:\tlearn 0.6367522109\ttest 0.6300779482\tbestTest 0.6300779482\t\ttotal: 3m 40s\tremaining: 23m 30s\n",
      "162:\tlearn 0.6367628815\ttest 0.6301343656\tbestTest 0.6301343656\t\ttotal: 3m 41s\tremaining: 23m 29s\n",
      "163:\tlearn 0.6367423144\ttest 0.6301404239\tbestTest 0.6301404239\t\ttotal: 3m 42s\tremaining: 23m 27s\n",
      "164:\tlearn 0.6368865004\ttest 0.6301970604\tbestTest 0.6301970604\t\ttotal: 3m 44s\tremaining: 23m 26s\n",
      "165:\tlearn 0.6369469713\ttest 0.6302104501\tbestTest 0.6302104501\t\ttotal: 3m 45s\tremaining: 23m 24s\n",
      "166:\tlearn 0.6370348526\ttest 0.6303183831\tbestTest 0.6303183831\t\ttotal: 3m 46s\tremaining: 23m 23s\n",
      "167:\tlearn 0.6370985967\ttest 0.6303355999\tbestTest 0.6303355999\t\ttotal: 3m 48s\tremaining: 23m 22s\n",
      "168:\tlearn 0.6371802729\ttest 0.6304123378\tbestTest 0.6304123378\t\ttotal: 3m 49s\tremaining: 23m 20s\n",
      "169:\tlearn 0.6372201352\ttest 0.6304128279\tbestTest 0.6304128279\t\ttotal: 3m 50s\tremaining: 23m 19s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170:\tlearn 0.6372341652\ttest 0.6304277629\tbestTest 0.6304277629\t\ttotal: 3m 52s\tremaining: 23m 16s\n",
      "171:\tlearn 0.6373022594\ttest 0.6304991647\tbestTest 0.6304991647\t\ttotal: 3m 53s\tremaining: 23m 15s\n",
      "172:\tlearn 0.6374593905\ttest 0.6305605138\tbestTest 0.6305605138\t\ttotal: 3m 54s\tremaining: 23m 14s\n",
      "173:\tlearn 0.6375021764\ttest 0.6305658655\tbestTest 0.6305658655\t\ttotal: 3m 56s\tremaining: 23m 12s\n",
      "174:\tlearn 0.6375000428\ttest 0.6305588258\tbestTest 0.6305658655\t\ttotal: 3m 57s\tremaining: 23m 10s\n",
      "175:\tlearn 0.6375323852\ttest 0.6305836683\tbestTest 0.6305836683\t\ttotal: 3m 58s\tremaining: 23m 9s\n",
      "176:\tlearn 0.6375272177\ttest 0.6305592575\tbestTest 0.6305836683\t\ttotal: 3m 59s\tremaining: 23m 6s\n",
      "177:\tlearn 0.6376498383\ttest 0.6306641879\tbestTest 0.6306641879\t\ttotal: 4m 1s\tremaining: 23m 5s\n",
      "178:\tlearn 0.6377500655\ttest 0.6307287289\tbestTest 0.6307287289\t\ttotal: 4m 2s\tremaining: 23m 3s\n",
      "179:\tlearn 0.6377866924\ttest 0.6307533705\tbestTest 0.6307533705\t\ttotal: 4m 3s\tremaining: 23m 2s\n",
      "180:\tlearn 0.6378601467\ttest 0.6307667394\tbestTest 0.6307667394\t\ttotal: 4m 5s\tremaining: 23m 1s\n",
      "181:\tlearn 0.6380522081\ttest 0.6309131341\tbestTest 0.6309131341\t\ttotal: 4m 6s\tremaining: 23m\n",
      "182:\tlearn 0.6380642181\ttest 0.6309446934\tbestTest 0.6309446934\t\ttotal: 4m 8s\tremaining: 22m 59s\n",
      "183:\tlearn 0.6381919672\ttest 0.6309894273\tbestTest 0.6309894273\t\ttotal: 4m 9s\tremaining: 22m 58s\n",
      "184:\tlearn 0.638269856\ttest 0.631060829\tbestTest 0.631060829\t\ttotal: 4m 10s\tremaining: 22m 57s\n",
      "185:\tlearn 0.6383197567\ttest 0.6310870574\tbestTest 0.6310870574\t\ttotal: 4m 12s\tremaining: 22m 56s\n",
      "186:\tlearn 0.6384364335\ttest 0.6311069734\tbestTest 0.6311069734\t\ttotal: 4m 13s\tremaining: 22m 55s\n",
      "187:\tlearn 0.6384961714\ttest 0.6311290117\tbestTest 0.6311290117\t\ttotal: 4m 15s\tremaining: 22m 54s\n",
      "188:\tlearn 0.6384994741\ttest 0.6311333159\tbestTest 0.6311333159\t\ttotal: 4m 17s\tremaining: 22m 54s\n",
      "189:\tlearn 0.6386136527\ttest 0.6312417027\tbestTest 0.6312417027\t\ttotal: 4m 18s\tremaining: 22m 54s\n",
      "190:\tlearn 0.6387572477\ttest 0.6312899966\tbestTest 0.6312899966\t\ttotal: 4m 20s\tremaining: 22m 54s\n",
      "191:\tlearn 0.6389183422\ttest 0.6313743887\tbestTest 0.6313743887\t\ttotal: 4m 21s\tremaining: 22m 53s\n",
      "192:\tlearn 0.6390575922\ttest 0.6314654316\tbestTest 0.6314654316\t\ttotal: 4m 23s\tremaining: 22m 53s\n",
      "193:\tlearn 0.6391251144\ttest 0.6315215988\tbestTest 0.6315215988\t\ttotal: 4m 24s\tremaining: 22m 53s\n",
      "194:\tlearn 0.6392511212\ttest 0.6315349263\tbestTest 0.6315349263\t\ttotal: 4m 26s\tremaining: 22m 52s\n",
      "195:\tlearn 0.6393073766\ttest 0.6315906008\tbestTest 0.6315906008\t\ttotal: 4m 27s\tremaining: 22m 51s\n",
      "196:\tlearn 0.6393350053\ttest 0.6315886147\tbestTest 0.6315906008\t\ttotal: 4m 29s\tremaining: 22m 49s\n",
      "197:\tlearn 0.6393514958\ttest 0.6316026604\tbestTest 0.6316026604\t\ttotal: 4m 30s\tremaining: 22m 47s\n",
      "198:\tlearn 0.6393621041\ttest 0.631586482\tbestTest 0.6316026604\t\ttotal: 4m 31s\tremaining: 22m 46s\n",
      "199:\tlearn 0.6393877148\ttest 0.6316054231\tbestTest 0.6316054231\t\ttotal: 4m 33s\tremaining: 22m 45s\n",
      "200:\tlearn 0.6394523597\ttest 0.6316656884\tbestTest 0.6316656884\t\ttotal: 4m 34s\tremaining: 22m 44s\n",
      "201:\tlearn 0.6394558634\ttest 0.6317113103\tbestTest 0.6317113103\t\ttotal: 4m 35s\tremaining: 22m 43s\n",
      "202:\tlearn 0.6395121723\ttest 0.6318138319\tbestTest 0.6318138319\t\ttotal: 4m 37s\tremaining: 22m 42s\n",
      "203:\tlearn 0.6395503876\ttest 0.6318482889\tbestTest 0.6318482889\t\ttotal: 4m 38s\tremaining: 22m 41s\n",
      "204:\tlearn 0.6396309695\ttest 0.6318701755\tbestTest 0.6318701755\t\ttotal: 4m 40s\tremaining: 22m 40s\n",
      "205:\tlearn 0.639732052\ttest 0.6319312679\tbestTest 0.6319312679\t\ttotal: 4m 41s\tremaining: 22m 38s\n",
      "206:\tlearn 0.6397559068\ttest 0.6319234335\tbestTest 0.6319312679\t\ttotal: 4m 42s\tremaining: 22m 37s\n",
      "207:\tlearn 0.6397897412\ttest 0.6319297718\tbestTest 0.6319312679\t\ttotal: 4m 44s\tremaining: 22m 36s\n",
      "208:\tlearn 0.639858137\ttest 0.6319718894\tbestTest 0.6319718894\t\ttotal: 4m 45s\tremaining: 22m 35s\n",
      "209:\tlearn 0.6398963639\ttest 0.6320183294\tbestTest 0.6320183294\t\ttotal: 4m 47s\tremaining: 22m 33s\n",
      "210:\tlearn 0.6399596456\ttest 0.6320670395\tbestTest 0.6320670395\t\ttotal: 4m 48s\tremaining: 22m 32s\n",
      "211:\tlearn 0.6401465697\ttest 0.6321660075\tbestTest 0.6321660075\t\ttotal: 4m 50s\tremaining: 22m 31s\n",
      "212:\tlearn 0.6402304081\ttest 0.632135615\tbestTest 0.6321660075\t\ttotal: 4m 51s\tremaining: 22m 30s\n",
      "213:\tlearn 0.6403335221\ttest 0.6321976525\tbestTest 0.6321976525\t\ttotal: 4m 52s\tremaining: 22m 29s\n",
      "214:\tlearn 0.6404036689\ttest 0.6322413505\tbestTest 0.6322413505\t\ttotal: 4m 54s\tremaining: 22m 28s\n",
      "215:\tlearn 0.6404095889\ttest 0.6322158675\tbestTest 0.6322413505\t\ttotal: 4m 55s\tremaining: 22m 27s\n",
      "216:\tlearn 0.6404358905\ttest 0.6322432757\tbestTest 0.6322432757\t\ttotal: 4m 57s\tremaining: 22m 26s\n",
      "217:\tlearn 0.6405015093\ttest 0.6322577142\tbestTest 0.6322577142\t\ttotal: 4m 58s\tremaining: 22m 26s\n",
      "218:\tlearn 0.6405672405\ttest 0.6323147552\tbestTest 0.6323147552\t\ttotal: 5m\tremaining: 22m 25s\n",
      "219:\tlearn 0.6406105594\ttest 0.6323623646\tbestTest 0.6323623646\t\ttotal: 5m 2s\tremaining: 22m 25s\n",
      "220:\tlearn 0.6406941487\ttest 0.6324658806\tbestTest 0.6324658806\t\ttotal: 5m 3s\tremaining: 22m 25s\n",
      "221:\tlearn 0.6407406748\ttest 0.6324883403\tbestTest 0.6324883403\t\ttotal: 5m 5s\tremaining: 22m 24s\n",
      "222:\tlearn 0.6407980014\ttest 0.6325161711\tbestTest 0.6325161711\t\ttotal: 5m 6s\tremaining: 22m 24s\n",
      "223:\tlearn 0.6408443199\ttest 0.6325228426\tbestTest 0.6325228426\t\ttotal: 5m 8s\tremaining: 22m 22s\n",
      "224:\tlearn 0.6409701593\ttest 0.6325836588\tbestTest 0.6325836588\t\ttotal: 5m 9s\tremaining: 22m 21s\n",
      "225:\tlearn 0.6410277283\ttest 0.6325851484\tbestTest 0.6325851484\t\ttotal: 5m 11s\tremaining: 22m 20s\n",
      "226:\tlearn 0.6410680963\ttest 0.6326224161\tbestTest 0.6326224161\t\ttotal: 5m 12s\tremaining: 22m 19s\n",
      "227:\tlearn 0.6410577403\ttest 0.6326050683\tbestTest 0.6326224161\t\ttotal: 5m 13s\tremaining: 22m 18s\n",
      "228:\tlearn 0.6410457825\ttest 0.6326238383\tbestTest 0.6326238383\t\ttotal: 5m 15s\tremaining: 22m 17s\n",
      "229:\tlearn 0.6411367045\ttest 0.6326768357\tbestTest 0.6326768357\t\ttotal: 5m 16s\tremaining: 22m 15s\n",
      "230:\tlearn 0.6411778752\ttest 0.6326907453\tbestTest 0.6326907453\t\ttotal: 5m 18s\tremaining: 22m 14s\n",
      "231:\tlearn 0.6412367484\ttest 0.6326871943\tbestTest 0.6326907453\t\ttotal: 5m 19s\tremaining: 22m 13s\n",
      "232:\tlearn 0.6413029577\ttest 0.6327552201\tbestTest 0.6327552201\t\ttotal: 5m 20s\tremaining: 22m 11s\n",
      "233:\tlearn 0.6414882853\ttest 0.6328289243\tbestTest 0.6328289243\t\ttotal: 5m 22s\tremaining: 22m 10s\n",
      "234:\tlearn 0.641573325\ttest 0.6328665692\tbestTest 0.6328665692\t\ttotal: 5m 23s\tremaining: 22m 9s\n",
      "235:\tlearn 0.6415971692\ttest 0.6328824079\tbestTest 0.6328824079\t\ttotal: 5m 24s\tremaining: 22m 6s\n",
      "236:\tlearn 0.6416260159\ttest 0.6328984696\tbestTest 0.6328984696\t\ttotal: 5m 26s\tremaining: 22m 5s\n",
      "237:\tlearn 0.6416971537\ttest 0.6329238812\tbestTest 0.6329238812\t\ttotal: 5m 27s\tremaining: 22m 4s\n",
      "238:\tlearn 0.6417274856\ttest 0.6329375017\tbestTest 0.6329375017\t\ttotal: 5m 28s\tremaining: 22m 2s\n",
      "239:\tlearn 0.6417831045\ttest 0.6329559008\tbestTest 0.6329559008\t\ttotal: 5m 30s\tremaining: 22m 1s\n",
      "240:\tlearn 0.6418413992\ttest 0.6329935872\tbestTest 0.6329935872\t\ttotal: 5m 31s\tremaining: 21m 59s\n",
      "241:\tlearn 0.6418821693\ttest 0.6330355907\tbestTest 0.6330355907\t\ttotal: 5m 33s\tremaining: 21m 58s\n",
      "242:\tlearn 0.6419473627\ttest 0.6330657707\tbestTest 0.6330657707\t\ttotal: 5m 34s\tremaining: 21m 57s\n",
      "243:\tlearn 0.6419965799\ttest 0.6330966326\tbestTest 0.6330966326\t\ttotal: 5m 35s\tremaining: 21m 56s\n",
      "244:\tlearn 0.6421696073\ttest 0.6331544489\tbestTest 0.6331544489\t\ttotal: 5m 37s\tremaining: 21m 54s\n",
      "245:\tlearn 0.6422871351\ttest 0.6332215542\tbestTest 0.6332215542\t\ttotal: 5m 38s\tremaining: 21m 53s\n",
      "246:\tlearn 0.6423484302\ttest 0.6332460765\tbestTest 0.6332460765\t\ttotal: 5m 40s\tremaining: 21m 52s\n",
      "247:\tlearn 0.6424254647\ttest 0.6333062134\tbestTest 0.6333062134\t\ttotal: 5m 41s\tremaining: 21m 51s\n",
      "248:\tlearn 0.6424892634\ttest 0.6333372724\tbestTest 0.6333372724\t\ttotal: 5m 42s\tremaining: 21m 49s\n",
      "249:\tlearn 0.6425008674\ttest 0.6333393946\tbestTest 0.6333393946\t\ttotal: 5m 44s\tremaining: 21m 48s\n",
      "250:\tlearn 0.6425242103\ttest 0.6333444352\tbestTest 0.6333444352\t\ttotal: 5m 45s\tremaining: 21m 46s\n",
      "251:\tlearn 0.642582783\ttest 0.6333652289\tbestTest 0.6333652289\t\ttotal: 5m 46s\tremaining: 21m 45s\n",
      "252:\tlearn 0.6426626585\ttest 0.6333836462\tbestTest 0.6333836462\t\ttotal: 5m 48s\tremaining: 21m 43s\n",
      "253:\tlearn 0.6427968859\ttest 0.6334602856\tbestTest 0.6334602856\t\ttotal: 5m 49s\tremaining: 21m 42s\n",
      "254:\tlearn 0.6428768001\ttest 0.6334702605\tbestTest 0.6334702605\t\ttotal: 5m 51s\tremaining: 21m 41s\n",
      "255:\tlearn 0.6429267843\ttest 0.6334980679\tbestTest 0.6334980679\t\ttotal: 5m 52s\tremaining: 21m 40s\n",
      "256:\tlearn 0.6429434307\ttest 0.6335145963\tbestTest 0.6335145963\t\ttotal: 5m 54s\tremaining: 21m 39s\n",
      "257:\tlearn 0.6429820226\ttest 0.6335362768\tbestTest 0.6335362768\t\ttotal: 5m 55s\tremaining: 21m 38s\n",
      "258:\tlearn 0.6430315072\ttest 0.6335624391\tbestTest 0.6335624391\t\ttotal: 5m 57s\tremaining: 21m 37s\n",
      "259:\tlearn 0.6430776685\ttest 0.6335431492\tbestTest 0.6335624391\t\ttotal: 5m 58s\tremaining: 21m 35s\n",
      "260:\tlearn 0.6431496501\ttest 0.6335895296\tbestTest 0.6335895296\t\ttotal: 5m 59s\tremaining: 21m 33s\n",
      "261:\tlearn 0.6432437773\ttest 0.6336390331\tbestTest 0.6336390331\t\ttotal: 6m 1s\tremaining: 21m 32s\n",
      "262:\tlearn 0.643301091\ttest 0.6336632701\tbestTest 0.6336632701\t\ttotal: 6m 2s\tremaining: 21m 30s\n",
      "263:\tlearn 0.6433587611\ttest 0.6337122991\tbestTest 0.6337122991\t\ttotal: 6m 3s\tremaining: 21m 29s\n",
      "264:\tlearn 0.6434508595\ttest 0.6337869381\tbestTest 0.6337869381\t\ttotal: 6m 5s\tremaining: 21m 28s\n",
      "265:\tlearn 0.6434973064\ttest 0.6338242848\tbestTest 0.6338242848\t\ttotal: 6m 6s\tremaining: 21m 27s\n",
      "266:\tlearn 0.6435511191\ttest 0.6338172347\tbestTest 0.6338242848\t\ttotal: 6m 8s\tremaining: 21m 26s\n",
      "267:\tlearn 0.6435874861\ttest 0.6338316369\tbestTest 0.6338316369\t\ttotal: 6m 9s\tremaining: 21m 25s\n",
      "268:\tlearn 0.6436409311\ttest 0.6338298375\tbestTest 0.6338316369\t\ttotal: 6m 11s\tremaining: 21m 24s\n",
      "269:\tlearn 0.6437162088\ttest 0.633833885\tbestTest 0.633833885\t\ttotal: 6m 12s\tremaining: 21m 23s\n",
      "270:\tlearn 0.6437762956\ttest 0.633848282\tbestTest 0.633848282\t\ttotal: 6m 14s\tremaining: 21m 22s\n",
      "271:\tlearn 0.6438417716\ttest 0.6338807437\tbestTest 0.6338807437\t\ttotal: 6m 15s\tremaining: 21m 21s\n",
      "272:\tlearn 0.6438735643\ttest 0.6338915003\tbestTest 0.6338915003\t\ttotal: 6m 16s\tremaining: 21m 19s\n",
      "273:\tlearn 0.6439105887\ttest 0.6339309706\tbestTest 0.6339309706\t\ttotal: 6m 18s\tremaining: 21m 18s\n",
      "274:\tlearn 0.6439527546\ttest 0.6339412566\tbestTest 0.6339412566\t\ttotal: 6m 19s\tremaining: 21m 17s\n",
      "275:\tlearn 0.644040077\ttest 0.6339754854\tbestTest 0.6339754854\t\ttotal: 6m 21s\tremaining: 21m 16s\n",
      "276:\tlearn 0.6441513617\ttest 0.6340166073\tbestTest 0.6340166073\t\ttotal: 6m 22s\tremaining: 21m 15s\n",
      "277:\tlearn 0.6442441702\ttest 0.6340272978\tbestTest 0.6340272978\t\ttotal: 6m 24s\tremaining: 21m 14s\n",
      "278:\tlearn 0.6444266881\ttest 0.6340955829\tbestTest 0.6340955829\t\ttotal: 6m 25s\tremaining: 21m 13s\n",
      "279:\tlearn 0.64447966\ttest 0.6341133805\tbestTest 0.6341133805\t\ttotal: 6m 27s\tremaining: 21m 12s\n",
      "280:\tlearn 0.6445349664\ttest 0.6341427982\tbestTest 0.6341427982\t\ttotal: 6m 28s\tremaining: 21m 11s\n",
      "281:\tlearn 0.6446346766\ttest 0.6342286255\tbestTest 0.6342286255\t\ttotal: 6m 30s\tremaining: 21m 10s\n",
      "282:\tlearn 0.6446560858\ttest 0.6342494347\tbestTest 0.6342494347\t\ttotal: 6m 31s\tremaining: 21m 8s\n",
      "283:\tlearn 0.6446914914\ttest 0.6342692289\tbestTest 0.6342692289\t\ttotal: 6m 32s\tremaining: 21m 7s\n",
      "284:\tlearn 0.644789279\ttest 0.6342482303\tbestTest 0.6342692289\t\ttotal: 6m 34s\tremaining: 21m 6s\n",
      "285:\tlearn 0.6448663319\ttest 0.6343040216\tbestTest 0.6343040216\t\ttotal: 6m 35s\tremaining: 21m 4s\n",
      "286:\tlearn 0.6448819827\ttest 0.6343175941\tbestTest 0.6343175941\t\ttotal: 6m 37s\tremaining: 21m 3s\n",
      "287:\tlearn 0.6449156428\ttest 0.6343179623\tbestTest 0.6343179623\t\ttotal: 6m 38s\tremaining: 21m 2s\n",
      "288:\tlearn 0.6449955847\ttest 0.6343104753\tbestTest 0.6343179623\t\ttotal: 6m 39s\tremaining: 21m\n",
      "289:\tlearn 0.6450716631\ttest 0.6343128906\tbestTest 0.6343179623\t\ttotal: 6m 41s\tremaining: 20m 59s\n",
      "290:\tlearn 0.6451659642\ttest 0.6343705344\tbestTest 0.6343705344\t\ttotal: 6m 42s\tremaining: 20m 58s\n",
      "291:\tlearn 0.6452540259\ttest 0.6344097014\tbestTest 0.6344097014\t\ttotal: 6m 44s\tremaining: 20m 57s\n",
      "292:\tlearn 0.6454194692\ttest 0.6344265733\tbestTest 0.6344265733\t\ttotal: 6m 45s\tremaining: 20m 56s\n",
      "293:\tlearn 0.6454871039\ttest 0.6344640095\tbestTest 0.6344640095\t\ttotal: 6m 47s\tremaining: 20m 55s\n",
      "294:\tlearn 0.6454907678\ttest 0.6344602381\tbestTest 0.6344640095\t\ttotal: 6m 48s\tremaining: 20m 53s\n",
      "295:\tlearn 0.6455590102\ttest 0.6344830944\tbestTest 0.6344830944\t\ttotal: 6m 50s\tremaining: 20m 53s\n",
      "296:\tlearn 0.6456197103\ttest 0.634484702\tbestTest 0.634484702\t\ttotal: 6m 51s\tremaining: 20m 52s\n",
      "297:\tlearn 0.645703464\ttest 0.6344984353\tbestTest 0.6344984353\t\ttotal: 6m 53s\tremaining: 20m 51s\n",
      "298:\tlearn 0.6457955361\ttest 0.6345349095\tbestTest 0.6345349095\t\ttotal: 6m 54s\tremaining: 20m 50s\n",
      "299:\tlearn 0.6458575621\ttest 0.6345802021\tbestTest 0.6345802021\t\ttotal: 6m 56s\tremaining: 20m 48s\n",
      "300:\tlearn 0.645968276\ttest 0.6346276507\tbestTest 0.6346276507\t\ttotal: 6m 57s\tremaining: 20m 47s\n",
      "301:\tlearn 0.6459749718\ttest 0.6346311226\tbestTest 0.6346311226\t\ttotal: 6m 59s\tremaining: 20m 46s\n",
      "302:\tlearn 0.6460047777\ttest 0.6346358572\tbestTest 0.6346358572\t\ttotal: 7m\tremaining: 20m 45s\n",
      "303:\tlearn 0.6460537554\ttest 0.634641113\tbestTest 0.634641113\t\ttotal: 7m 2s\tremaining: 20m 44s\n",
      "304:\tlearn 0.6460859664\ttest 0.6346466605\tbestTest 0.6346466605\t\ttotal: 7m 3s\tremaining: 20m 43s\n",
      "305:\tlearn 0.6461689604\ttest 0.6346745548\tbestTest 0.6346745548\t\ttotal: 7m 5s\tremaining: 20m 41s\n",
      "306:\tlearn 0.6462062009\ttest 0.6346523312\tbestTest 0.6346745548\t\ttotal: 7m 6s\tremaining: 20m 41s\n",
      "307:\tlearn 0.6462842782\ttest 0.634644839\tbestTest 0.6346745548\t\ttotal: 7m 8s\tremaining: 20m 41s\n",
      "308:\tlearn 0.6463164485\ttest 0.6346685899\tbestTest 0.6346745548\t\ttotal: 7m 9s\tremaining: 20m 39s\n",
      "309:\tlearn 0.6464367078\ttest 0.6347534695\tbestTest 0.6347534695\t\ttotal: 7m 11s\tremaining: 20m 38s\n",
      "310:\tlearn 0.646460801\ttest 0.6347460448\tbestTest 0.6347534695\t\ttotal: 7m 12s\tremaining: 20m 37s\n",
      "311:\tlearn 0.6465032898\ttest 0.6347393629\tbestTest 0.6347534695\t\ttotal: 7m 14s\tremaining: 20m 36s\n",
      "312:\tlearn 0.6465720451\ttest 0.6347551277\tbestTest 0.6347551277\t\ttotal: 7m 16s\tremaining: 20m 35s\n",
      "313:\tlearn 0.6466215143\ttest 0.6347812381\tbestTest 0.6347812381\t\ttotal: 7m 17s\tremaining: 20m 34s\n",
      "314:\tlearn 0.6466757157\ttest 0.6347980011\tbestTest 0.6347980011\t\ttotal: 7m 19s\tremaining: 20m 33s\n",
      "315:\tlearn 0.6467100695\ttest 0.6348114401\tbestTest 0.6348114401\t\ttotal: 7m 20s\tremaining: 20m 32s\n",
      "316:\tlearn 0.6467984175\ttest 0.6348737408\tbestTest 0.6348737408\t\ttotal: 7m 21s\tremaining: 20m 30s\n",
      "317:\tlearn 0.646890929\ttest 0.6348863383\tbestTest 0.6348863383\t\ttotal: 7m 23s\tremaining: 20m 29s\n",
      "318:\tlearn 0.6469404573\ttest 0.6348949856\tbestTest 0.6348949856\t\ttotal: 7m 24s\tremaining: 20m 28s\n",
      "319:\tlearn 0.6470294885\ttest 0.6349172858\tbestTest 0.6349172858\t\ttotal: 7m 26s\tremaining: 20m 26s\n",
      "320:\tlearn 0.6470653886\ttest 0.6349247209\tbestTest 0.6349247209\t\ttotal: 7m 27s\tremaining: 20m 25s\n",
      "321:\tlearn 0.6471009294\ttest 0.6349375946\tbestTest 0.6349375946\t\ttotal: 7m 28s\tremaining: 20m 23s\n",
      "322:\tlearn 0.6471612757\ttest 0.6349743722\tbestTest 0.6349743722\t\ttotal: 7m 30s\tremaining: 20m 22s\n",
      "323:\tlearn 0.6472489397\ttest 0.6349920103\tbestTest 0.6349920103\t\ttotal: 7m 31s\tremaining: 20m 21s\n",
      "324:\tlearn 0.6472808016\ttest 0.6350138101\tbestTest 0.6350138101\t\ttotal: 7m 33s\tremaining: 20m 20s\n",
      "325:\tlearn 0.6473153171\ttest 0.635020068\tbestTest 0.635020068\t\ttotal: 7m 34s\tremaining: 20m 18s\n",
      "326:\tlearn 0.647364794\ttest 0.6350334901\tbestTest 0.6350334901\t\ttotal: 7m 36s\tremaining: 20m 17s\n",
      "327:\tlearn 0.6473902534\ttest 0.6350463833\tbestTest 0.6350463833\t\ttotal: 7m 37s\tremaining: 20m 16s\n",
      "328:\tlearn 0.6474230833\ttest 0.6350553547\tbestTest 0.6350553547\t\ttotal: 7m 38s\tremaining: 20m 14s\n",
      "329:\tlearn 0.6474790472\ttest 0.6350679133\tbestTest 0.6350679133\t\ttotal: 7m 40s\tremaining: 20m 13s\n",
      "330:\tlearn 0.6475127809\ttest 0.6350677409\tbestTest 0.6350679133\t\ttotal: 7m 41s\tremaining: 20m 12s\n",
      "331:\tlearn 0.6475723286\ttest 0.6350782836\tbestTest 0.6350782836\t\ttotal: 7m 43s\tremaining: 20m 10s\n",
      "332:\tlearn 0.6476150345\ttest 0.6351132539\tbestTest 0.6351132539\t\ttotal: 7m 44s\tremaining: 20m 9s\n",
      "333:\tlearn 0.6476709564\ttest 0.6351402978\tbestTest 0.6351402978\t\ttotal: 7m 45s\tremaining: 20m 8s\n",
      "334:\tlearn 0.6476784302\ttest 0.6351307041\tbestTest 0.6351402978\t\ttotal: 7m 46s\tremaining: 20m 5s\n",
      "335:\tlearn 0.6476916147\ttest 0.6351396159\tbestTest 0.6351402978\t\ttotal: 7m 48s\tremaining: 20m 4s\n",
      "336:\tlearn 0.6477152164\ttest 0.6351589368\tbestTest 0.6351589368\t\ttotal: 7m 49s\tremaining: 20m 2s\n",
      "337:\tlearn 0.6478281367\ttest 0.6352098417\tbestTest 0.6352098417\t\ttotal: 7m 50s\tremaining: 20m\n",
      "338:\tlearn 0.6478669206\ttest 0.6352094658\tbestTest 0.6352098417\t\ttotal: 7m 52s\tremaining: 19m 59s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339:\tlearn 0.6479680687\ttest 0.6352219765\tbestTest 0.6352219765\t\ttotal: 7m 54s\tremaining: 19m 58s\n",
      "340:\tlearn 0.6480190851\ttest 0.6352489866\tbestTest 0.6352489866\t\ttotal: 7m 55s\tremaining: 19m 57s\n",
      "341:\tlearn 0.6480553368\ttest 0.6352597147\tbestTest 0.6352597147\t\ttotal: 7m 56s\tremaining: 19m 56s\n",
      "342:\tlearn 0.6481014489\ttest 0.6352415191\tbestTest 0.6352597147\t\ttotal: 7m 58s\tremaining: 19m 54s\n",
      "343:\tlearn 0.6481301343\ttest 0.6352541231\tbestTest 0.6352597147\t\ttotal: 7m 59s\tremaining: 19m 53s\n",
      "344:\tlearn 0.6481728429\ttest 0.6352561028\tbestTest 0.6352597147\t\ttotal: 8m 1s\tremaining: 19m 52s\n",
      "345:\tlearn 0.6482242648\ttest 0.6352748403\tbestTest 0.6352748403\t\ttotal: 8m 2s\tremaining: 19m 51s\n",
      "346:\tlearn 0.6482997241\ttest 0.6352626693\tbestTest 0.6352748403\t\ttotal: 8m 3s\tremaining: 19m 49s\n",
      "347:\tlearn 0.6483542765\ttest 0.6353223914\tbestTest 0.6353223914\t\ttotal: 8m 5s\tremaining: 19m 48s\n",
      "348:\tlearn 0.6483914517\ttest 0.6353555752\tbestTest 0.6353555752\t\ttotal: 8m 6s\tremaining: 19m 47s\n",
      "349:\tlearn 0.6484121873\ttest 0.6353639697\tbestTest 0.6353639697\t\ttotal: 8m 8s\tremaining: 19m 45s\n",
      "350:\tlearn 0.6484359199\ttest 0.6353593193\tbestTest 0.6353639697\t\ttotal: 8m 9s\tremaining: 19m 44s\n",
      "351:\tlearn 0.6484650814\ttest 0.6353689973\tbestTest 0.6353689973\t\ttotal: 8m 11s\tremaining: 19m 43s\n",
      "352:\tlearn 0.6485128812\ttest 0.635388068\tbestTest 0.635388068\t\ttotal: 8m 12s\tremaining: 19m 42s\n",
      "353:\tlearn 0.6485992367\ttest 0.6353863269\tbestTest 0.635388068\t\ttotal: 8m 14s\tremaining: 19m 41s\n",
      "354:\tlearn 0.6486297638\ttest 0.6353965157\tbestTest 0.6353965157\t\ttotal: 8m 15s\tremaining: 19m 39s\n",
      "355:\tlearn 0.6486828469\ttest 0.635375416\tbestTest 0.6353965157\t\ttotal: 8m 17s\tremaining: 19m 38s\n",
      "356:\tlearn 0.6487424911\ttest 0.6354099248\tbestTest 0.6354099248\t\ttotal: 8m 18s\tremaining: 19m 37s\n",
      "357:\tlearn 0.6487748035\ttest 0.6354226766\tbestTest 0.6354226766\t\ttotal: 8m 20s\tremaining: 19m 36s\n",
      "358:\tlearn 0.6488065929\ttest 0.6354316182\tbestTest 0.6354316182\t\ttotal: 8m 21s\tremaining: 19m 35s\n",
      "359:\tlearn 0.6488541332\ttest 0.6354477862\tbestTest 0.6354477862\t\ttotal: 8m 23s\tremaining: 19m 34s\n",
      "360:\tlearn 0.6489200806\ttest 0.6354779532\tbestTest 0.6354779532\t\ttotal: 8m 25s\tremaining: 19m 33s\n",
      "361:\tlearn 0.6490178178\ttest 0.6355028385\tbestTest 0.6355028385\t\ttotal: 8m 26s\tremaining: 19m 32s\n",
      "362:\tlearn 0.6490783263\ttest 0.6355116206\tbestTest 0.6355116206\t\ttotal: 8m 28s\tremaining: 19m 31s\n",
      "363:\tlearn 0.6491084306\ttest 0.6354944569\tbestTest 0.6355116206\t\ttotal: 8m 29s\tremaining: 19m 30s\n",
      "364:\tlearn 0.6491946195\ttest 0.6355441912\tbestTest 0.6355441912\t\ttotal: 8m 31s\tremaining: 19m 29s\n",
      "365:\tlearn 0.6492278196\ttest 0.6355418226\tbestTest 0.6355441912\t\ttotal: 8m 32s\tremaining: 19m 28s\n",
      "366:\tlearn 0.6492814946\ttest 0.6355747186\tbestTest 0.6355747186\t\ttotal: 8m 34s\tremaining: 19m 27s\n",
      "367:\tlearn 0.6493377977\ttest 0.635594317\tbestTest 0.635594317\t\ttotal: 8m 35s\tremaining: 19m 26s\n",
      "368:\tlearn 0.649381693\ttest 0.6356094815\tbestTest 0.6356094815\t\ttotal: 8m 37s\tremaining: 19m 24s\n",
      "369:\tlearn 0.6494144238\ttest 0.6356201966\tbestTest 0.6356201966\t\ttotal: 8m 38s\tremaining: 19m 23s\n",
      "370:\tlearn 0.6495231674\ttest 0.635619188\tbestTest 0.6356201966\t\ttotal: 8m 39s\tremaining: 19m 21s\n",
      "371:\tlearn 0.6496089259\ttest 0.635650151\tbestTest 0.635650151\t\ttotal: 8m 41s\tremaining: 19m 20s\n",
      "372:\tlearn 0.6496340543\ttest 0.6356376001\tbestTest 0.635650151\t\ttotal: 8m 42s\tremaining: 19m 18s\n",
      "373:\tlearn 0.6496839802\ttest 0.6356611047\tbestTest 0.6356611047\t\ttotal: 8m 44s\tremaining: 19m 17s\n",
      "374:\tlearn 0.6497356978\ttest 0.6356601479\tbestTest 0.6356611047\t\ttotal: 8m 45s\tremaining: 19m 16s\n",
      "375:\tlearn 0.6497493045\ttest 0.6356595476\tbestTest 0.6356611047\t\ttotal: 8m 46s\tremaining: 19m 14s\n",
      "376:\tlearn 0.6498353173\ttest 0.6356747381\tbestTest 0.6356747381\t\ttotal: 8m 48s\tremaining: 19m 13s\n",
      "377:\tlearn 0.6499352721\ttest 0.6357263807\tbestTest 0.6357263807\t\ttotal: 8m 49s\tremaining: 19m 11s\n",
      "378:\tlearn 0.6499715744\ttest 0.6357286975\tbestTest 0.6357286975\t\ttotal: 8m 50s\tremaining: 19m 10s\n",
      "379:\tlearn 0.6500786563\ttest 0.6357412821\tbestTest 0.6357412821\t\ttotal: 8m 52s\tremaining: 19m 8s\n",
      "380:\tlearn 0.6501109157\ttest 0.6357375768\tbestTest 0.6357412821\t\ttotal: 8m 53s\tremaining: 19m 7s\n",
      "381:\tlearn 0.6501961044\ttest 0.6357988365\tbestTest 0.6357988365\t\ttotal: 8m 55s\tremaining: 19m 6s\n",
      "382:\tlearn 0.6502319564\ttest 0.6358014786\tbestTest 0.6358014786\t\ttotal: 8m 56s\tremaining: 19m 5s\n",
      "383:\tlearn 0.6502830714\ttest 0.6357973533\tbestTest 0.6358014786\t\ttotal: 8m 58s\tremaining: 19m 3s\n",
      "384:\tlearn 0.6503121545\ttest 0.6357823405\tbestTest 0.6358014786\t\ttotal: 8m 59s\tremaining: 19m 2s\n",
      "385:\tlearn 0.6503258322\ttest 0.6357981105\tbestTest 0.6358014786\t\ttotal: 9m 1s\tremaining: 19m 1s\n",
      "386:\tlearn 0.6503442533\ttest 0.635804126\tbestTest 0.635804126\t\ttotal: 9m 2s\tremaining: 18m 59s\n",
      "387:\tlearn 0.6503892498\ttest 0.6358213078\tbestTest 0.6358213078\t\ttotal: 9m 4s\tremaining: 18m 58s\n",
      "388:\tlearn 0.6504648343\ttest 0.6358131907\tbestTest 0.6358213078\t\ttotal: 9m 5s\tremaining: 18m 57s\n",
      "389:\tlearn 0.6505235567\ttest 0.6358700126\tbestTest 0.6358700126\t\ttotal: 9m 7s\tremaining: 18m 56s\n",
      "390:\tlearn 0.6505644488\ttest 0.6358655995\tbestTest 0.6358700126\t\ttotal: 9m 8s\tremaining: 18m 55s\n",
      "391:\tlearn 0.6506152043\ttest 0.6358970254\tbestTest 0.6358970254\t\ttotal: 9m 10s\tremaining: 18m 53s\n",
      "392:\tlearn 0.6506425682\ttest 0.6358955163\tbestTest 0.6358970254\t\ttotal: 9m 11s\tremaining: 18m 52s\n",
      "393:\tlearn 0.6506996369\ttest 0.635901314\tbestTest 0.635901314\t\ttotal: 9m 12s\tremaining: 18m 50s\n",
      "394:\tlearn 0.6507428393\ttest 0.6359185231\tbestTest 0.6359185231\t\ttotal: 9m 14s\tremaining: 18m 50s\n",
      "395:\tlearn 0.6507840973\ttest 0.6359264028\tbestTest 0.6359264028\t\ttotal: 9m 16s\tremaining: 18m 49s\n",
      "396:\tlearn 0.6508315068\ttest 0.6359344447\tbestTest 0.6359344447\t\ttotal: 9m 17s\tremaining: 18m 48s\n",
      "397:\tlearn 0.6509049623\ttest 0.6359443081\tbestTest 0.6359443081\t\ttotal: 9m 19s\tremaining: 18m 46s\n",
      "398:\tlearn 0.6509652618\ttest 0.6359400026\tbestTest 0.6359443081\t\ttotal: 9m 20s\tremaining: 18m 45s\n",
      "399:\tlearn 0.6509789938\ttest 0.635938382\tbestTest 0.6359443081\t\ttotal: 9m 22s\tremaining: 18m 44s\n",
      "400:\tlearn 0.6510124358\ttest 0.6359375704\tbestTest 0.6359443081\t\ttotal: 9m 23s\tremaining: 18m 43s\n",
      "401:\tlearn 0.6510804922\ttest 0.6359612396\tbestTest 0.6359612396\t\ttotal: 9m 25s\tremaining: 18m 42s\n",
      "402:\tlearn 0.6511473462\ttest 0.6359925929\tbestTest 0.6359925929\t\ttotal: 9m 26s\tremaining: 18m 41s\n",
      "403:\tlearn 0.6512199512\ttest 0.6360038707\tbestTest 0.6360038707\t\ttotal: 9m 28s\tremaining: 18m 39s\n",
      "404:\tlearn 0.6512710966\ttest 0.6360267711\tbestTest 0.6360267711\t\ttotal: 9m 30s\tremaining: 18m 38s\n",
      "405:\tlearn 0.651353548\ttest 0.6360527454\tbestTest 0.6360527454\t\ttotal: 9m 31s\tremaining: 18m 37s\n",
      "406:\tlearn 0.6514120124\ttest 0.6360733913\tbestTest 0.6360733913\t\ttotal: 9m 33s\tremaining: 18m 36s\n",
      "407:\tlearn 0.6514442487\ttest 0.6360845018\tbestTest 0.6360845018\t\ttotal: 9m 34s\tremaining: 18m 35s\n",
      "408:\tlearn 0.6514831057\ttest 0.6361095193\tbestTest 0.6361095193\t\ttotal: 9m 36s\tremaining: 18m 34s\n",
      "409:\tlearn 0.6515140769\ttest 0.6361262876\tbestTest 0.6361262876\t\ttotal: 9m 37s\tremaining: 18m 32s\n",
      "410:\tlearn 0.6515490309\ttest 0.6361589321\tbestTest 0.6361589321\t\ttotal: 9m 39s\tremaining: 18m 31s\n",
      "411:\tlearn 0.6515800317\ttest 0.6361921755\tbestTest 0.6361921755\t\ttotal: 9m 40s\tremaining: 18m 30s\n",
      "412:\tlearn 0.6516705479\ttest 0.6361848713\tbestTest 0.6361921755\t\ttotal: 9m 41s\tremaining: 18m 28s\n",
      "413:\tlearn 0.6517350776\ttest 0.6362052904\tbestTest 0.6362052904\t\ttotal: 9m 43s\tremaining: 18m 27s\n",
      "414:\tlearn 0.6517546755\ttest 0.6362204147\tbestTest 0.6362204147\t\ttotal: 9m 44s\tremaining: 18m 25s\n",
      "415:\tlearn 0.6517767736\ttest 0.636241526\tbestTest 0.636241526\t\ttotal: 9m 46s\tremaining: 18m 24s\n",
      "416:\tlearn 0.651833399\ttest 0.6362414988\tbestTest 0.636241526\t\ttotal: 9m 47s\tremaining: 18m 23s\n",
      "417:\tlearn 0.6518715686\ttest 0.6362420602\tbestTest 0.6362420602\t\ttotal: 9m 49s\tremaining: 18m 22s\n",
      "418:\tlearn 0.6519286658\ttest 0.6362516098\tbestTest 0.6362516098\t\ttotal: 9m 50s\tremaining: 18m 20s\n",
      "419:\tlearn 0.6519670894\ttest 0.63626976\tbestTest 0.63626976\t\ttotal: 9m 52s\tremaining: 18m 19s\n",
      "420:\tlearn 0.6520075915\ttest 0.6362911216\tbestTest 0.6362911216\t\ttotal: 9m 53s\tremaining: 18m 18s\n",
      "421:\tlearn 0.6520389964\ttest 0.6362895282\tbestTest 0.6362911216\t\ttotal: 9m 55s\tremaining: 18m 17s\n",
      "422:\tlearn 0.6521116936\ttest 0.636324553\tbestTest 0.636324553\t\ttotal: 9m 56s\tremaining: 18m 16s\n",
      "423:\tlearn 0.6521968806\ttest 0.636317101\tbestTest 0.636324553\t\ttotal: 9m 58s\tremaining: 18m 15s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424:\tlearn 0.6522818144\ttest 0.6363720133\tbestTest 0.6363720133\t\ttotal: 9m 59s\tremaining: 18m 13s\n",
      "425:\tlearn 0.6523379754\ttest 0.6363794173\tbestTest 0.6363794173\t\ttotal: 10m 1s\tremaining: 18m 12s\n",
      "426:\tlearn 0.6523761702\ttest 0.6363745803\tbestTest 0.6363794173\t\ttotal: 10m 2s\tremaining: 18m 11s\n",
      "427:\tlearn 0.6524722283\ttest 0.6363994616\tbestTest 0.6363994616\t\ttotal: 10m 4s\tremaining: 18m 10s\n",
      "428:\tlearn 0.6525438885\ttest 0.6364166084\tbestTest 0.6364166084\t\ttotal: 10m 5s\tremaining: 18m 8s\n",
      "429:\tlearn 0.6526222215\ttest 0.6364509992\tbestTest 0.6364509992\t\ttotal: 10m 7s\tremaining: 18m 7s\n",
      "430:\tlearn 0.652710926\ttest 0.6364711136\tbestTest 0.6364711136\t\ttotal: 10m 8s\tremaining: 18m 6s\n",
      "431:\tlearn 0.6527562859\ttest 0.636482792\tbestTest 0.636482792\t\ttotal: 10m 10s\tremaining: 18m 4s\n",
      "432:\tlearn 0.6528525441\ttest 0.6365033108\tbestTest 0.6365033108\t\ttotal: 10m 11s\tremaining: 18m 3s\n",
      "433:\tlearn 0.6528793003\ttest 0.6365153224\tbestTest 0.6365153224\t\ttotal: 10m 13s\tremaining: 18m 2s\n",
      "434:\tlearn 0.6529106957\ttest 0.6365149814\tbestTest 0.6365153224\t\ttotal: 10m 14s\tremaining: 18m 1s\n",
      "435:\tlearn 0.6529565778\ttest 0.636554794\tbestTest 0.636554794\t\ttotal: 10m 16s\tremaining: 17m 59s\n",
      "436:\tlearn 0.6529779557\ttest 0.6365581194\tbestTest 0.6365581194\t\ttotal: 10m 17s\tremaining: 17m 58s\n",
      "437:\tlearn 0.653025371\ttest 0.6365745492\tbestTest 0.6365745492\t\ttotal: 10m 19s\tremaining: 17m 57s\n",
      "438:\tlearn 0.6530439452\ttest 0.6365682472\tbestTest 0.6365745492\t\ttotal: 10m 20s\tremaining: 17m 56s\n",
      "439:\tlearn 0.6531236913\ttest 0.6365881567\tbestTest 0.6365881567\t\ttotal: 10m 22s\tremaining: 17m 54s\n",
      "440:\tlearn 0.6531730435\ttest 0.6365989795\tbestTest 0.6365989795\t\ttotal: 10m 23s\tremaining: 17m 53s\n",
      "441:\tlearn 0.6531815692\ttest 0.636604116\tbestTest 0.636604116\t\ttotal: 10m 25s\tremaining: 17m 51s\n",
      "442:\tlearn 0.6533065253\ttest 0.6366474873\tbestTest 0.6366474873\t\ttotal: 10m 26s\tremaining: 17m 50s\n",
      "443:\tlearn 0.6533658063\ttest 0.6366496471\tbestTest 0.6366496471\t\ttotal: 10m 28s\tremaining: 17m 49s\n",
      "444:\tlearn 0.653404543\ttest 0.6366530451\tbestTest 0.6366530451\t\ttotal: 10m 29s\tremaining: 17m 48s\n",
      "445:\tlearn 0.653414848\ttest 0.6366478853\tbestTest 0.6366530451\t\ttotal: 10m 31s\tremaining: 17m 46s\n",
      "446:\tlearn 0.6534405135\ttest 0.6366745104\tbestTest 0.6366745104\t\ttotal: 10m 32s\tremaining: 17m 46s\n",
      "447:\tlearn 0.6535022962\ttest 0.6366855574\tbestTest 0.6366855574\t\ttotal: 10m 34s\tremaining: 17m 44s\n",
      "448:\tlearn 0.6535364426\ttest 0.6366878093\tbestTest 0.6366878093\t\ttotal: 10m 35s\tremaining: 17m 43s\n",
      "449:\tlearn 0.6535803747\ttest 0.6367257317\tbestTest 0.6367257317\t\ttotal: 10m 37s\tremaining: 17m 42s\n",
      "450:\tlearn 0.6537013154\ttest 0.6367374412\tbestTest 0.6367374412\t\ttotal: 10m 38s\tremaining: 17m 40s\n",
      "451:\tlearn 0.65374531\ttest 0.6367425038\tbestTest 0.6367425038\t\ttotal: 10m 39s\tremaining: 17m 39s\n",
      "452:\tlearn 0.653803826\ttest 0.6367580041\tbestTest 0.6367580041\t\ttotal: 10m 41s\tremaining: 17m 37s\n",
      "453:\tlearn 0.6538410171\ttest 0.636775965\tbestTest 0.636775965\t\ttotal: 10m 42s\tremaining: 17m 36s\n",
      "454:\tlearn 0.6539001292\ttest 0.6367934593\tbestTest 0.6367934593\t\ttotal: 10m 44s\tremaining: 17m 35s\n",
      "455:\tlearn 0.65390467\ttest 0.6367910505\tbestTest 0.6367934593\t\ttotal: 10m 45s\tremaining: 17m 33s\n",
      "456:\tlearn 0.6539892978\ttest 0.6368130447\tbestTest 0.6368130447\t\ttotal: 10m 47s\tremaining: 17m 32s\n",
      "457:\tlearn 0.6540129028\ttest 0.6368410388\tbestTest 0.6368410388\t\ttotal: 10m 48s\tremaining: 17m 30s\n",
      "458:\tlearn 0.6540749581\ttest 0.6368549873\tbestTest 0.6368549873\t\ttotal: 10m 50s\tremaining: 17m 29s\n",
      "459:\tlearn 0.6541023227\ttest 0.6368503797\tbestTest 0.6368549873\t\ttotal: 10m 51s\tremaining: 17m 28s\n",
      "460:\tlearn 0.6541677586\ttest 0.6368351244\tbestTest 0.6368549873\t\ttotal: 10m 53s\tremaining: 17m 27s\n",
      "461:\tlearn 0.6542279741\ttest 0.6368419801\tbestTest 0.6368549873\t\ttotal: 10m 54s\tremaining: 17m 25s\n",
      "462:\tlearn 0.6542834046\ttest 0.6368594561\tbestTest 0.6368594561\t\ttotal: 10m 56s\tremaining: 17m 24s\n",
      "463:\tlearn 0.6543128058\ttest 0.6368666955\tbestTest 0.6368666955\t\ttotal: 10m 57s\tremaining: 17m 23s\n",
      "464:\tlearn 0.6543574946\ttest 0.6368541563\tbestTest 0.6368666955\t\ttotal: 10m 59s\tremaining: 17m 22s\n",
      "465:\tlearn 0.6544116041\ttest 0.636842509\tbestTest 0.6368666955\t\ttotal: 11m\tremaining: 17m 20s\n",
      "466:\tlearn 0.6544764686\ttest 0.6368806945\tbestTest 0.6368806945\t\ttotal: 11m 2s\tremaining: 17m 19s\n",
      "467:\tlearn 0.6545359452\ttest 0.6369110236\tbestTest 0.6369110236\t\ttotal: 11m 4s\tremaining: 17m 18s\n",
      "468:\tlearn 0.6545686668\ttest 0.6369284867\tbestTest 0.6369284867\t\ttotal: 11m 5s\tremaining: 17m 17s\n",
      "469:\tlearn 0.6545771741\ttest 0.6369359114\tbestTest 0.6369359114\t\ttotal: 11m 7s\tremaining: 17m 16s\n",
      "470:\tlearn 0.6546007228\ttest 0.6369376214\tbestTest 0.6369376214\t\ttotal: 11m 8s\tremaining: 17m 14s\n",
      "471:\tlearn 0.6546559601\ttest 0.6369637189\tbestTest 0.6369637189\t\ttotal: 11m 10s\tremaining: 17m 13s\n",
      "472:\tlearn 0.654715957\ttest 0.6370031659\tbestTest 0.6370031659\t\ttotal: 11m 11s\tremaining: 17m 12s\n",
      "473:\tlearn 0.6547735765\ttest 0.6370356042\tbestTest 0.6370356042\t\ttotal: 11m 13s\tremaining: 17m 11s\n",
      "474:\tlearn 0.6548196137\ttest 0.6370489343\tbestTest 0.6370489343\t\ttotal: 11m 14s\tremaining: 17m 10s\n",
      "475:\tlearn 0.6548529011\ttest 0.6370482433\tbestTest 0.6370489343\t\ttotal: 11m 16s\tremaining: 17m 8s\n",
      "476:\tlearn 0.6549416344\ttest 0.637083119\tbestTest 0.637083119\t\ttotal: 11m 17s\tremaining: 17m 7s\n",
      "477:\tlearn 0.6549797834\ttest 0.6370780239\tbestTest 0.637083119\t\ttotal: 11m 19s\tremaining: 17m 6s\n",
      "478:\tlearn 0.6549961874\ttest 0.6370818692\tbestTest 0.637083119\t\ttotal: 11m 20s\tremaining: 17m 4s\n",
      "479:\tlearn 0.6550470305\ttest 0.6370852335\tbestTest 0.6370852335\t\ttotal: 11m 22s\tremaining: 17m 3s\n",
      "480:\tlearn 0.6550708129\ttest 0.6370897607\tbestTest 0.6370897607\t\ttotal: 11m 23s\tremaining: 17m 2s\n",
      "481:\tlearn 0.6551404796\ttest 0.637133832\tbestTest 0.637133832\t\ttotal: 11m 25s\tremaining: 17m\n",
      "482:\tlearn 0.6552030181\ttest 0.6371455039\tbestTest 0.6371455039\t\ttotal: 11m 26s\tremaining: 16m 59s\n",
      "483:\tlearn 0.6552014346\ttest 0.637146755\tbestTest 0.637146755\t\ttotal: 11m 27s\tremaining: 16m 57s\n",
      "484:\tlearn 0.6552226597\ttest 0.6371401094\tbestTest 0.637146755\t\ttotal: 11m 29s\tremaining: 16m 55s\n",
      "485:\tlearn 0.6552970941\ttest 0.6371496642\tbestTest 0.6371496642\t\ttotal: 11m 30s\tremaining: 16m 54s\n",
      "486:\tlearn 0.6553340836\ttest 0.6371705124\tbestTest 0.6371705124\t\ttotal: 11m 32s\tremaining: 16m 53s\n",
      "487:\tlearn 0.6553390816\ttest 0.6371689852\tbestTest 0.6371705124\t\ttotal: 11m 33s\tremaining: 16m 51s\n",
      "488:\tlearn 0.6553683943\ttest 0.6371795914\tbestTest 0.6371795914\t\ttotal: 11m 34s\tremaining: 16m 50s\n",
      "489:\tlearn 0.6554107636\ttest 0.6371925649\tbestTest 0.6371925649\t\ttotal: 11m 36s\tremaining: 16m 49s\n",
      "490:\tlearn 0.655460166\ttest 0.6372311342\tbestTest 0.6372311342\t\ttotal: 11m 38s\tremaining: 16m 47s\n",
      "491:\tlearn 0.6555290033\ttest 0.6372235914\tbestTest 0.6372311342\t\ttotal: 11m 39s\tremaining: 16m 46s\n",
      "492:\tlearn 0.6555861744\ttest 0.6372289704\tbestTest 0.6372311342\t\ttotal: 11m 40s\tremaining: 16m 45s\n",
      "493:\tlearn 0.6556460796\ttest 0.6372501375\tbestTest 0.6372501375\t\ttotal: 11m 42s\tremaining: 16m 43s\n",
      "494:\tlearn 0.6556793877\ttest 0.6372718192\tbestTest 0.6372718192\t\ttotal: 11m 44s\tremaining: 16m 42s\n",
      "495:\tlearn 0.6557544555\ttest 0.6372771839\tbestTest 0.6372771839\t\ttotal: 11m 45s\tremaining: 16m 41s\n",
      "496:\tlearn 0.6557959604\ttest 0.6373050627\tbestTest 0.6373050627\t\ttotal: 11m 47s\tremaining: 16m 40s\n",
      "497:\tlearn 0.6558436097\ttest 0.637325999\tbestTest 0.637325999\t\ttotal: 11m 48s\tremaining: 16m 38s\n",
      "498:\tlearn 0.655854535\ttest 0.6373210855\tbestTest 0.637325999\t\ttotal: 11m 49s\tremaining: 16m 37s\n",
      "499:\tlearn 0.6558985251\ttest 0.6373247583\tbestTest 0.637325999\t\ttotal: 11m 51s\tremaining: 16m 35s\n",
      "500:\tlearn 0.6559454282\ttest 0.6373339112\tbestTest 0.6373339112\t\ttotal: 11m 52s\tremaining: 16m 34s\n",
      "501:\tlearn 0.6560095692\ttest 0.6373443165\tbestTest 0.6373443165\t\ttotal: 11m 54s\tremaining: 16m 33s\n",
      "502:\tlearn 0.6560663019\ttest 0.6373566496\tbestTest 0.6373566496\t\ttotal: 11m 55s\tremaining: 16m 31s\n",
      "503:\tlearn 0.6560793771\ttest 0.6373594408\tbestTest 0.6373594408\t\ttotal: 11m 56s\tremaining: 16m 30s\n",
      "504:\tlearn 0.6561058657\ttest 0.6373523687\tbestTest 0.6373594408\t\ttotal: 11m 58s\tremaining: 16m 28s\n",
      "505:\tlearn 0.6561570376\ttest 0.6373835223\tbestTest 0.6373835223\t\ttotal: 11m 59s\tremaining: 16m 27s\n",
      "506:\tlearn 0.6561773199\ttest 0.6373929462\tbestTest 0.6373929462\t\ttotal: 12m 1s\tremaining: 16m 25s\n",
      "507:\tlearn 0.6562425607\ttest 0.6374103043\tbestTest 0.6374103043\t\ttotal: 12m 2s\tremaining: 16m 24s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508:\tlearn 0.6562687352\ttest 0.6374214394\tbestTest 0.6374214394\t\ttotal: 12m 4s\tremaining: 16m 23s\n",
      "509:\tlearn 0.6562986885\ttest 0.6374404648\tbestTest 0.6374404648\t\ttotal: 12m 5s\tremaining: 16m 21s\n",
      "510:\tlearn 0.6563685475\ttest 0.6374632291\tbestTest 0.6374632291\t\ttotal: 12m 7s\tremaining: 16m 20s\n",
      "511:\tlearn 0.656394891\ttest 0.6374830738\tbestTest 0.6374830738\t\ttotal: 12m 9s\tremaining: 16m 19s\n",
      "512:\tlearn 0.6564017813\ttest 0.6374795941\tbestTest 0.6374830738\t\ttotal: 12m 10s\tremaining: 16m 17s\n",
      "513:\tlearn 0.6564798865\ttest 0.6375066652\tbestTest 0.6375066652\t\ttotal: 12m 11s\tremaining: 16m 16s\n",
      "514:\tlearn 0.6565488684\ttest 0.6374943334\tbestTest 0.6375066652\t\ttotal: 12m 13s\tremaining: 16m 15s\n",
      "515:\tlearn 0.6565788236\ttest 0.6375192083\tbestTest 0.6375192083\t\ttotal: 12m 14s\tremaining: 16m 14s\n",
      "516:\tlearn 0.6566088834\ttest 0.6375336559\tbestTest 0.6375336559\t\ttotal: 12m 16s\tremaining: 16m 12s\n",
      "517:\tlearn 0.6566378848\ttest 0.637551845\tbestTest 0.637551845\t\ttotal: 12m 17s\tremaining: 16m 11s\n",
      "518:\tlearn 0.6566905237\ttest 0.6375664145\tbestTest 0.6375664145\t\ttotal: 12m 19s\tremaining: 16m 10s\n",
      "519:\tlearn 0.6567331103\ttest 0.6375741659\tbestTest 0.6375741659\t\ttotal: 12m 20s\tremaining: 16m 8s\n",
      "520:\tlearn 0.6567565547\ttest 0.637592862\tbestTest 0.637592862\t\ttotal: 12m 22s\tremaining: 16m 7s\n",
      "521:\tlearn 0.6568253957\ttest 0.6376024725\tbestTest 0.6376024725\t\ttotal: 12m 24s\tremaining: 16m 6s\n",
      "522:\tlearn 0.6569171037\ttest 0.6376156353\tbestTest 0.6376156353\t\ttotal: 12m 25s\tremaining: 16m 5s\n",
      "523:\tlearn 0.656962037\ttest 0.6376318863\tbestTest 0.6376318863\t\ttotal: 12m 26s\tremaining: 16m 3s\n",
      "524:\tlearn 0.6570066212\ttest 0.6376173389\tbestTest 0.6376318863\t\ttotal: 12m 28s\tremaining: 16m 2s\n",
      "525:\tlearn 0.6571197004\ttest 0.6376560067\tbestTest 0.6376560067\t\ttotal: 12m 29s\tremaining: 16m\n",
      "526:\tlearn 0.6571925487\ttest 0.6376710688\tbestTest 0.6376710688\t\ttotal: 12m 31s\tremaining: 15m 59s\n",
      "527:\tlearn 0.6572554858\ttest 0.6376908772\tbestTest 0.6376908772\t\ttotal: 12m 33s\tremaining: 15m 58s\n",
      "528:\tlearn 0.6572908427\ttest 0.6377138385\tbestTest 0.6377138385\t\ttotal: 12m 34s\tremaining: 15m 57s\n",
      "529:\tlearn 0.6573094108\ttest 0.6377148394\tbestTest 0.6377148394\t\ttotal: 12m 36s\tremaining: 15m 56s\n",
      "530:\tlearn 0.6573895965\ttest 0.6377642625\tbestTest 0.6377642625\t\ttotal: 12m 37s\tremaining: 15m 54s\n",
      "531:\tlearn 0.6574206914\ttest 0.6377667322\tbestTest 0.6377667322\t\ttotal: 12m 39s\tremaining: 15m 53s\n",
      "532:\tlearn 0.6574528133\ttest 0.6378000249\tbestTest 0.6378000249\t\ttotal: 12m 40s\tremaining: 15m 52s\n",
      "533:\tlearn 0.6575069536\ttest 0.6378221021\tbestTest 0.6378221021\t\ttotal: 12m 42s\tremaining: 15m 50s\n",
      "534:\tlearn 0.6575550341\ttest 0.6378502311\tbestTest 0.6378502311\t\ttotal: 12m 43s\tremaining: 15m 49s\n",
      "535:\tlearn 0.6575536157\ttest 0.6378492964\tbestTest 0.6378502311\t\ttotal: 12m 44s\tremaining: 15m 47s\n",
      "536:\tlearn 0.6575772641\ttest 0.6378400618\tbestTest 0.6378502311\t\ttotal: 12m 46s\tremaining: 15m 45s\n",
      "537:\tlearn 0.6576461959\ttest 0.6378591053\tbestTest 0.6378591053\t\ttotal: 12m 47s\tremaining: 15m 44s\n",
      "538:\tlearn 0.6577235269\ttest 0.6378456456\tbestTest 0.6378591053\t\ttotal: 12m 48s\tremaining: 15m 43s\n",
      "539:\tlearn 0.6577831209\ttest 0.6378500963\tbestTest 0.6378591053\t\ttotal: 12m 50s\tremaining: 15m 41s\n",
      "540:\tlearn 0.6578428639\ttest 0.6378646644\tbestTest 0.6378646644\t\ttotal: 12m 51s\tremaining: 15m 40s\n",
      "541:\tlearn 0.6579274452\ttest 0.6378634691\tbestTest 0.6378646644\t\ttotal: 12m 53s\tremaining: 15m 38s\n",
      "542:\tlearn 0.6579740252\ttest 0.6378593749\tbestTest 0.6378646644\t\ttotal: 12m 54s\tremaining: 15m 37s\n",
      "543:\tlearn 0.6580729926\ttest 0.6378659012\tbestTest 0.6378659012\t\ttotal: 12m 56s\tremaining: 15m 35s\n",
      "544:\tlearn 0.658227685\ttest 0.6379213502\tbestTest 0.6379213502\t\ttotal: 12m 57s\tremaining: 15m 34s\n",
      "545:\tlearn 0.6582568217\ttest 0.6379175516\tbestTest 0.6379213502\t\ttotal: 12m 59s\tremaining: 15m 33s\n",
      "546:\tlearn 0.6582962973\ttest 0.6379182634\tbestTest 0.6379213502\t\ttotal: 13m\tremaining: 15m 31s\n",
      "547:\tlearn 0.6583405874\ttest 0.6379174129\tbestTest 0.6379213502\t\ttotal: 13m 1s\tremaining: 15m 30s\n",
      "548:\tlearn 0.6583688249\ttest 0.6379346738\tbestTest 0.6379346738\t\ttotal: 13m 3s\tremaining: 15m 28s\n",
      "549:\tlearn 0.6584208693\ttest 0.6379497385\tbestTest 0.6379497385\t\ttotal: 13m 4s\tremaining: 15m 27s\n",
      "550:\tlearn 0.6584621576\ttest 0.63795777\tbestTest 0.63795777\t\ttotal: 13m 6s\tremaining: 15m 26s\n",
      "551:\tlearn 0.6585180315\ttest 0.6379407697\tbestTest 0.63795777\t\ttotal: 13m 7s\tremaining: 15m 24s\n",
      "552:\tlearn 0.6585514226\ttest 0.6379228606\tbestTest 0.63795777\t\ttotal: 13m 9s\tremaining: 15m 23s\n",
      "553:\tlearn 0.658559581\ttest 0.6379278571\tbestTest 0.63795777\t\ttotal: 13m 10s\tremaining: 15m 22s\n",
      "554:\tlearn 0.6586113147\ttest 0.6379585349\tbestTest 0.6379585349\t\ttotal: 13m 12s\tremaining: 15m 20s\n",
      "555:\tlearn 0.6586976977\ttest 0.637990421\tbestTest 0.637990421\t\ttotal: 13m 13s\tremaining: 15m 19s\n",
      "556:\tlearn 0.6587230144\ttest 0.6379915657\tbestTest 0.6379915657\t\ttotal: 13m 15s\tremaining: 15m 18s\n",
      "557:\tlearn 0.6587760796\ttest 0.6379797136\tbestTest 0.6379915657\t\ttotal: 13m 17s\tremaining: 15m 17s\n",
      "558:\tlearn 0.6588143806\ttest 0.6379797071\tbestTest 0.6379915657\t\ttotal: 13m 18s\tremaining: 15m 15s\n",
      "559:\tlearn 0.6588744637\ttest 0.6379880238\tbestTest 0.6379915657\t\ttotal: 13m 20s\tremaining: 15m 14s\n",
      "560:\tlearn 0.6588998993\ttest 0.6380013681\tbestTest 0.6380013681\t\ttotal: 13m 21s\tremaining: 15m 12s\n",
      "561:\tlearn 0.658957692\ttest 0.6380232042\tbestTest 0.6380232042\t\ttotal: 13m 23s\tremaining: 15m 11s\n",
      "562:\tlearn 0.658993604\ttest 0.6380255857\tbestTest 0.6380255857\t\ttotal: 13m 24s\tremaining: 15m 10s\n",
      "563:\tlearn 0.659047024\ttest 0.6380400204\tbestTest 0.6380400204\t\ttotal: 13m 25s\tremaining: 15m 8s\n",
      "564:\tlearn 0.659074091\ttest 0.638058063\tbestTest 0.638058063\t\ttotal: 13m 27s\tremaining: 15m 7s\n",
      "565:\tlearn 0.6590816272\ttest 0.6380555375\tbestTest 0.638058063\t\ttotal: 13m 28s\tremaining: 15m 6s\n",
      "566:\tlearn 0.659098862\ttest 0.6380527554\tbestTest 0.638058063\t\ttotal: 13m 30s\tremaining: 15m 4s\n",
      "567:\tlearn 0.6591236743\ttest 0.6380499097\tbestTest 0.638058063\t\ttotal: 13m 31s\tremaining: 15m 3s\n",
      "568:\tlearn 0.6591608092\ttest 0.6380606183\tbestTest 0.6380606183\t\ttotal: 13m 33s\tremaining: 15m 1s\n",
      "569:\tlearn 0.6591768678\ttest 0.6380600673\tbestTest 0.6380606183\t\ttotal: 13m 34s\tremaining: 15m\n",
      "570:\tlearn 0.6592374379\ttest 0.6380772569\tbestTest 0.6380772569\t\ttotal: 13m 36s\tremaining: 14m 59s\n",
      "571:\tlearn 0.6592741874\ttest 0.6380543435\tbestTest 0.6380772569\t\ttotal: 13m 37s\tremaining: 14m 57s\n",
      "572:\tlearn 0.6592786708\ttest 0.638054748\tbestTest 0.6380772569\t\ttotal: 13m 39s\tremaining: 14m 56s\n",
      "573:\tlearn 0.6593291945\ttest 0.6380363838\tbestTest 0.6380772569\t\ttotal: 13m 40s\tremaining: 14m 54s\n",
      "574:\tlearn 0.6593704724\ttest 0.6380525285\tbestTest 0.6380772569\t\ttotal: 13m 42s\tremaining: 14m 53s\n",
      "575:\tlearn 0.6594093348\ttest 0.6380648551\tbestTest 0.6380772569\t\ttotal: 13m 43s\tremaining: 14m 52s\n",
      "576:\tlearn 0.6594462237\ttest 0.6380601075\tbestTest 0.6380772569\t\ttotal: 13m 44s\tremaining: 14m 50s\n",
      "577:\tlearn 0.6594470426\ttest 0.6380595889\tbestTest 0.6380772569\t\ttotal: 13m 45s\tremaining: 14m 48s\n",
      "578:\tlearn 0.6595029042\ttest 0.6380770702\tbestTest 0.6380772569\t\ttotal: 13m 47s\tremaining: 14m 47s\n",
      "579:\tlearn 0.6595451497\ttest 0.6380869595\tbestTest 0.6380869595\t\ttotal: 13m 48s\tremaining: 14m 45s\n",
      "580:\tlearn 0.6596347701\ttest 0.6381116671\tbestTest 0.6381116671\t\ttotal: 13m 50s\tremaining: 14m 44s\n",
      "581:\tlearn 0.6596710584\ttest 0.6381027372\tbestTest 0.6381116671\t\ttotal: 13m 51s\tremaining: 14m 43s\n",
      "582:\tlearn 0.6597271592\ttest 0.6381112588\tbestTest 0.6381116671\t\ttotal: 13m 53s\tremaining: 14m 41s\n",
      "583:\tlearn 0.6597644825\ttest 0.6381129804\tbestTest 0.6381129804\t\ttotal: 13m 54s\tremaining: 14m 40s\n",
      "584:\tlearn 0.6597852255\ttest 0.6381328303\tbestTest 0.6381328303\t\ttotal: 13m 55s\tremaining: 14m 38s\n",
      "585:\tlearn 0.6598345917\ttest 0.6381479845\tbestTest 0.6381479845\t\ttotal: 13m 57s\tremaining: 14m 37s\n",
      "586:\tlearn 0.6598632705\ttest 0.6381541983\tbestTest 0.6381541983\t\ttotal: 13m 58s\tremaining: 14m 35s\n",
      "587:\tlearn 0.6598910894\ttest 0.6381614857\tbestTest 0.6381614857\t\ttotal: 14m\tremaining: 14m 34s\n",
      "588:\tlearn 0.6599011199\ttest 0.6381614986\tbestTest 0.6381614986\t\ttotal: 14m 1s\tremaining: 14m 33s\n",
      "589:\tlearn 0.6599169561\ttest 0.6381657847\tbestTest 0.6381657847\t\ttotal: 14m 3s\tremaining: 14m 31s\n",
      "590:\tlearn 0.6599683566\ttest 0.6381624749\tbestTest 0.6381657847\t\ttotal: 14m 4s\tremaining: 14m 30s\n",
      "591:\tlearn 0.6600187034\ttest 0.6381677682\tbestTest 0.6381677682\t\ttotal: 14m 6s\tremaining: 14m 29s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592:\tlearn 0.6600944575\ttest 0.6381653193\tbestTest 0.6381677682\t\ttotal: 14m 7s\tremaining: 14m 27s\n",
      "593:\tlearn 0.6601157978\ttest 0.6381824401\tbestTest 0.6381824401\t\ttotal: 14m 9s\tremaining: 14m 26s\n",
      "594:\tlearn 0.6601374262\ttest 0.6381836471\tbestTest 0.6381836471\t\ttotal: 14m 10s\tremaining: 14m 24s\n",
      "595:\tlearn 0.6602297367\ttest 0.6382167389\tbestTest 0.6382167389\t\ttotal: 14m 12s\tremaining: 14m 23s\n",
      "596:\tlearn 0.6602614265\ttest 0.6382157562\tbestTest 0.6382167389\t\ttotal: 14m 13s\tremaining: 14m 21s\n",
      "597:\tlearn 0.66028839\ttest 0.6382226572\tbestTest 0.6382226572\t\ttotal: 14m 14s\tremaining: 14m 20s\n",
      "598:\tlearn 0.6603129037\ttest 0.6382313446\tbestTest 0.6382313446\t\ttotal: 14m 16s\tremaining: 14m 19s\n",
      "599:\tlearn 0.6603247654\ttest 0.6382343394\tbestTest 0.6382343394\t\ttotal: 14m 17s\tremaining: 14m 17s\n",
      "600:\tlearn 0.6603875944\ttest 0.6382510908\tbestTest 0.6382510908\t\ttotal: 14m 18s\tremaining: 14m 16s\n",
      "601:\tlearn 0.6604215444\ttest 0.638265786\tbestTest 0.638265786\t\ttotal: 14m 20s\tremaining: 14m 14s\n",
      "602:\tlearn 0.6605255903\ttest 0.6382779778\tbestTest 0.6382779778\t\ttotal: 14m 21s\tremaining: 14m 13s\n",
      "603:\tlearn 0.6605551933\ttest 0.6382938878\tbestTest 0.6382938878\t\ttotal: 14m 23s\tremaining: 14m 11s\n",
      "604:\tlearn 0.6606344869\ttest 0.6383019296\tbestTest 0.6383019296\t\ttotal: 14m 24s\tremaining: 14m 10s\n",
      "605:\tlearn 0.6606398413\ttest 0.6383053847\tbestTest 0.6383053847\t\ttotal: 14m 26s\tremaining: 14m 9s\n",
      "606:\tlearn 0.6606555047\ttest 0.6383255094\tbestTest 0.6383255094\t\ttotal: 14m 27s\tremaining: 14m 7s\n",
      "607:\tlearn 0.6607112393\ttest 0.6383344951\tbestTest 0.6383344951\t\ttotal: 14m 29s\tremaining: 14m 6s\n",
      "608:\tlearn 0.6607638031\ttest 0.6383502624\tbestTest 0.6383502624\t\ttotal: 14m 30s\tremaining: 14m 5s\n",
      "609:\tlearn 0.6607823859\ttest 0.638347186\tbestTest 0.6383502624\t\ttotal: 14m 32s\tremaining: 14m 3s\n",
      "610:\tlearn 0.6608128127\ttest 0.6383627615\tbestTest 0.6383627615\t\ttotal: 14m 33s\tremaining: 14m 2s\n",
      "611:\tlearn 0.6608310672\ttest 0.6383592546\tbestTest 0.6383627615\t\ttotal: 14m 35s\tremaining: 14m 1s\n",
      "612:\tlearn 0.6608790649\ttest 0.6383407854\tbestTest 0.6383627615\t\ttotal: 14m 36s\tremaining: 13m 59s\n",
      "613:\tlearn 0.6609214872\ttest 0.638352972\tbestTest 0.6383627615\t\ttotal: 14m 38s\tremaining: 13m 58s\n",
      "614:\tlearn 0.6609555926\ttest 0.6383666975\tbestTest 0.6383666975\t\ttotal: 14m 39s\tremaining: 13m 57s\n",
      "615:\tlearn 0.6609889532\ttest 0.6383816792\tbestTest 0.6383816792\t\ttotal: 14m 41s\tremaining: 13m 55s\n",
      "616:\tlearn 0.6610088123\ttest 0.6383876869\tbestTest 0.6383876869\t\ttotal: 14m 43s\tremaining: 13m 54s\n",
      "617:\tlearn 0.6610685624\ttest 0.6383691063\tbestTest 0.6383876869\t\ttotal: 14m 44s\tremaining: 13m 53s\n",
      "618:\tlearn 0.6611007577\ttest 0.638376286\tbestTest 0.6383876869\t\ttotal: 14m 46s\tremaining: 13m 51s\n",
      "619:\tlearn 0.6611466529\ttest 0.6383831584\tbestTest 0.6383876869\t\ttotal: 14m 47s\tremaining: 13m 50s\n",
      "620:\tlearn 0.6611847362\ttest 0.6383975334\tbestTest 0.6383975334\t\ttotal: 14m 49s\tremaining: 13m 49s\n",
      "621:\tlearn 0.6612297922\ttest 0.6383995287\tbestTest 0.6383995287\t\ttotal: 14m 50s\tremaining: 13m 47s\n",
      "622:\tlearn 0.6612594507\ttest 0.6384067512\tbestTest 0.6384067512\t\ttotal: 14m 52s\tremaining: 13m 46s\n",
      "623:\tlearn 0.6612902805\ttest 0.638395275\tbestTest 0.6384067512\t\ttotal: 14m 53s\tremaining: 13m 44s\n",
      "624:\tlearn 0.661303921\ttest 0.6384005464\tbestTest 0.6384067512\t\ttotal: 14m 55s\tremaining: 13m 43s\n",
      "625:\tlearn 0.6613360745\ttest 0.6383862894\tbestTest 0.6384067512\t\ttotal: 14m 56s\tremaining: 13m 42s\n",
      "626:\tlearn 0.661394937\ttest 0.6383893982\tbestTest 0.6384067512\t\ttotal: 14m 57s\tremaining: 13m 40s\n",
      "627:\tlearn 0.6614748878\ttest 0.6383876428\tbestTest 0.6384067512\t\ttotal: 14m 59s\tremaining: 13m 39s\n",
      "628:\tlearn 0.6614865661\ttest 0.638393224\tbestTest 0.6384067512\t\ttotal: 15m\tremaining: 13m 37s\n",
      "629:\tlearn 0.6615256009\ttest 0.6384095411\tbestTest 0.6384095411\t\ttotal: 15m 2s\tremaining: 13m 36s\n",
      "630:\tlearn 0.6615455261\ttest 0.6384215462\tbestTest 0.6384215462\t\ttotal: 15m 3s\tremaining: 13m 34s\n",
      "631:\tlearn 0.6615729813\ttest 0.6384373628\tbestTest 0.6384373628\t\ttotal: 15m 4s\tremaining: 13m 33s\n",
      "632:\tlearn 0.6616006304\ttest 0.6384456406\tbestTest 0.6384456406\t\ttotal: 15m 6s\tremaining: 13m 31s\n",
      "633:\tlearn 0.6616219583\ttest 0.638447059\tbestTest 0.638447059\t\ttotal: 15m 7s\tremaining: 13m 30s\n",
      "634:\tlearn 0.661642647\ttest 0.6384652248\tbestTest 0.6384652248\t\ttotal: 15m 9s\tremaining: 13m 28s\n",
      "635:\tlearn 0.6616872185\ttest 0.6384626202\tbestTest 0.6384652248\t\ttotal: 15m 10s\tremaining: 13m 27s\n",
      "636:\tlearn 0.6617170554\ttest 0.6384659637\tbestTest 0.6384659637\t\ttotal: 15m 11s\tremaining: 13m 25s\n",
      "637:\tlearn 0.6617479752\ttest 0.6384460685\tbestTest 0.6384659637\t\ttotal: 15m 13s\tremaining: 13m 24s\n",
      "638:\tlearn 0.6617649342\ttest 0.6384538355\tbestTest 0.6384659637\t\ttotal: 15m 14s\tremaining: 13m 22s\n",
      "639:\tlearn 0.6618029679\ttest 0.6384405677\tbestTest 0.6384659637\t\ttotal: 15m 16s\tremaining: 13m 21s\n",
      "640:\tlearn 0.6618662957\ttest 0.6384436013\tbestTest 0.6384659637\t\ttotal: 15m 17s\tremaining: 13m 20s\n",
      "641:\tlearn 0.6618835054\ttest 0.638455456\tbestTest 0.6384659637\t\ttotal: 15m 19s\tremaining: 13m 18s\n",
      "642:\tlearn 0.6619651556\ttest 0.6384864761\tbestTest 0.6384864761\t\ttotal: 15m 20s\tremaining: 13m 17s\n",
      "643:\tlearn 0.6619776846\ttest 0.6384839014\tbestTest 0.6384864761\t\ttotal: 15m 21s\tremaining: 13m 16s\n",
      "644:\tlearn 0.6619869942\ttest 0.6384860262\tbestTest 0.6384864761\t\ttotal: 15m 23s\tremaining: 13m 14s\n",
      "645:\tlearn 0.6620207668\ttest 0.638482894\tbestTest 0.6384864761\t\ttotal: 15m 25s\tremaining: 13m 13s\n",
      "646:\tlearn 0.6620554294\ttest 0.6384831922\tbestTest 0.6384864761\t\ttotal: 15m 26s\tremaining: 13m 11s\n",
      "647:\tlearn 0.6620770564\ttest 0.6384841464\tbestTest 0.6384864761\t\ttotal: 15m 27s\tremaining: 13m 10s\n",
      "648:\tlearn 0.6621393206\ttest 0.6384920975\tbestTest 0.6384920975\t\ttotal: 15m 29s\tremaining: 13m 8s\n",
      "649:\tlearn 0.6621770269\ttest 0.6384907388\tbestTest 0.6384920975\t\ttotal: 15m 30s\tremaining: 13m 7s\n",
      "650:\tlearn 0.662233136\ttest 0.6385071427\tbestTest 0.6385071427\t\ttotal: 15m 31s\tremaining: 13m 5s\n",
      "651:\tlearn 0.6623031321\ttest 0.6385116621\tbestTest 0.6385116621\t\ttotal: 15m 33s\tremaining: 13m 4s\n",
      "652:\tlearn 0.6623257543\ttest 0.6384917708\tbestTest 0.6385116621\t\ttotal: 15m 34s\tremaining: 13m 2s\n",
      "653:\tlearn 0.6623894933\ttest 0.6385019557\tbestTest 0.6385116621\t\ttotal: 15m 36s\tremaining: 13m 1s\n",
      "654:\tlearn 0.6624316249\ttest 0.6385216876\tbestTest 0.6385216876\t\ttotal: 15m 37s\tremaining: 13m\n",
      "655:\tlearn 0.6624592421\ttest 0.6385158678\tbestTest 0.6385216876\t\ttotal: 15m 39s\tremaining: 12m 58s\n",
      "656:\tlearn 0.6624826985\ttest 0.6385077132\tbestTest 0.6385216876\t\ttotal: 15m 40s\tremaining: 12m 57s\n",
      "657:\tlearn 0.6625409624\ttest 0.6385164149\tbestTest 0.6385216876\t\ttotal: 15m 42s\tremaining: 12m 56s\n",
      "658:\tlearn 0.6625450856\ttest 0.6385161699\tbestTest 0.6385216876\t\ttotal: 15m 43s\tremaining: 12m 54s\n",
      "659:\tlearn 0.6625558074\ttest 0.6385271793\tbestTest 0.6385271793\t\ttotal: 15m 45s\tremaining: 12m 53s\n",
      "660:\tlearn 0.662587862\ttest 0.6385475063\tbestTest 0.6385475063\t\ttotal: 15m 46s\tremaining: 12m 52s\n",
      "661:\tlearn 0.6626091418\ttest 0.6385588139\tbestTest 0.6385588139\t\ttotal: 15m 48s\tremaining: 12m 50s\n",
      "662:\tlearn 0.6626619138\ttest 0.638580156\tbestTest 0.638580156\t\ttotal: 15m 50s\tremaining: 12m 49s\n",
      "663:\tlearn 0.6626976122\ttest 0.6385861468\tbestTest 0.6385861468\t\ttotal: 15m 51s\tremaining: 12m 48s\n",
      "664:\tlearn 0.6627505716\ttest 0.6385807458\tbestTest 0.6385861468\t\ttotal: 15m 53s\tremaining: 12m 46s\n",
      "665:\tlearn 0.6627700046\ttest 0.6385730501\tbestTest 0.6385861468\t\ttotal: 15m 54s\tremaining: 12m 45s\n",
      "666:\tlearn 0.6627870593\ttest 0.6385668778\tbestTest 0.6385861468\t\ttotal: 15m 56s\tremaining: 12m 44s\n",
      "667:\tlearn 0.6628101591\ttest 0.638585111\tbestTest 0.6385861468\t\ttotal: 15m 58s\tremaining: 12m 42s\n",
      "668:\tlearn 0.6628603661\ttest 0.6385938568\tbestTest 0.6385938568\t\ttotal: 15m 59s\tremaining: 12m 41s\n",
      "669:\tlearn 0.6628781594\ttest 0.6385903512\tbestTest 0.6385938568\t\ttotal: 16m 1s\tremaining: 12m 40s\n",
      "670:\tlearn 0.6629275567\ttest 0.6385703172\tbestTest 0.6385938568\t\ttotal: 16m 2s\tremaining: 12m 38s\n",
      "671:\tlearn 0.6629514301\ttest 0.6385973105\tbestTest 0.6385973105\t\ttotal: 16m 3s\tremaining: 12m 37s\n",
      "672:\tlearn 0.6629976571\ttest 0.6385953335\tbestTest 0.6385973105\t\ttotal: 16m 5s\tremaining: 12m 36s\n",
      "673:\tlearn 0.6630274492\ttest 0.6385950845\tbestTest 0.6385973105\t\ttotal: 16m 6s\tremaining: 12m 34s\n",
      "674:\tlearn 0.6630894896\ttest 0.6385940111\tbestTest 0.6385973105\t\ttotal: 16m 8s\tremaining: 12m 33s\n",
      "675:\tlearn 0.6631360092\ttest 0.6385912704\tbestTest 0.6385973105\t\ttotal: 16m 10s\tremaining: 12m 31s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676:\tlearn 0.6631468097\ttest 0.6385782476\tbestTest 0.6385973105\t\ttotal: 16m 11s\tremaining: 12m 30s\n",
      "677:\tlearn 0.663155372\ttest 0.6385825583\tbestTest 0.6385973105\t\ttotal: 16m 13s\tremaining: 12m 29s\n",
      "678:\tlearn 0.6632051474\ttest 0.638584901\tbestTest 0.6385973105\t\ttotal: 16m 14s\tremaining: 12m 28s\n",
      "679:\tlearn 0.6632582322\ttest 0.6386147166\tbestTest 0.6386147166\t\ttotal: 16m 16s\tremaining: 12m 26s\n",
      "680:\tlearn 0.6632834626\ttest 0.6386073424\tbestTest 0.6386147166\t\ttotal: 16m 18s\tremaining: 12m 25s\n",
      "681:\tlearn 0.6633101336\ttest 0.6385998606\tbestTest 0.6386147166\t\ttotal: 16m 19s\tremaining: 12m 24s\n",
      "682:\tlearn 0.6633544073\ttest 0.6386054107\tbestTest 0.6386147166\t\ttotal: 16m 21s\tremaining: 12m 22s\n",
      "683:\tlearn 0.6633862239\ttest 0.6386020828\tbestTest 0.6386147166\t\ttotal: 16m 22s\tremaining: 12m 21s\n",
      "684:\tlearn 0.6634388008\ttest 0.638608036\tbestTest 0.6386147166\t\ttotal: 16m 24s\tremaining: 12m 20s\n",
      "685:\tlearn 0.6634938507\ttest 0.6386304218\tbestTest 0.6386304218\t\ttotal: 16m 25s\tremaining: 12m 18s\n",
      "686:\tlearn 0.6635126648\ttest 0.6386328837\tbestTest 0.6386328837\t\ttotal: 16m 27s\tremaining: 12m 17s\n",
      "687:\tlearn 0.6635495922\ttest 0.6386278833\tbestTest 0.6386328837\t\ttotal: 16m 28s\tremaining: 12m 15s\n",
      "688:\tlearn 0.6635778363\ttest 0.6386331949\tbestTest 0.6386331949\t\ttotal: 16m 30s\tremaining: 12m 14s\n",
      "689:\tlearn 0.6636014118\ttest 0.638653575\tbestTest 0.638653575\t\ttotal: 16m 31s\tremaining: 12m 13s\n",
      "690:\tlearn 0.6635988723\ttest 0.6386494627\tbestTest 0.638653575\t\ttotal: 16m 33s\tremaining: 12m 11s\n",
      "691:\tlearn 0.6636250588\ttest 0.638654747\tbestTest 0.638654747\t\ttotal: 16m 34s\tremaining: 12m 10s\n",
      "692:\tlearn 0.6636443631\ttest 0.6386617841\tbestTest 0.6386617841\t\ttotal: 16m 36s\tremaining: 12m 8s\n",
      "693:\tlearn 0.663674332\ttest 0.6386519765\tbestTest 0.6386617841\t\ttotal: 16m 37s\tremaining: 12m 7s\n",
      "694:\tlearn 0.6637036417\ttest 0.6386704716\tbestTest 0.6386704716\t\ttotal: 16m 39s\tremaining: 12m 6s\n",
      "695:\tlearn 0.6637632232\ttest 0.638711858\tbestTest 0.638711858\t\ttotal: 16m 40s\tremaining: 12m 4s\n",
      "696:\tlearn 0.6637801227\ttest 0.63869398\tbestTest 0.638711858\t\ttotal: 16m 42s\tremaining: 12m 3s\n",
      "697:\tlearn 0.6638128153\ttest 0.6386927743\tbestTest 0.638711858\t\ttotal: 16m 43s\tremaining: 12m 1s\n",
      "698:\tlearn 0.6638432501\ttest 0.638695563\tbestTest 0.638711858\t\ttotal: 16m 45s\tremaining: 12m\n",
      "699:\tlearn 0.6638522317\ttest 0.6387039575\tbestTest 0.638711858\t\ttotal: 16m 46s\tremaining: 11m 58s\n",
      "700:\tlearn 0.6638717829\ttest 0.6386948564\tbestTest 0.638711858\t\ttotal: 16m 47s\tremaining: 11m 57s\n",
      "701:\tlearn 0.663897231\ttest 0.6387063805\tbestTest 0.638711858\t\ttotal: 16m 49s\tremaining: 11m 56s\n",
      "702:\tlearn 0.6639358166\ttest 0.6387141034\tbestTest 0.6387141034\t\ttotal: 16m 50s\tremaining: 11m 54s\n",
      "703:\tlearn 0.6639594105\ttest 0.6387299058\tbestTest 0.6387299058\t\ttotal: 16m 52s\tremaining: 11m 53s\n",
      "704:\tlearn 0.6640106328\ttest 0.6387390276\tbestTest 0.6387390276\t\ttotal: 16m 53s\tremaining: 11m 51s\n",
      "705:\tlearn 0.6640495079\ttest 0.63873564\tbestTest 0.6387390276\t\ttotal: 16m 55s\tremaining: 11m 50s\n",
      "706:\tlearn 0.6640633784\ttest 0.6387389835\tbestTest 0.6387390276\t\ttotal: 16m 56s\tremaining: 11m 48s\n",
      "707:\tlearn 0.6640921029\ttest 0.6387464757\tbestTest 0.6387464757\t\ttotal: 16m 57s\tremaining: 11m 47s\n",
      "708:\tlearn 0.6641388689\ttest 0.6387607794\tbestTest 0.6387607794\t\ttotal: 16m 59s\tremaining: 11m 45s\n",
      "709:\tlearn 0.6642092222\ttest 0.6387875601\tbestTest 0.6387875601\t\ttotal: 17m\tremaining: 11m 44s\n",
      "710:\tlearn 0.6642410815\ttest 0.6387639738\tbestTest 0.6387875601\t\ttotal: 17m 2s\tremaining: 11m 42s\n",
      "711:\tlearn 0.6643295714\ttest 0.6387398534\tbestTest 0.6387875601\t\ttotal: 17m 3s\tremaining: 11m 41s\n",
      "712:\tlearn 0.6643662038\ttest 0.6387472899\tbestTest 0.6387875601\t\ttotal: 17m 5s\tremaining: 11m 40s\n",
      "713:\tlearn 0.6643882473\ttest 0.638756925\tbestTest 0.6387875601\t\ttotal: 17m 6s\tremaining: 11m 38s\n",
      "714:\tlearn 0.6644085931\ttest 0.6387651769\tbestTest 0.6387875601\t\ttotal: 17m 8s\tremaining: 11m 37s\n",
      "715:\tlearn 0.6644387879\ttest 0.6387643174\tbestTest 0.6387875601\t\ttotal: 17m 10s\tremaining: 11m 36s\n",
      "716:\tlearn 0.6644414325\ttest 0.6387529177\tbestTest 0.6387875601\t\ttotal: 17m 11s\tremaining: 11m 35s\n",
      "717:\tlearn 0.6644931004\ttest 0.6387430673\tbestTest 0.6387875601\t\ttotal: 17m 13s\tremaining: 11m 33s\n",
      "718:\tlearn 0.6645589195\ttest 0.6387609142\tbestTest 0.6387875601\t\ttotal: 17m 15s\tremaining: 11m 32s\n",
      "719:\tlearn 0.6645946125\ttest 0.6387621925\tbestTest 0.6387875601\t\ttotal: 17m 16s\tremaining: 11m 31s\n",
      "720:\tlearn 0.6646623643\ttest 0.6387730412\tbestTest 0.6387875601\t\ttotal: 17m 18s\tremaining: 11m 30s\n",
      "721:\tlearn 0.6647580834\ttest 0.6387839313\tbestTest 0.6387875601\t\ttotal: 17m 20s\tremaining: 11m 28s\n",
      "722:\tlearn 0.6647950182\ttest 0.6387831068\tbestTest 0.6387875601\t\ttotal: 17m 21s\tremaining: 11m 27s\n",
      "723:\tlearn 0.6648067972\ttest 0.6387733653\tbestTest 0.6387875601\t\ttotal: 17m 23s\tremaining: 11m 25s\n",
      "724:\tlearn 0.6648347729\ttest 0.6387906404\tbestTest 0.6387906404\t\ttotal: 17m 24s\tremaining: 11m 24s\n",
      "725:\tlearn 0.6648443947\ttest 0.6387964096\tbestTest 0.6387964096\t\ttotal: 17m 26s\tremaining: 11m 23s\n",
      "726:\tlearn 0.6649038689\ttest 0.6388190857\tbestTest 0.6388190857\t\ttotal: 17m 27s\tremaining: 11m 21s\n",
      "727:\tlearn 0.6649090731\ttest 0.6388146947\tbestTest 0.6388190857\t\ttotal: 17m 29s\tremaining: 11m 20s\n",
      "728:\tlearn 0.6649553946\ttest 0.6388014878\tbestTest 0.6388190857\t\ttotal: 17m 31s\tremaining: 11m 19s\n",
      "729:\tlearn 0.6649672911\ttest 0.6388072634\tbestTest 0.6388190857\t\ttotal: 17m 32s\tremaining: 11m 17s\n",
      "730:\tlearn 0.6650189043\ttest 0.6388047509\tbestTest 0.6388190857\t\ttotal: 17m 34s\tremaining: 11m 16s\n",
      "731:\tlearn 0.6650386078\ttest 0.6387946801\tbestTest 0.6388190857\t\ttotal: 17m 35s\tremaining: 11m 14s\n",
      "732:\tlearn 0.6651034851\ttest 0.6387906923\tbestTest 0.6388190857\t\ttotal: 17m 37s\tremaining: 11m 13s\n",
      "733:\tlearn 0.6651226753\ttest 0.6387827528\tbestTest 0.6388190857\t\ttotal: 17m 38s\tremaining: 11m 12s\n",
      "734:\tlearn 0.6651847795\ttest 0.6387902463\tbestTest 0.6388190857\t\ttotal: 17m 40s\tremaining: 11m 10s\n",
      "735:\tlearn 0.6651987775\ttest 0.6387913638\tbestTest 0.6388190857\t\ttotal: 17m 41s\tremaining: 11m 9s\n",
      "736:\tlearn 0.6652226377\ttest 0.6387904058\tbestTest 0.6388190857\t\ttotal: 17m 43s\tremaining: 11m 7s\n",
      "737:\tlearn 0.6652814632\ttest 0.6387978875\tbestTest 0.6388190857\t\ttotal: 17m 44s\tremaining: 11m 6s\n",
      "738:\tlearn 0.6653208678\ttest 0.638816371\tbestTest 0.6388190857\t\ttotal: 17m 46s\tremaining: 11m 5s\n",
      "739:\tlearn 0.6653405734\ttest 0.6387969256\tbestTest 0.6388190857\t\ttotal: 17m 47s\tremaining: 11m 3s\n",
      "740:\tlearn 0.6653688842\ttest 0.6387881655\tbestTest 0.6388190857\t\ttotal: 17m 49s\tremaining: 11m 2s\n",
      "741:\tlearn 0.6653996969\ttest 0.6387910669\tbestTest 0.6388190857\t\ttotal: 17m 50s\tremaining: 11m\n",
      "742:\tlearn 0.6654513066\ttest 0.6387855972\tbestTest 0.6388190857\t\ttotal: 17m 52s\tremaining: 10m 59s\n",
      "743:\tlearn 0.6654842981\ttest 0.6387790204\tbestTest 0.6388190857\t\ttotal: 17m 53s\tremaining: 10m 58s\n",
      "744:\tlearn 0.6655084161\ttest 0.6387700347\tbestTest 0.6388190857\t\ttotal: 17m 55s\tremaining: 10m 56s\n",
      "745:\tlearn 0.6655438897\ttest 0.6387886543\tbestTest 0.6388190857\t\ttotal: 17m 56s\tremaining: 10m 55s\n",
      "746:\tlearn 0.6655643253\ttest 0.6387982324\tbestTest 0.6388190857\t\ttotal: 17m 58s\tremaining: 10m 53s\n",
      "747:\tlearn 0.6655827113\ttest 0.6387996339\tbestTest 0.6388190857\t\ttotal: 17m 59s\tremaining: 10m 52s\n",
      "748:\tlearn 0.6655892931\ttest 0.6388016745\tbestTest 0.6388190857\t\ttotal: 18m 1s\tremaining: 10m 51s\n",
      "749:\tlearn 0.6656560569\ttest 0.6388328669\tbestTest 0.6388328669\t\ttotal: 18m 3s\tremaining: 10m 49s\n",
      "750:\tlearn 0.6656953988\ttest 0.6388439334\tbestTest 0.6388439334\t\ttotal: 18m 4s\tremaining: 10m 48s\n",
      "751:\tlearn 0.6657363475\ttest 0.6388441681\tbestTest 0.6388441681\t\ttotal: 18m 6s\tremaining: 10m 47s\n",
      "752:\tlearn 0.6657608326\ttest 0.6388294547\tbestTest 0.6388441681\t\ttotal: 18m 7s\tremaining: 10m 45s\n",
      "753:\tlearn 0.6657756599\ttest 0.6388338224\tbestTest 0.6388441681\t\ttotal: 18m 9s\tremaining: 10m 44s\n",
      "754:\tlearn 0.6657996026\ttest 0.638829115\tbestTest 0.6388441681\t\ttotal: 18m 11s\tremaining: 10m 43s\n",
      "755:\tlearn 0.6658454253\ttest 0.6388451728\tbestTest 0.6388451728\t\ttotal: 18m 12s\tremaining: 10m 41s\n",
      "756:\tlearn 0.6658980748\ttest 0.6388519182\tbestTest 0.6388519182\t\ttotal: 18m 14s\tremaining: 10m 40s\n",
      "757:\tlearn 0.665912276\ttest 0.6388589553\tbestTest 0.6388589553\t\ttotal: 18m 15s\tremaining: 10m 38s\n",
      "758:\tlearn 0.6659449247\ttest 0.6388588348\tbestTest 0.6388589553\t\ttotal: 18m 17s\tremaining: 10m 37s\n",
      "759:\tlearn 0.6659572966\ttest 0.6388501058\tbestTest 0.6388589553\t\ttotal: 18m 18s\tremaining: 10m 36s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "760:\tlearn 0.6659888259\ttest 0.6388500915\tbestTest 0.6388589553\t\ttotal: 18m 20s\tremaining: 10m 34s\n",
      "761:\tlearn 0.6660289189\ttest 0.6388434382\tbestTest 0.6388589553\t\ttotal: 18m 22s\tremaining: 10m 33s\n",
      "762:\tlearn 0.6660566832\ttest 0.6388500487\tbestTest 0.6388589553\t\ttotal: 18m 23s\tremaining: 10m 32s\n",
      "763:\tlearn 0.6660854537\ttest 0.6388400168\tbestTest 0.6388589553\t\ttotal: 18m 25s\tremaining: 10m 30s\n",
      "764:\tlearn 0.6660842634\ttest 0.6388403513\tbestTest 0.6388589553\t\ttotal: 18m 25s\tremaining: 10m 28s\n",
      "765:\tlearn 0.6661230456\ttest 0.6388480859\tbestTest 0.6388589553\t\ttotal: 18m 27s\tremaining: 10m 27s\n",
      "766:\tlearn 0.6661495044\ttest 0.638842248\tbestTest 0.6388589553\t\ttotal: 18m 29s\tremaining: 10m 26s\n",
      "767:\tlearn 0.6662054505\ttest 0.6388134864\tbestTest 0.6388589553\t\ttotal: 18m 30s\tremaining: 10m 24s\n",
      "768:\tlearn 0.6662109779\ttest 0.6388143965\tbestTest 0.6388589553\t\ttotal: 18m 32s\tremaining: 10m 23s\n",
      "769:\tlearn 0.6662381072\ttest 0.638815855\tbestTest 0.6388589553\t\ttotal: 18m 33s\tremaining: 10m 21s\n",
      "770:\tlearn 0.6662807667\ttest 0.6388279819\tbestTest 0.6388589553\t\ttotal: 18m 34s\tremaining: 10m 20s\n",
      "771:\tlearn 0.6663216943\ttest 0.6388222141\tbestTest 0.6388589553\t\ttotal: 18m 36s\tremaining: 10m 18s\n",
      "772:\tlearn 0.6663440943\ttest 0.6388262927\tbestTest 0.6388589553\t\ttotal: 18m 37s\tremaining: 10m 17s\n",
      "773:\tlearn 0.6663642284\ttest 0.6388335631\tbestTest 0.6388589553\t\ttotal: 18m 39s\tremaining: 10m 15s\n",
      "774:\tlearn 0.6664126729\ttest 0.6388245295\tbestTest 0.6388589553\t\ttotal: 18m 40s\tremaining: 10m 14s\n",
      "775:\tlearn 0.6664297651\ttest 0.6388255887\tbestTest 0.6388589553\t\ttotal: 18m 42s\tremaining: 10m 13s\n",
      "776:\tlearn 0.6664508701\ttest 0.6388186307\tbestTest 0.6388589553\t\ttotal: 18m 44s\tremaining: 10m 12s\n",
      "777:\tlearn 0.6664779807\ttest 0.6388161622\tbestTest 0.6388589553\t\ttotal: 18m 45s\tremaining: 10m 10s\n",
      "778:\tlearn 0.6665080067\ttest 0.6388096165\tbestTest 0.6388589553\t\ttotal: 18m 47s\tremaining: 10m 9s\n",
      "779:\tlearn 0.6665463354\ttest 0.6388207789\tbestTest 0.6388589553\t\ttotal: 18m 48s\tremaining: 10m 7s\n",
      "780:\tlearn 0.6665714669\ttest 0.638825389\tbestTest 0.6388589553\t\ttotal: 18m 49s\tremaining: 10m 6s\n",
      "781:\tlearn 0.666598072\ttest 0.6388408803\tbestTest 0.6388589553\t\ttotal: 18m 51s\tremaining: 10m 4s\n",
      "782:\tlearn 0.666615577\ttest 0.6388372463\tbestTest 0.6388589553\t\ttotal: 18m 52s\tremaining: 10m 3s\n",
      "783:\tlearn 0.6666664534\ttest 0.6388483945\tbestTest 0.6388589553\t\ttotal: 18m 53s\tremaining: 10m 1s\n",
      "784:\tlearn 0.6667232601\ttest 0.6388548015\tbestTest 0.6388589553\t\ttotal: 18m 55s\tremaining: 10m\n",
      "785:\tlearn 0.666768472\ttest 0.6388854028\tbestTest 0.6388854028\t\ttotal: 18m 56s\tremaining: 9m 58s\n",
      "786:\tlearn 0.6667861079\ttest 0.6388694125\tbestTest 0.6388854028\t\ttotal: 18m 58s\tremaining: 9m 57s\n",
      "787:\tlearn 0.6668250195\ttest 0.6388912939\tbestTest 0.6388912939\t\ttotal: 18m 59s\tremaining: 9m 55s\n",
      "788:\tlearn 0.6668544996\ttest 0.6389047069\tbestTest 0.6389047069\t\ttotal: 19m\tremaining: 9m 54s\n",
      "789:\tlearn 0.6668697592\ttest 0.6389203381\tbestTest 0.6389203381\t\ttotal: 19m 2s\tremaining: 9m 52s\n",
      "790:\tlearn 0.6668958514\ttest 0.6389468971\tbestTest 0.6389468971\t\ttotal: 19m 3s\tremaining: 9m 51s\n",
      "791:\tlearn 0.6669215275\ttest 0.6389603581\tbestTest 0.6389603581\t\ttotal: 19m 5s\tremaining: 9m 49s\n",
      "792:\tlearn 0.6669515849\ttest 0.6389731852\tbestTest 0.6389731852\t\ttotal: 19m 6s\tremaining: 9m 48s\n",
      "793:\tlearn 0.6669664863\ttest 0.6389867965\tbestTest 0.6389867965\t\ttotal: 19m 7s\tremaining: 9m 46s\n",
      "794:\tlearn 0.6669763772\ttest 0.6389843903\tbestTest 0.6389867965\t\ttotal: 19m 9s\tremaining: 9m 45s\n",
      "795:\tlearn 0.6669967001\ttest 0.6389852875\tbestTest 0.6389867965\t\ttotal: 19m 10s\tremaining: 9m 44s\n",
      "796:\tlearn 0.6670491379\ttest 0.6389790516\tbestTest 0.6389867965\t\ttotal: 19m 12s\tremaining: 9m 42s\n",
      "797:\tlearn 0.6670791036\ttest 0.6389905588\tbestTest 0.6389905588\t\ttotal: 19m 13s\tremaining: 9m 41s\n",
      "798:\tlearn 0.6671077631\ttest 0.638988106\tbestTest 0.6389905588\t\ttotal: 19m 15s\tremaining: 9m 39s\n",
      "799:\tlearn 0.6671384854\ttest 0.638993201\tbestTest 0.638993201\t\ttotal: 19m 16s\tremaining: 9m 38s\n",
      "800:\tlearn 0.6672311226\ttest 0.6390161597\tbestTest 0.6390161597\t\ttotal: 19m 18s\tremaining: 9m 36s\n",
      "801:\tlearn 0.6672482612\ttest 0.6390251\tbestTest 0.6390251\t\ttotal: 19m 19s\tremaining: 9m 35s\n",
      "802:\tlearn 0.6672799648\ttest 0.6389986733\tbestTest 0.6390251\t\ttotal: 19m 21s\tremaining: 9m 34s\n",
      "803:\tlearn 0.6673331321\ttest 0.6390144834\tbestTest 0.6390251\t\ttotal: 19m 22s\tremaining: 9m 32s\n",
      "804:\tlearn 0.6673433876\ttest 0.6390136213\tbestTest 0.6390251\t\ttotal: 19m 24s\tremaining: 9m 31s\n",
      "805:\tlearn 0.6673513051\ttest 0.6389981716\tbestTest 0.6390251\t\ttotal: 19m 25s\tremaining: 9m 29s\n",
      "806:\tlearn 0.6673830389\ttest 0.6390001486\tbestTest 0.6390251\t\ttotal: 19m 27s\tremaining: 9m 28s\n",
      "807:\tlearn 0.6674309779\ttest 0.6390128123\tbestTest 0.6390251\t\ttotal: 19m 28s\tremaining: 9m 26s\n",
      "808:\tlearn 0.6674703764\ttest 0.6390126282\tbestTest 0.6390251\t\ttotal: 19m 30s\tremaining: 9m 25s\n",
      "809:\tlearn 0.6674951082\ttest 0.6390097851\tbestTest 0.6390251\t\ttotal: 19m 31s\tremaining: 9m 24s\n",
      "810:\tlearn 0.6675230576\ttest 0.6390132829\tbestTest 0.6390251\t\ttotal: 19m 32s\tremaining: 9m 22s\n",
      "811:\tlearn 0.6675403147\ttest 0.6390312193\tbestTest 0.6390312193\t\ttotal: 19m 34s\tremaining: 9m 21s\n",
      "812:\tlearn 0.66755913\ttest 0.6390175093\tbestTest 0.6390312193\t\ttotal: 19m 35s\tremaining: 9m 19s\n",
      "813:\tlearn 0.6676169813\ttest 0.63905029\tbestTest 0.63905029\t\ttotal: 19m 37s\tremaining: 9m 18s\n",
      "814:\tlearn 0.6676932572\ttest 0.6390648892\tbestTest 0.6390648892\t\ttotal: 19m 38s\tremaining: 9m 16s\n",
      "815:\tlearn 0.6677034898\ttest 0.6390659484\tbestTest 0.6390659484\t\ttotal: 19m 39s\tremaining: 9m 15s\n",
      "816:\tlearn 0.6677516576\ttest 0.6390619035\tbestTest 0.6390659484\t\ttotal: 19m 41s\tremaining: 9m 13s\n",
      "817:\tlearn 0.6677530732\ttest 0.6390565427\tbestTest 0.6390659484\t\ttotal: 19m 42s\tremaining: 9m 12s\n",
      "818:\tlearn 0.6678191493\ttest 0.6390765326\tbestTest 0.6390765326\t\ttotal: 19m 44s\tremaining: 9m 10s\n",
      "819:\tlearn 0.6678550662\ttest 0.639084695\tbestTest 0.639084695\t\ttotal: 19m 45s\tremaining: 9m 9s\n",
      "820:\tlearn 0.6679014288\ttest 0.6390842193\tbestTest 0.639084695\t\ttotal: 19m 46s\tremaining: 9m 7s\n",
      "821:\tlearn 0.6679271661\ttest 0.6390987356\tbestTest 0.6390987356\t\ttotal: 19m 48s\tremaining: 9m 6s\n",
      "822:\tlearn 0.6679852318\ttest 0.6390874915\tbestTest 0.6390987356\t\ttotal: 19m 49s\tremaining: 9m 4s\n",
      "823:\tlearn 0.6680087387\ttest 0.6390934914\tbestTest 0.6390987356\t\ttotal: 19m 51s\tremaining: 9m 3s\n",
      "824:\tlearn 0.6680579103\ttest 0.6391015501\tbestTest 0.6391015501\t\ttotal: 19m 52s\tremaining: 9m 2s\n",
      "825:\tlearn 0.6680764527\ttest 0.6391148011\tbestTest 0.6391148011\t\ttotal: 19m 53s\tremaining: 9m\n",
      "826:\tlearn 0.6681325399\ttest 0.6390972485\tbestTest 0.6391148011\t\ttotal: 19m 55s\tremaining: 8m 59s\n",
      "827:\tlearn 0.6681488677\ttest 0.6391100393\tbestTest 0.6391148011\t\ttotal: 19m 56s\tremaining: 8m 57s\n",
      "828:\tlearn 0.6682158177\ttest 0.6391189783\tbestTest 0.6391189783\t\ttotal: 19m 57s\tremaining: 8m 56s\n",
      "829:\tlearn 0.6682278374\ttest 0.6391069382\tbestTest 0.6391189783\t\ttotal: 19m 59s\tremaining: 8m 54s\n",
      "830:\tlearn 0.66824428\ttest 0.6391025199\tbestTest 0.6391189783\t\ttotal: 20m\tremaining: 8m 53s\n",
      "831:\tlearn 0.6682651021\ttest 0.6390974806\tbestTest 0.6391189783\t\ttotal: 20m 1s\tremaining: 8m 51s\n",
      "832:\tlearn 0.6682816907\ttest 0.6391074308\tbestTest 0.6391189783\t\ttotal: 20m 3s\tremaining: 8m 50s\n",
      "833:\tlearn 0.6683221374\ttest 0.6391273494\tbestTest 0.6391273494\t\ttotal: 20m 4s\tremaining: 8m 48s\n",
      "834:\tlearn 0.6683470295\ttest 0.6391212704\tbestTest 0.6391273494\t\ttotal: 20m 6s\tremaining: 8m 47s\n",
      "835:\tlearn 0.6683657716\ttest 0.6391297089\tbestTest 0.6391297089\t\ttotal: 20m 7s\tremaining: 8m 45s\n",
      "836:\tlearn 0.6684058048\ttest 0.6391291359\tbestTest 0.6391297089\t\ttotal: 20m 8s\tremaining: 8m 44s\n",
      "837:\tlearn 0.6684348288\ttest 0.6391285032\tbestTest 0.6391297089\t\ttotal: 20m 10s\tremaining: 8m 42s\n",
      "838:\tlearn 0.6684990092\ttest 0.6391640025\tbestTest 0.6391640025\t\ttotal: 20m 11s\tremaining: 8m 41s\n",
      "839:\tlearn 0.668519328\ttest 0.6391612333\tbestTest 0.6391640025\t\ttotal: 20m 12s\tremaining: 8m 39s\n",
      "840:\tlearn 0.6685500144\ttest 0.6391619334\tbestTest 0.6391640025\t\ttotal: 20m 14s\tremaining: 8m 38s\n",
      "841:\tlearn 0.6685869201\ttest 0.6391716956\tbestTest 0.6391716956\t\ttotal: 20m 15s\tremaining: 8m 36s\n",
      "842:\tlearn 0.6686496973\ttest 0.6391937171\tbestTest 0.6391937171\t\ttotal: 20m 17s\tremaining: 8m 35s\n",
      "843:\tlearn 0.6686877192\ttest 0.6391981742\tbestTest 0.6391981742\t\ttotal: 20m 18s\tremaining: 8m 33s\n",
      "844:\tlearn 0.6687091709\ttest 0.6391999802\tbestTest 0.6391999802\t\ttotal: 20m 19s\tremaining: 8m 32s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "845:\tlearn 0.6687198718\ttest 0.6391942745\tbestTest 0.6391999802\t\ttotal: 20m 21s\tremaining: 8m 31s\n",
      "846:\tlearn 0.6687656486\ttest 0.6391922313\tbestTest 0.6391999802\t\ttotal: 20m 22s\tremaining: 8m 29s\n",
      "847:\tlearn 0.6688180729\ttest 0.6392091266\tbestTest 0.6392091266\t\ttotal: 20m 23s\tremaining: 8m 28s\n",
      "848:\tlearn 0.6688330581\ttest 0.6391974119\tbestTest 0.6392091266\t\ttotal: 20m 25s\tremaining: 8m 26s\n",
      "849:\tlearn 0.6688717884\ttest 0.6391700777\tbestTest 0.6392091266\t\ttotal: 20m 26s\tremaining: 8m 25s\n",
      "850:\tlearn 0.6689035679\ttest 0.6391731956\tbestTest 0.6392091266\t\ttotal: 20m 28s\tremaining: 8m 23s\n",
      "851:\tlearn 0.6689546806\ttest 0.6391835503\tbestTest 0.6392091266\t\ttotal: 20m 29s\tremaining: 8m 22s\n",
      "852:\tlearn 0.6689789568\ttest 0.6391968752\tbestTest 0.6392091266\t\ttotal: 20m 30s\tremaining: 8m 20s\n",
      "853:\tlearn 0.6689969638\ttest 0.639193074\tbestTest 0.6392091266\t\ttotal: 20m 32s\tremaining: 8m 19s\n",
      "854:\tlearn 0.669029578\ttest 0.6391945209\tbestTest 0.6392091266\t\ttotal: 20m 33s\tremaining: 8m 17s\n",
      "855:\tlearn 0.66905997\ttest 0.6391790348\tbestTest 0.6392091266\t\ttotal: 20m 34s\tremaining: 8m 16s\n",
      "856:\tlearn 0.6690774781\ttest 0.6391700777\tbestTest 0.6392091266\t\ttotal: 20m 36s\tremaining: 8m 14s\n",
      "857:\tlearn 0.6691242371\ttest 0.6391720768\tbestTest 0.6392091266\t\ttotal: 20m 37s\tremaining: 8m 13s\n",
      "858:\tlearn 0.669160432\ttest 0.639178769\tbestTest 0.6392091266\t\ttotal: 20m 39s\tremaining: 8m 11s\n",
      "859:\tlearn 0.6691883515\ttest 0.6391855715\tbestTest 0.6392091266\t\ttotal: 20m 40s\tremaining: 8m 10s\n",
      "860:\tlearn 0.6692348594\ttest 0.6391812141\tbestTest 0.6392091266\t\ttotal: 20m 41s\tremaining: 8m 8s\n",
      "861:\tlearn 0.6692510548\ttest 0.6391824652\tbestTest 0.6392091266\t\ttotal: 20m 43s\tremaining: 8m 7s\n",
      "862:\tlearn 0.6692913472\ttest 0.6391916077\tbestTest 0.6392091266\t\ttotal: 20m 44s\tremaining: 8m 6s\n",
      "863:\tlearn 0.6693357936\ttest 0.639214888\tbestTest 0.639214888\t\ttotal: 20m 45s\tremaining: 8m 4s\n",
      "864:\tlearn 0.6693654146\ttest 0.6391984659\tbestTest 0.639214888\t\ttotal: 20m 47s\tremaining: 8m 3s\n",
      "865:\tlearn 0.669395643\ttest 0.6392024616\tbestTest 0.639214888\t\ttotal: 20m 48s\tremaining: 8m 1s\n",
      "866:\tlearn 0.6694181266\ttest 0.6392177545\tbestTest 0.6392177545\t\ttotal: 20m 50s\tremaining: 8m\n",
      "867:\tlearn 0.6694256143\ttest 0.6392103284\tbestTest 0.6392177545\t\ttotal: 20m 51s\tremaining: 7m 58s\n",
      "868:\tlearn 0.6694376897\ttest 0.6392092433\tbestTest 0.6392177545\t\ttotal: 20m 52s\tremaining: 7m 57s\n",
      "869:\tlearn 0.6694821184\ttest 0.63919551\tbestTest 0.6392177545\t\ttotal: 20m 54s\tremaining: 7m 55s\n",
      "870:\tlearn 0.6695084944\ttest 0.6391910075\tbestTest 0.6392177545\t\ttotal: 20m 55s\tremaining: 7m 54s\n",
      "871:\tlearn 0.6695163617\ttest 0.6391941462\tbestTest 0.6392177545\t\ttotal: 20m 56s\tremaining: 7m 52s\n",
      "872:\tlearn 0.6695183726\ttest 0.6391912655\tbestTest 0.6392177545\t\ttotal: 20m 58s\tremaining: 7m 51s\n",
      "873:\tlearn 0.6695404463\ttest 0.6391693231\tbestTest 0.6392177545\t\ttotal: 20m 59s\tremaining: 7m 49s\n",
      "874:\tlearn 0.6695884346\ttest 0.6391673603\tbestTest 0.6392177545\t\ttotal: 21m 1s\tremaining: 7m 48s\n",
      "875:\tlearn 0.6696471964\ttest 0.6391679165\tbestTest 0.6392177545\t\ttotal: 21m 2s\tremaining: 7m 46s\n",
      "876:\tlearn 0.6696781156\ttest 0.6391712432\tbestTest 0.6392177545\t\ttotal: 21m 3s\tremaining: 7m 45s\n",
      "877:\tlearn 0.6697148887\ttest 0.6391768892\tbestTest 0.6392177545\t\ttotal: 21m 5s\tremaining: 7m 44s\n",
      "878:\tlearn 0.6697409676\ttest 0.6391866385\tbestTest 0.6392177545\t\ttotal: 21m 6s\tremaining: 7m 42s\n",
      "879:\tlearn 0.6697792437\ttest 0.6391975468\tbestTest 0.6392177545\t\ttotal: 21m 8s\tremaining: 7m 41s\n",
      "880:\tlearn 0.6698052865\ttest 0.6392081659\tbestTest 0.6392177545\t\ttotal: 21m 9s\tremaining: 7m 39s\n",
      "881:\tlearn 0.669863192\ttest 0.6391786744\tbestTest 0.6392177545\t\ttotal: 21m 10s\tremaining: 7m 38s\n",
      "882:\tlearn 0.66990632\ttest 0.6391906354\tbestTest 0.6392177545\t\ttotal: 21m 12s\tremaining: 7m 36s\n",
      "883:\tlearn 0.6699254432\ttest 0.6392119023\tbestTest 0.6392177545\t\ttotal: 21m 13s\tremaining: 7m 35s\n",
      "884:\tlearn 0.6699566326\ttest 0.639214525\tbestTest 0.6392177545\t\ttotal: 21m 14s\tremaining: 7m 33s\n",
      "885:\tlearn 0.6700139998\ttest 0.6392333572\tbestTest 0.6392333572\t\ttotal: 21m 16s\tremaining: 7m 32s\n",
      "886:\tlearn 0.6700642778\ttest 0.6392242885\tbestTest 0.6392333572\t\ttotal: 21m 17s\tremaining: 7m 30s\n",
      "887:\tlearn 0.6700936639\ttest 0.6392322345\tbestTest 0.6392333572\t\ttotal: 21m 19s\tremaining: 7m 29s\n",
      "888:\tlearn 0.6701157376\ttest 0.6392307526\tbestTest 0.6392333572\t\ttotal: 21m 20s\tremaining: 7m 28s\n",
      "889:\tlearn 0.6701341419\ttest 0.6392345357\tbestTest 0.6392345357\t\ttotal: 21m 22s\tremaining: 7m 26s\n",
      "890:\tlearn 0.6701549486\ttest 0.6392383524\tbestTest 0.6392383524\t\ttotal: 21m 23s\tremaining: 7m 25s\n",
      "891:\tlearn 0.6701882151\ttest 0.6392447387\tbestTest 0.6392447387\t\ttotal: 21m 25s\tremaining: 7m 23s\n",
      "892:\tlearn 0.6702074446\ttest 0.6392416052\tbestTest 0.6392447387\t\ttotal: 21m 26s\tremaining: 7m 22s\n",
      "893:\tlearn 0.6702211576\ttest 0.6392510563\tbestTest 0.6392510563\t\ttotal: 21m 28s\tremaining: 7m 20s\n",
      "894:\tlearn 0.6702279543\ttest 0.6392468921\tbestTest 0.6392510563\t\ttotal: 21m 29s\tremaining: 7m 19s\n",
      "895:\tlearn 0.6702863696\ttest 0.6392401493\tbestTest 0.6392510563\t\ttotal: 21m 31s\tremaining: 7m 18s\n",
      "896:\tlearn 0.6703176307\ttest 0.6392396787\tbestTest 0.6392510563\t\ttotal: 21m 32s\tremaining: 7m 16s\n",
      "897:\tlearn 0.6703541155\ttest 0.6392232734\tbestTest 0.6392510563\t\ttotal: 21m 34s\tremaining: 7m 15s\n",
      "898:\tlearn 0.6703849422\ttest 0.6392320465\tbestTest 0.6392510563\t\ttotal: 21m 36s\tremaining: 7m 13s\n",
      "899:\tlearn 0.6704091672\ttest 0.6392318909\tbestTest 0.6392510563\t\ttotal: 21m 37s\tremaining: 7m 12s\n",
      "900:\tlearn 0.6704402421\ttest 0.6392319817\tbestTest 0.6392510563\t\ttotal: 21m 39s\tremaining: 7m 11s\n",
      "901:\tlearn 0.6704661354\ttest 0.6392388424\tbestTest 0.6392510563\t\ttotal: 21m 40s\tremaining: 7m 9s\n",
      "902:\tlearn 0.6704716254\ttest 0.6392443614\tbestTest 0.6392510563\t\ttotal: 21m 42s\tremaining: 7m 8s\n",
      "903:\tlearn 0.6705140252\ttest 0.6392574179\tbestTest 0.6392574179\t\ttotal: 21m 43s\tremaining: 7m 6s\n",
      "904:\tlearn 0.6705712624\ttest 0.6392650825\tbestTest 0.6392650825\t\ttotal: 21m 45s\tremaining: 7m 5s\n",
      "905:\tlearn 0.6706340458\ttest 0.6392410762\tbestTest 0.6392650825\t\ttotal: 21m 46s\tremaining: 7m 3s\n",
      "906:\tlearn 0.6706654018\ttest 0.6392582425\tbestTest 0.6392650825\t\ttotal: 21m 47s\tremaining: 7m 2s\n",
      "907:\tlearn 0.6706808206\ttest 0.6392674394\tbestTest 0.6392674394\t\ttotal: 21m 49s\tremaining: 7m 1s\n",
      "908:\tlearn 0.6707021595\ttest 0.6392679347\tbestTest 0.6392679347\t\ttotal: 21m 50s\tremaining: 6m 59s\n",
      "909:\tlearn 0.6707289465\ttest 0.6392760932\tbestTest 0.6392760932\t\ttotal: 21m 52s\tremaining: 6m 58s\n",
      "910:\tlearn 0.6707732391\ttest 0.6392927733\tbestTest 0.6392927733\t\ttotal: 21m 53s\tremaining: 6m 56s\n",
      "911:\tlearn 0.6708922934\ttest 0.6393114447\tbestTest 0.6393114447\t\ttotal: 21m 55s\tremaining: 6m 55s\n",
      "912:\tlearn 0.6709136469\ttest 0.6393061863\tbestTest 0.6393114447\t\ttotal: 21m 56s\tremaining: 6m 53s\n",
      "913:\tlearn 0.6709629267\ttest 0.6393288793\tbestTest 0.6393288793\t\ttotal: 21m 57s\tremaining: 6m 52s\n",
      "914:\tlearn 0.6709753506\ttest 0.6393377639\tbestTest 0.6393377639\t\ttotal: 21m 59s\tremaining: 6m 50s\n",
      "915:\tlearn 0.671023253\ttest 0.6393393092\tbestTest 0.6393393092\t\ttotal: 22m\tremaining: 6m 49s\n",
      "916:\tlearn 0.671039815\ttest 0.639332814\tbestTest 0.6393393092\t\ttotal: 22m 2s\tremaining: 6m 48s\n",
      "917:\tlearn 0.6710777238\ttest 0.6393481004\tbestTest 0.6393481004\t\ttotal: 22m 3s\tremaining: 6m 46s\n",
      "918:\tlearn 0.6711169462\ttest 0.6393502901\tbestTest 0.6393502901\t\ttotal: 22m 5s\tremaining: 6m 45s\n",
      "919:\tlearn 0.6711624635\ttest 0.6393477374\tbestTest 0.6393502901\t\ttotal: 22m 6s\tremaining: 6m 43s\n",
      "920:\tlearn 0.6711820234\ttest 0.6393627502\tbestTest 0.6393627502\t\ttotal: 22m 7s\tremaining: 6m 42s\n",
      "921:\tlearn 0.6711923299\ttest 0.6393527119\tbestTest 0.6393627502\t\ttotal: 22m 9s\tremaining: 6m 40s\n",
      "922:\tlearn 0.6712119606\ttest 0.6393547966\tbestTest 0.6393627502\t\ttotal: 22m 10s\tremaining: 6m 39s\n",
      "923:\tlearn 0.6712590809\ttest 0.6393451653\tbestTest 0.6393627502\t\ttotal: 22m 11s\tremaining: 6m 37s\n",
      "924:\tlearn 0.6712761042\ttest 0.6393580066\tbestTest 0.6393627502\t\ttotal: 22m 13s\tremaining: 6m 36s\n",
      "925:\tlearn 0.671286617\ttest 0.6393528765\tbestTest 0.6393627502\t\ttotal: 22m 14s\tremaining: 6m 34s\n",
      "926:\tlearn 0.6713248507\ttest 0.63936379\tbestTest 0.63936379\t\ttotal: 22m 16s\tremaining: 6m 33s\n",
      "927:\tlearn 0.6713437492\ttest 0.639366108\tbestTest 0.639366108\t\ttotal: 22m 17s\tremaining: 6m 32s\n",
      "928:\tlearn 0.671364702\ttest 0.6393885262\tbestTest 0.6393885262\t\ttotal: 22m 19s\tremaining: 6m 30s\n",
      "929:\tlearn 0.6713923867\ttest 0.6393830461\tbestTest 0.6393885262\t\ttotal: 22m 20s\tremaining: 6m 29s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "930:\tlearn 0.6714277242\ttest 0.6393550986\tbestTest 0.6393885262\t\ttotal: 22m 21s\tremaining: 6m 27s\n",
      "931:\tlearn 0.6714606029\ttest 0.6393659071\tbestTest 0.6393885262\t\ttotal: 22m 23s\tremaining: 6m 26s\n",
      "932:\tlearn 0.6714972243\ttest 0.6393612373\tbestTest 0.6393885262\t\ttotal: 22m 24s\tremaining: 6m 24s\n",
      "933:\tlearn 0.6715407057\ttest 0.6393675238\tbestTest 0.6393885262\t\ttotal: 22m 26s\tremaining: 6m 23s\n",
      "934:\tlearn 0.6715945433\ttest 0.6393432776\tbestTest 0.6393885262\t\ttotal: 22m 27s\tremaining: 6m 21s\n",
      "935:\tlearn 0.6716335133\ttest 0.639353889\tbestTest 0.6393885262\t\ttotal: 22m 28s\tremaining: 6m 20s\n",
      "936:\tlearn 0.6716751635\ttest 0.6393519638\tbestTest 0.6393885262\t\ttotal: 22m 30s\tremaining: 6m 18s\n",
      "937:\tlearn 0.671716888\ttest 0.6393479371\tbestTest 0.6393885262\t\ttotal: 22m 31s\tremaining: 6m 17s\n",
      "938:\tlearn 0.6717337401\ttest 0.6393436108\tbestTest 0.6393885262\t\ttotal: 22m 33s\tremaining: 6m 16s\n",
      "939:\tlearn 0.6717940871\ttest 0.6393213055\tbestTest 0.6393885262\t\ttotal: 22m 34s\tremaining: 6m 14s\n",
      "940:\tlearn 0.6718347046\ttest 0.6393311092\tbestTest 0.6393885262\t\ttotal: 22m 36s\tremaining: 6m 13s\n",
      "941:\tlearn 0.6718808418\ttest 0.6393181849\tbestTest 0.6393885262\t\ttotal: 22m 38s\tremaining: 6m 12s\n",
      "942:\tlearn 0.6719301888\ttest 0.6393265677\tbestTest 0.6393885262\t\ttotal: 22m 39s\tremaining: 6m 10s\n",
      "943:\tlearn 0.6719436623\ttest 0.6393242562\tbestTest 0.6393885262\t\ttotal: 22m 41s\tremaining: 6m 9s\n",
      "944:\tlearn 0.6719490612\ttest 0.6393171296\tbestTest 0.6393885262\t\ttotal: 22m 43s\tremaining: 6m 7s\n",
      "945:\tlearn 0.6719828165\ttest 0.6393088051\tbestTest 0.6393885262\t\ttotal: 22m 44s\tremaining: 6m 6s\n",
      "946:\tlearn 0.6720142535\ttest 0.6393162169\tbestTest 0.6393885262\t\ttotal: 22m 46s\tremaining: 6m 5s\n",
      "947:\tlearn 0.6720458484\ttest 0.6393220367\tbestTest 0.6393885262\t\ttotal: 22m 48s\tremaining: 6m 3s\n",
      "948:\tlearn 0.6720580948\ttest 0.639328572\tbestTest 0.6393885262\t\ttotal: 22m 49s\tremaining: 6m 2s\n",
      "949:\tlearn 0.6720773354\ttest 0.6393333676\tbestTest 0.6393885262\t\ttotal: 22m 51s\tremaining: 6m\n",
      "950:\tlearn 0.6721040006\ttest 0.6393196266\tbestTest 0.6393885262\t\ttotal: 22m 52s\tremaining: 5m 59s\n",
      "951:\tlearn 0.6721092639\ttest 0.6393129966\tbestTest 0.6393885262\t\ttotal: 22m 54s\tremaining: 5m 58s\n",
      "952:\tlearn 0.6721372733\ttest 0.6393091383\tbestTest 0.6393885262\t\ttotal: 22m 56s\tremaining: 5m 56s\n",
      "953:\tlearn 0.6721426291\ttest 0.63931372\tbestTest 0.6393885262\t\ttotal: 22m 57s\tremaining: 5m 55s\n",
      "954:\tlearn 0.6721746421\ttest 0.6393183094\tbestTest 0.6393885262\t\ttotal: 22m 59s\tremaining: 5m 53s\n",
      "955:\tlearn 0.6722034604\ttest 0.6393297609\tbestTest 0.6393885262\t\ttotal: 23m\tremaining: 5m 52s\n",
      "956:\tlearn 0.6722332566\ttest 0.6393407962\tbestTest 0.6393885262\t\ttotal: 23m 2s\tremaining: 5m 51s\n",
      "957:\tlearn 0.6722950953\ttest 0.639347307\tbestTest 0.6393885262\t\ttotal: 23m 3s\tremaining: 5m 49s\n",
      "958:\tlearn 0.6723390139\ttest 0.6393421173\tbestTest 0.6393885262\t\ttotal: 23m 5s\tremaining: 5m 48s\n",
      "959:\tlearn 0.6723682911\ttest 0.639341766\tbestTest 0.6393885262\t\ttotal: 23m 6s\tremaining: 5m 46s\n",
      "960:\tlearn 0.6723957279\ttest 0.6393243171\tbestTest 0.6393885262\t\ttotal: 23m 7s\tremaining: 5m 45s\n",
      "961:\tlearn 0.6724141848\ttest 0.6393241602\tbestTest 0.6393885262\t\ttotal: 23m 9s\tremaining: 5m 43s\n",
      "962:\tlearn 0.6724267869\ttest 0.6393293188\tbestTest 0.6393885262\t\ttotal: 23m 10s\tremaining: 5m 42s\n",
      "963:\tlearn 0.6724515109\ttest 0.6393183612\tbestTest 0.6393885262\t\ttotal: 23m 12s\tremaining: 5m 40s\n",
      "964:\tlearn 0.6724595805\ttest 0.6393176871\tbestTest 0.6393885262\t\ttotal: 23m 13s\tremaining: 5m 39s\n",
      "965:\tlearn 0.6724702624\ttest 0.6393257834\tbestTest 0.6393885262\t\ttotal: 23m 14s\tremaining: 5m 37s\n",
      "966:\tlearn 0.6724806002\ttest 0.6393310612\tbestTest 0.6393885262\t\ttotal: 23m 16s\tremaining: 5m 36s\n",
      "967:\tlearn 0.6724980927\ttest 0.6393406368\tbestTest 0.6393885262\t\ttotal: 23m 17s\tremaining: 5m 34s\n",
      "968:\tlearn 0.6725573692\ttest 0.639347154\tbestTest 0.6393885262\t\ttotal: 23m 18s\tremaining: 5m 33s\n",
      "969:\tlearn 0.6725590553\ttest 0.6393477128\tbestTest 0.6393885262\t\ttotal: 23m 20s\tremaining: 5m 31s\n",
      "970:\tlearn 0.6726024339\ttest 0.6393543143\tbestTest 0.6393885262\t\ttotal: 23m 21s\tremaining: 5m 30s\n",
      "971:\tlearn 0.6726396399\ttest 0.6393605554\tbestTest 0.6393885262\t\ttotal: 23m 22s\tremaining: 5m 29s\n",
      "972:\tlearn 0.6726599567\ttest 0.6393607446\tbestTest 0.6393885262\t\ttotal: 23m 24s\tremaining: 5m 27s\n",
      "973:\tlearn 0.6726776037\ttest 0.639371216\tbestTest 0.6393885262\t\ttotal: 23m 25s\tremaining: 5m 26s\n",
      "974:\tlearn 0.672707017\ttest 0.6393475481\tbestTest 0.6393885262\t\ttotal: 23m 26s\tremaining: 5m 24s\n",
      "975:\tlearn 0.6727335736\ttest 0.6393571522\tbestTest 0.6393885262\t\ttotal: 23m 28s\tremaining: 5m 23s\n",
      "976:\tlearn 0.6727578377\ttest 0.6393581129\tbestTest 0.6393885262\t\ttotal: 23m 29s\tremaining: 5m 21s\n",
      "977:\tlearn 0.6727971275\ttest 0.6393828348\tbestTest 0.6393885262\t\ttotal: 23m 31s\tremaining: 5m 20s\n",
      "978:\tlearn 0.6728226691\ttest 0.6393760686\tbestTest 0.6393885262\t\ttotal: 23m 32s\tremaining: 5m 18s\n",
      "979:\tlearn 0.6728644519\ttest 0.6393546864\tbestTest 0.6393885262\t\ttotal: 23m 33s\tremaining: 5m 17s\n",
      "980:\tlearn 0.6728762957\ttest 0.6393648466\tbestTest 0.6393885262\t\ttotal: 23m 35s\tremaining: 5m 15s\n",
      "981:\tlearn 0.6728888012\ttest 0.6393696318\tbestTest 0.6393885262\t\ttotal: 23m 36s\tremaining: 5m 14s\n",
      "982:\tlearn 0.6729098302\ttest 0.6393732087\tbestTest 0.6393885262\t\ttotal: 23m 37s\tremaining: 5m 13s\n",
      "983:\tlearn 0.6729117961\ttest 0.6393705574\tbestTest 0.6393885262\t\ttotal: 23m 39s\tremaining: 5m 11s\n",
      "984:\tlearn 0.6729467485\ttest 0.6393731529\tbestTest 0.6393885262\t\ttotal: 23m 40s\tremaining: 5m 10s\n",
      "985:\tlearn 0.6729640158\ttest 0.6393823175\tbestTest 0.6393885262\t\ttotal: 23m 42s\tremaining: 5m 8s\n",
      "986:\tlearn 0.6729843366\ttest 0.6393940815\tbestTest 0.6393940815\t\ttotal: 23m 43s\tremaining: 5m 7s\n",
      "987:\tlearn 0.6730164058\ttest 0.6393888996\tbestTest 0.6393940815\t\ttotal: 23m 44s\tremaining: 5m 5s\n",
      "988:\tlearn 0.6730248204\ttest 0.6393772769\tbestTest 0.6393940815\t\ttotal: 23m 46s\tremaining: 5m 4s\n",
      "989:\tlearn 0.6730319436\ttest 0.6393852928\tbestTest 0.6393940815\t\ttotal: 23m 47s\tremaining: 5m 2s\n",
      "990:\tlearn 0.6730526526\ttest 0.6393937379\tbestTest 0.6393940815\t\ttotal: 23m 48s\tremaining: 5m 1s\n",
      "991:\tlearn 0.6730782907\ttest 0.6394013377\tbestTest 0.6394013377\t\ttotal: 23m 50s\tremaining: 4m 59s\n",
      "992:\tlearn 0.6731039586\ttest 0.6393885184\tbestTest 0.6394013377\t\ttotal: 23m 51s\tremaining: 4m 58s\n",
      "993:\tlearn 0.6731376239\ttest 0.6393775984\tbestTest 0.6394013377\t\ttotal: 23m 52s\tremaining: 4m 56s\n",
      "994:\tlearn 0.6731670522\ttest 0.6393703474\tbestTest 0.6394013377\t\ttotal: 23m 54s\tremaining: 4m 55s\n",
      "995:\tlearn 0.673227214\ttest 0.6393707843\tbestTest 0.6394013377\t\ttotal: 23m 55s\tremaining: 4m 54s\n",
      "996:\tlearn 0.6732594809\ttest 0.6393870042\tbestTest 0.6394013377\t\ttotal: 23m 57s\tremaining: 4m 52s\n",
      "997:\tlearn 0.6732759295\ttest 0.6393940283\tbestTest 0.6394013377\t\ttotal: 23m 58s\tremaining: 4m 51s\n",
      "998:\tlearn 0.673292629\ttest 0.6393936601\tbestTest 0.6394013377\t\ttotal: 23m 59s\tremaining: 4m 49s\n",
      "999:\tlearn 0.6733280853\ttest 0.6393974094\tbestTest 0.6394013377\t\ttotal: 24m 1s\tremaining: 4m 48s\n",
      "1000:\tlearn 0.673354127\ttest 0.6393962465\tbestTest 0.6394013377\t\ttotal: 24m 2s\tremaining: 4m 46s\n",
      "1001:\tlearn 0.6733691522\ttest 0.6393897241\tbestTest 0.6394013377\t\ttotal: 24m 3s\tremaining: 4m 45s\n",
      "1002:\tlearn 0.6734028858\ttest 0.6393914756\tbestTest 0.6394013377\t\ttotal: 24m 5s\tremaining: 4m 43s\n",
      "1003:\tlearn 0.673453117\ttest 0.6394163725\tbestTest 0.6394163725\t\ttotal: 24m 6s\tremaining: 4m 42s\n",
      "1004:\tlearn 0.673474095\ttest 0.6394250834\tbestTest 0.6394250834\t\ttotal: 24m 8s\tremaining: 4m 40s\n",
      "1005:\tlearn 0.6735016458\ttest 0.6394426554\tbestTest 0.6394426554\t\ttotal: 24m 9s\tremaining: 4m 39s\n",
      "1006:\tlearn 0.6735306613\ttest 0.639436063\tbestTest 0.6394426554\t\ttotal: 24m 10s\tremaining: 4m 38s\n",
      "1007:\tlearn 0.6735611466\ttest 0.6394310911\tbestTest 0.6394426554\t\ttotal: 24m 12s\tremaining: 4m 36s\n",
      "1008:\tlearn 0.6736026966\ttest 0.6394416221\tbestTest 0.6394426554\t\ttotal: 24m 13s\tremaining: 4m 35s\n",
      "1009:\tlearn 0.6736293391\ttest 0.6394265159\tbestTest 0.6394426554\t\ttotal: 24m 15s\tremaining: 4m 33s\n",
      "1010:\tlearn 0.6736532866\ttest 0.6394448166\tbestTest 0.6394448166\t\ttotal: 24m 16s\tremaining: 4m 32s\n",
      "1011:\tlearn 0.6736763905\ttest 0.6394449929\tbestTest 0.6394449929\t\ttotal: 24m 18s\tremaining: 4m 30s\n",
      "1012:\tlearn 0.6736987605\ttest 0.6394432038\tbestTest 0.6394449929\t\ttotal: 24m 19s\tremaining: 4m 29s\n",
      "1013:\tlearn 0.6737164388\ttest 0.6394452535\tbestTest 0.6394452535\t\ttotal: 24m 21s\tremaining: 4m 28s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1014:\tlearn 0.6737986025\ttest 0.6394545127\tbestTest 0.6394545127\t\ttotal: 24m 22s\tremaining: 4m 26s\n",
      "1015:\tlearn 0.6738096178\ttest 0.6394480538\tbestTest 0.6394545127\t\ttotal: 24m 24s\tremaining: 4m 25s\n",
      "1016:\tlearn 0.6738215178\ttest 0.6394435072\tbestTest 0.6394545127\t\ttotal: 24m 25s\tremaining: 4m 23s\n",
      "1017:\tlearn 0.6738638876\ttest 0.6394333975\tbestTest 0.6394545127\t\ttotal: 24m 27s\tremaining: 4m 22s\n",
      "1018:\tlearn 0.6738882002\ttest 0.6394297272\tbestTest 0.6394545127\t\ttotal: 24m 28s\tremaining: 4m 20s\n",
      "1019:\tlearn 0.6738946622\ttest 0.6394460923\tbestTest 0.6394545127\t\ttotal: 24m 30s\tremaining: 4m 19s\n",
      "1020:\tlearn 0.6739223555\ttest 0.6394514271\tbestTest 0.6394545127\t\ttotal: 24m 32s\tremaining: 4m 18s\n",
      "1021:\tlearn 0.6739473401\ttest 0.6394402829\tbestTest 0.6394545127\t\ttotal: 24m 33s\tremaining: 4m 16s\n",
      "1022:\tlearn 0.673961217\ttest 0.6394457085\tbestTest 0.6394545127\t\ttotal: 24m 35s\tremaining: 4m 15s\n",
      "1023:\tlearn 0.6739849526\ttest 0.6394336632\tbestTest 0.6394545127\t\ttotal: 24m 36s\tremaining: 4m 13s\n",
      "1024:\tlearn 0.6739890342\ttest 0.6394345526\tbestTest 0.6394545127\t\ttotal: 24m 38s\tremaining: 4m 12s\n",
      "1025:\tlearn 0.6740023924\ttest 0.6394376654\tbestTest 0.6394545127\t\ttotal: 24m 39s\tremaining: 4m 10s\n",
      "1026:\tlearn 0.6740473663\ttest 0.6394205367\tbestTest 0.6394545127\t\ttotal: 24m 41s\tremaining: 4m 9s\n",
      "1027:\tlearn 0.6740707914\ttest 0.6394125662\tbestTest 0.6394545127\t\ttotal: 24m 42s\tremaining: 4m 8s\n",
      "1028:\tlearn 0.6740811424\ttest 0.6394152278\tbestTest 0.6394545127\t\ttotal: 24m 44s\tremaining: 4m 6s\n",
      "1029:\tlearn 0.6740977698\ttest 0.639415443\tbestTest 0.6394545127\t\ttotal: 24m 46s\tremaining: 4m 5s\n",
      "1030:\tlearn 0.6741160325\ttest 0.6394070355\tbestTest 0.6394545127\t\ttotal: 24m 47s\tremaining: 4m 3s\n",
      "1031:\tlearn 0.6741256023\ttest 0.6394105696\tbestTest 0.6394545127\t\ttotal: 24m 49s\tremaining: 4m 2s\n",
      "1032:\tlearn 0.6741509569\ttest 0.6394127749\tbestTest 0.6394545127\t\ttotal: 24m 50s\tremaining: 4m 1s\n",
      "1033:\tlearn 0.6741805121\ttest 0.6394206573\tbestTest 0.6394545127\t\ttotal: 24m 52s\tremaining: 3m 59s\n",
      "1034:\tlearn 0.6741959528\ttest 0.639428366\tbestTest 0.6394545127\t\ttotal: 24m 54s\tremaining: 3m 58s\n",
      "1035:\tlearn 0.6742590963\ttest 0.6394389748\tbestTest 0.6394545127\t\ttotal: 24m 55s\tremaining: 3m 56s\n",
      "1036:\tlearn 0.6742886595\ttest 0.6394383914\tbestTest 0.6394545127\t\ttotal: 24m 57s\tremaining: 3m 55s\n",
      "1037:\tlearn 0.6743046025\ttest 0.6394292929\tbestTest 0.6394545127\t\ttotal: 24m 58s\tremaining: 3m 53s\n",
      "1038:\tlearn 0.6743266156\ttest 0.6394284347\tbestTest 0.6394545127\t\ttotal: 25m\tremaining: 3m 52s\n",
      "1039:\tlearn 0.6743482272\ttest 0.6394499103\tbestTest 0.6394545127\t\ttotal: 25m 1s\tremaining: 3m 51s\n",
      "1040:\tlearn 0.6743714463\ttest 0.639447263\tbestTest 0.6394545127\t\ttotal: 25m 3s\tremaining: 3m 49s\n",
      "1041:\tlearn 0.6743901283\ttest 0.6394500736\tbestTest 0.6394545127\t\ttotal: 25m 4s\tremaining: 3m 48s\n",
      "1042:\tlearn 0.6744019856\ttest 0.6394502513\tbestTest 0.6394545127\t\ttotal: 25m 6s\tremaining: 3m 46s\n",
      "1043:\tlearn 0.6744134499\ttest 0.6394435823\tbestTest 0.6394545127\t\ttotal: 25m 8s\tremaining: 3m 45s\n",
      "1044:\tlearn 0.6744362659\ttest 0.6394519716\tbestTest 0.6394545127\t\ttotal: 25m 9s\tremaining: 3m 43s\n",
      "1045:\tlearn 0.6744587575\ttest 0.6394535715\tbestTest 0.6394545127\t\ttotal: 25m 11s\tremaining: 3m 42s\n",
      "1046:\tlearn 0.674460307\ttest 0.6394549872\tbestTest 0.6394549872\t\ttotal: 25m 12s\tremaining: 3m 41s\n",
      "1047:\tlearn 0.6744883385\ttest 0.63946215\tbestTest 0.63946215\t\ttotal: 25m 14s\tremaining: 3m 39s\n",
      "1048:\tlearn 0.6744960075\ttest 0.6394635593\tbestTest 0.6394635593\t\ttotal: 25m 15s\tremaining: 3m 38s\n",
      "1049:\tlearn 0.6745210532\ttest 0.6394633454\tbestTest 0.6394635593\t\ttotal: 25m 17s\tremaining: 3m 36s\n",
      "1050:\tlearn 0.6745458248\ttest 0.6394537633\tbestTest 0.6394635593\t\ttotal: 25m 19s\tremaining: 3m 35s\n",
      "1051:\tlearn 0.6745558054\ttest 0.6394415067\tbestTest 0.6394635593\t\ttotal: 25m 20s\tremaining: 3m 33s\n",
      "1052:\tlearn 0.6745767938\ttest 0.6394297895\tbestTest 0.6394635593\t\ttotal: 25m 22s\tremaining: 3m 32s\n",
      "1053:\tlearn 0.6745818524\ttest 0.6394402609\tbestTest 0.6394635593\t\ttotal: 25m 23s\tremaining: 3m 31s\n",
      "1054:\tlearn 0.6746226608\ttest 0.6394404035\tbestTest 0.6394635593\t\ttotal: 25m 25s\tremaining: 3m 29s\n",
      "1055:\tlearn 0.6746364223\ttest 0.6394503887\tbestTest 0.6394635593\t\ttotal: 25m 26s\tremaining: 3m 28s\n",
      "1056:\tlearn 0.6746692453\ttest 0.6394514038\tbestTest 0.6394635593\t\ttotal: 25m 28s\tremaining: 3m 26s\n",
      "1057:\tlearn 0.6747141587\ttest 0.6394560075\tbestTest 0.6394635593\t\ttotal: 25m 29s\tremaining: 3m 25s\n",
      "1058:\tlearn 0.6747312732\ttest 0.6394693557\tbestTest 0.6394693557\t\ttotal: 25m 31s\tremaining: 3m 23s\n",
      "1059:\tlearn 0.674755955\ttest 0.6394652589\tbestTest 0.6394693557\t\ttotal: 25m 32s\tremaining: 3m 22s\n",
      "1060:\tlearn 0.6747753632\ttest 0.6394548925\tbestTest 0.6394693557\t\ttotal: 25m 34s\tremaining: 3m 21s\n",
      "1061:\tlearn 0.6748435859\ttest 0.6394801434\tbestTest 0.6394801434\t\ttotal: 25m 36s\tremaining: 3m 19s\n",
      "1062:\tlearn 0.67486269\ttest 0.6394923624\tbestTest 0.6394923624\t\ttotal: 25m 37s\tremaining: 3m 18s\n",
      "1063:\tlearn 0.6748638805\ttest 0.6394973537\tbestTest 0.6394973537\t\ttotal: 25m 39s\tremaining: 3m 16s\n",
      "1064:\tlearn 0.6748937988\ttest 0.6395046501\tbestTest 0.6395046501\t\ttotal: 25m 40s\tremaining: 3m 15s\n",
      "1065:\tlearn 0.6749250872\ttest 0.6394994579\tbestTest 0.6395046501\t\ttotal: 25m 42s\tremaining: 3m 13s\n",
      "1066:\tlearn 0.6749381771\ttest 0.6394802705\tbestTest 0.6395046501\t\ttotal: 25m 43s\tremaining: 3m 12s\n",
      "1067:\tlearn 0.6749848492\ttest 0.6394978866\tbestTest 0.6395046501\t\ttotal: 25m 45s\tremaining: 3m 11s\n",
      "1068:\tlearn 0.6750361982\ttest 0.6395207766\tbestTest 0.6395207766\t\ttotal: 25m 47s\tremaining: 3m 9s\n",
      "1069:\tlearn 0.6750524422\ttest 0.6395083541\tbestTest 0.6395207766\t\ttotal: 25m 48s\tremaining: 3m 8s\n",
      "1070:\tlearn 0.6750762516\ttest 0.6395082905\tbestTest 0.6395207766\t\ttotal: 25m 50s\tremaining: 3m 6s\n",
      "1071:\tlearn 0.675094058\ttest 0.639506915\tbestTest 0.6395207766\t\ttotal: 25m 51s\tremaining: 3m 5s\n",
      "1072:\tlearn 0.6751065032\ttest 0.6395135891\tbestTest 0.6395207766\t\ttotal: 25m 53s\tremaining: 3m 3s\n",
      "1073:\tlearn 0.675114177\ttest 0.6395126985\tbestTest 0.6395207766\t\ttotal: 25m 55s\tremaining: 3m 2s\n",
      "1074:\tlearn 0.6751298556\ttest 0.6395239879\tbestTest 0.6395239879\t\ttotal: 25m 56s\tremaining: 3m 1s\n",
      "1075:\tlearn 0.6751678987\ttest 0.6395316382\tbestTest 0.6395316382\t\ttotal: 25m 58s\tremaining: 2m 59s\n",
      "1076:\tlearn 0.6752108252\ttest 0.6395266054\tbestTest 0.6395316382\t\ttotal: 25m 59s\tremaining: 2m 58s\n",
      "1077:\tlearn 0.6752375921\ttest 0.6395049548\tbestTest 0.6395316382\t\ttotal: 26m 1s\tremaining: 2m 56s\n",
      "1078:\tlearn 0.675252156\ttest 0.6395194089\tbestTest 0.6395316382\t\ttotal: 26m 3s\tremaining: 2m 55s\n",
      "1079:\tlearn 0.6752578046\ttest 0.6395201452\tbestTest 0.6395316382\t\ttotal: 26m 4s\tremaining: 2m 53s\n",
      "1080:\tlearn 0.6752760374\ttest 0.6395309343\tbestTest 0.6395316382\t\ttotal: 26m 6s\tremaining: 2m 52s\n",
      "1081:\tlearn 0.6753052508\ttest 0.6395159901\tbestTest 0.6395316382\t\ttotal: 26m 7s\tremaining: 2m 51s\n",
      "1082:\tlearn 0.6753280382\ttest 0.6395271888\tbestTest 0.6395316382\t\ttotal: 26m 9s\tremaining: 2m 49s\n",
      "1083:\tlearn 0.675337053\ttest 0.6395177455\tbestTest 0.6395316382\t\ttotal: 26m 11s\tremaining: 2m 48s\n",
      "1084:\tlearn 0.6753625753\ttest 0.6395230337\tbestTest 0.6395316382\t\ttotal: 26m 12s\tremaining: 2m 46s\n",
      "1085:\tlearn 0.6753703551\ttest 0.6395216686\tbestTest 0.6395316382\t\ttotal: 26m 14s\tremaining: 2m 45s\n",
      "1086:\tlearn 0.6753892547\ttest 0.6395288262\tbestTest 0.6395316382\t\ttotal: 26m 15s\tremaining: 2m 43s\n",
      "1087:\tlearn 0.675398968\ttest 0.6395434696\tbestTest 0.6395434696\t\ttotal: 26m 17s\tremaining: 2m 42s\n",
      "1088:\tlearn 0.675435643\ttest 0.6395513546\tbestTest 0.6395513546\t\ttotal: 26m 19s\tremaining: 2m 40s\n",
      "1089:\tlearn 0.6754850981\ttest 0.6395607214\tbestTest 0.6395607214\t\ttotal: 26m 20s\tremaining: 2m 39s\n",
      "1090:\tlearn 0.6755134619\ttest 0.6395490223\tbestTest 0.6395607214\t\ttotal: 26m 22s\tremaining: 2m 38s\n",
      "1091:\tlearn 0.675519573\ttest 0.6395514129\tbestTest 0.6395607214\t\ttotal: 26m 23s\tremaining: 2m 36s\n",
      "1092:\tlearn 0.6755498755\ttest 0.6395421278\tbestTest 0.6395607214\t\ttotal: 26m 25s\tremaining: 2m 35s\n",
      "1093:\tlearn 0.6755764917\ttest 0.6395508412\tbestTest 0.6395607214\t\ttotal: 26m 27s\tremaining: 2m 33s\n",
      "1094:\tlearn 0.6756134002\ttest 0.6395421459\tbestTest 0.6395607214\t\ttotal: 26m 28s\tremaining: 2m 32s\n",
      "1095:\tlearn 0.675648198\ttest 0.6395270229\tbestTest 0.6395607214\t\ttotal: 26m 30s\tremaining: 2m 30s\n",
      "1096:\tlearn 0.6756705848\ttest 0.6395241915\tbestTest 0.6395607214\t\ttotal: 26m 31s\tremaining: 2m 29s\n",
      "1097:\tlearn 0.6756942738\ttest 0.6395185299\tbestTest 0.6395607214\t\ttotal: 26m 33s\tremaining: 2m 28s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1098:\tlearn 0.6757413243\ttest 0.639531458\tbestTest 0.6395607214\t\ttotal: 26m 35s\tremaining: 2m 26s\n",
      "1099:\tlearn 0.6757869358\ttest 0.639560291\tbestTest 0.6395607214\t\ttotal: 26m 36s\tremaining: 2m 25s\n",
      "1100:\tlearn 0.6757960363\ttest 0.6395618052\tbestTest 0.6395618052\t\ttotal: 26m 38s\tremaining: 2m 23s\n",
      "1101:\tlearn 0.6758253834\ttest 0.6395478671\tbestTest 0.6395618052\t\ttotal: 26m 39s\tremaining: 2m 22s\n",
      "1102:\tlearn 0.6758511889\ttest 0.639546467\tbestTest 0.6395618052\t\ttotal: 26m 41s\tremaining: 2m 20s\n",
      "1103:\tlearn 0.6758813005\ttest 0.6395586575\tbestTest 0.6395618052\t\ttotal: 26m 42s\tremaining: 2m 19s\n",
      "1104:\tlearn 0.675901277\ttest 0.6395579483\tbestTest 0.6395618052\t\ttotal: 26m 44s\tremaining: 2m 17s\n",
      "1105:\tlearn 0.6759214438\ttest 0.6395510836\tbestTest 0.6395618052\t\ttotal: 26m 46s\tremaining: 2m 16s\n",
      "1106:\tlearn 0.6759350061\ttest 0.6395463866\tbestTest 0.6395618052\t\ttotal: 26m 47s\tremaining: 2m 15s\n",
      "1107:\tlearn 0.6759696351\ttest 0.6395449294\tbestTest 0.6395618052\t\ttotal: 26m 49s\tremaining: 2m 13s\n",
      "1108:\tlearn 0.6759933002\ttest 0.6395497275\tbestTest 0.6395618052\t\ttotal: 26m 50s\tremaining: 2m 12s\n",
      "1109:\tlearn 0.6760189226\ttest 0.6395474432\tbestTest 0.6395618052\t\ttotal: 26m 52s\tremaining: 2m 10s\n",
      "1110:\tlearn 0.6760683313\ttest 0.6395459912\tbestTest 0.6395618052\t\ttotal: 26m 53s\tremaining: 2m 9s\n",
      "1111:\tlearn 0.6760900462\ttest 0.6395535948\tbestTest 0.6395618052\t\ttotal: 26m 55s\tremaining: 2m 7s\n",
      "1112:\tlearn 0.6761548742\ttest 0.639561135\tbestTest 0.6395618052\t\ttotal: 26m 57s\tremaining: 2m 6s\n",
      "1113:\tlearn 0.6761882197\ttest 0.639560759\tbestTest 0.6395618052\t\ttotal: 26m 58s\tremaining: 2m 4s\n",
      "1114:\tlearn 0.6762644335\ttest 0.6395620075\tbestTest 0.6395620075\t\ttotal: 27m\tremaining: 2m 3s\n",
      "1115:\tlearn 0.6762913278\ttest 0.6395701803\tbestTest 0.6395701803\t\ttotal: 27m 2s\tremaining: 2m 2s\n",
      "1116:\tlearn 0.6763125269\ttest 0.6395715234\tbestTest 0.6395715234\t\ttotal: 27m 3s\tremaining: 2m\n",
      "1117:\tlearn 0.6763437931\ttest 0.6395756759\tbestTest 0.6395756759\t\ttotal: 27m 5s\tremaining: 1m 59s\n",
      "1118:\tlearn 0.6763594064\ttest 0.6395699949\tbestTest 0.6395756759\t\ttotal: 27m 7s\tremaining: 1m 57s\n",
      "1119:\tlearn 0.6763791144\ttest 0.6395662663\tbestTest 0.6395756759\t\ttotal: 27m 8s\tremaining: 1m 56s\n",
      "1120:\tlearn 0.6764110913\ttest 0.6395750938\tbestTest 0.6395756759\t\ttotal: 27m 9s\tremaining: 1m 54s\n",
      "1121:\tlearn 0.6764462164\ttest 0.6395823746\tbestTest 0.6395823746\t\ttotal: 27m 11s\tremaining: 1m 53s\n",
      "1122:\tlearn 0.6764549579\ttest 0.6395875928\tbestTest 0.6395875928\t\ttotal: 27m 12s\tremaining: 1m 51s\n",
      "1123:\tlearn 0.6764914039\ttest 0.6395881127\tbestTest 0.6395881127\t\ttotal: 27m 14s\tremaining: 1m 50s\n",
      "1124:\tlearn 0.6765438335\ttest 0.6396031243\tbestTest 0.6396031243\t\ttotal: 27m 16s\tremaining: 1m 49s\n",
      "1125:\tlearn 0.6765794594\ttest 0.639586859\tbestTest 0.6396031243\t\ttotal: 27m 17s\tremaining: 1m 47s\n",
      "1126:\tlearn 0.6765866321\ttest 0.6395884446\tbestTest 0.6396031243\t\ttotal: 27m 19s\tremaining: 1m 46s\n",
      "1127:\tlearn 0.6766017993\ttest 0.6395883344\tbestTest 0.6396031243\t\ttotal: 27m 21s\tremaining: 1m 44s\n",
      "1128:\tlearn 0.6766210221\ttest 0.6395798427\tbestTest 0.6396031243\t\ttotal: 27m 22s\tremaining: 1m 43s\n",
      "1129:\tlearn 0.6766556097\ttest 0.6395770125\tbestTest 0.6396031243\t\ttotal: 27m 24s\tremaining: 1m 41s\n",
      "1130:\tlearn 0.6766756334\ttest 0.639571456\tbestTest 0.6396031243\t\ttotal: 27m 25s\tremaining: 1m 40s\n",
      "1131:\tlearn 0.6766940108\ttest 0.6395683912\tbestTest 0.6396031243\t\ttotal: 27m 27s\tremaining: 1m 38s\n",
      "1132:\tlearn 0.6767125653\ttest 0.6395834857\tbestTest 0.6396031243\t\ttotal: 27m 29s\tremaining: 1m 37s\n",
      "1133:\tlearn 0.6767396933\ttest 0.6395852709\tbestTest 0.6396031243\t\ttotal: 27m 30s\tremaining: 1m 36s\n",
      "1134:\tlearn 0.6767514712\ttest 0.6395853928\tbestTest 0.6396031243\t\ttotal: 27m 32s\tremaining: 1m 34s\n",
      "1135:\tlearn 0.6767972958\ttest 0.6395808319\tbestTest 0.6396031243\t\ttotal: 27m 33s\tremaining: 1m 33s\n",
      "1136:\tlearn 0.6768571977\ttest 0.6395665321\tbestTest 0.6396031243\t\ttotal: 27m 35s\tremaining: 1m 31s\n",
      "1137:\tlearn 0.676877686\ttest 0.6395475391\tbestTest 0.6396031243\t\ttotal: 27m 37s\tremaining: 1m 30s\n",
      "1138:\tlearn 0.6769408972\ttest 0.6395326274\tbestTest 0.6396031243\t\ttotal: 27m 38s\tremaining: 1m 28s\n",
      "1139:\tlearn 0.6769573838\ttest 0.6395262619\tbestTest 0.6396031243\t\ttotal: 27m 40s\tremaining: 1m 27s\n",
      "1140:\tlearn 0.6769982906\ttest 0.6395432388\tbestTest 0.6396031243\t\ttotal: 27m 42s\tremaining: 1m 25s\n",
      "1141:\tlearn 0.6770309426\ttest 0.6395261439\tbestTest 0.6396031243\t\ttotal: 27m 43s\tremaining: 1m 24s\n",
      "1142:\tlearn 0.6770575955\ttest 0.6395396632\tbestTest 0.6396031243\t\ttotal: 27m 45s\tremaining: 1m 23s\n",
      "1143:\tlearn 0.6770852311\ttest 0.639548002\tbestTest 0.6396031243\t\ttotal: 27m 46s\tremaining: 1m 21s\n",
      "1144:\tlearn 0.6771002824\ttest 0.6395338733\tbestTest 0.6396031243\t\ttotal: 27m 48s\tremaining: 1m 20s\n",
      "1145:\tlearn 0.6771173733\ttest 0.6395239503\tbestTest 0.6396031243\t\ttotal: 27m 50s\tremaining: 1m 18s\n",
      "1146:\tlearn 0.6771575804\ttest 0.6395276426\tbestTest 0.6396031243\t\ttotal: 27m 51s\tremaining: 1m 17s\n",
      "1147:\tlearn 0.6771928885\ttest 0.6395205082\tbestTest 0.6396031243\t\ttotal: 27m 53s\tremaining: 1m 15s\n",
      "1148:\tlearn 0.6772163072\ttest 0.6395117313\tbestTest 0.6396031243\t\ttotal: 27m 54s\tremaining: 1m 14s\n",
      "1149:\tlearn 0.6772177299\ttest 0.639515408\tbestTest 0.6396031243\t\ttotal: 27m 56s\tremaining: 1m 12s\n",
      "1150:\tlearn 0.6772473514\ttest 0.6395041549\tbestTest 0.6396031243\t\ttotal: 27m 57s\tremaining: 1m 11s\n",
      "1151:\tlearn 0.6772668451\ttest 0.6395019185\tbestTest 0.6396031243\t\ttotal: 27m 59s\tremaining: 1m 9s\n",
      "1152:\tlearn 0.6772780346\ttest 0.6395023476\tbestTest 0.6396031243\t\ttotal: 28m\tremaining: 1m 8s\n",
      "1153:\tlearn 0.6773092298\ttest 0.6395042275\tbestTest 0.6396031243\t\ttotal: 28m 2s\tremaining: 1m 7s\n",
      "1154:\tlearn 0.6773384821\ttest 0.639498807\tbestTest 0.6396031243\t\ttotal: 28m 3s\tremaining: 1m 5s\n",
      "1155:\tlearn 0.6773507909\ttest 0.6394970024\tbestTest 0.6396031243\t\ttotal: 28m 5s\tremaining: 1m 4s\n",
      "1156:\tlearn 0.6773680683\ttest 0.6394904087\tbestTest 0.6396031243\t\ttotal: 28m 6s\tremaining: 1m 2s\n",
      "1157:\tlearn 0.6773815753\ttest 0.6394903672\tbestTest 0.6396031243\t\ttotal: 28m 8s\tremaining: 1m 1s\n",
      "1158:\tlearn 0.6773951448\ttest 0.639477649\tbestTest 0.6396031243\t\ttotal: 28m 10s\tremaining: 59.8s\n",
      "1159:\tlearn 0.6774216132\ttest 0.6394772005\tbestTest 0.6396031243\t\ttotal: 28m 11s\tremaining: 58.3s\n",
      "1160:\tlearn 0.6774484478\ttest 0.6394657282\tbestTest 0.6396031243\t\ttotal: 28m 13s\tremaining: 56.9s\n",
      "1161:\tlearn 0.6775058648\ttest 0.6394916053\tbestTest 0.6396031243\t\ttotal: 28m 14s\tremaining: 55.4s\n",
      "1162:\tlearn 0.6775147281\ttest 0.6395093614\tbestTest 0.6396031243\t\ttotal: 28m 16s\tremaining: 54s\n",
      "1163:\tlearn 0.6775278456\ttest 0.6395100822\tbestTest 0.6396031243\t\ttotal: 28m 17s\tremaining: 52.5s\n",
      "1164:\tlearn 0.677566243\ttest 0.6395202917\tbestTest 0.6396031243\t\ttotal: 28m 19s\tremaining: 51s\n",
      "1165:\tlearn 0.6775784719\ttest 0.6395284619\tbestTest 0.6396031243\t\ttotal: 28m 20s\tremaining: 49.6s\n",
      "1166:\tlearn 0.6776088716\ttest 0.6395259391\tbestTest 0.6396031243\t\ttotal: 28m 22s\tremaining: 48.1s\n",
      "1167:\tlearn 0.6776288129\ttest 0.6395227822\tbestTest 0.6396031243\t\ttotal: 28m 23s\tremaining: 46.7s\n",
      "1168:\tlearn 0.677647069\ttest 0.6395360941\tbestTest 0.6396031243\t\ttotal: 28m 25s\tremaining: 45.2s\n",
      "1169:\tlearn 0.6776814846\ttest 0.6395366308\tbestTest 0.6396031243\t\ttotal: 28m 26s\tremaining: 43.8s\n",
      "1170:\tlearn 0.6777105485\ttest 0.6395562927\tbestTest 0.6396031243\t\ttotal: 28m 28s\tremaining: 42.3s\n",
      "1171:\tlearn 0.6777869563\ttest 0.6395120256\tbestTest 0.6396031243\t\ttotal: 28m 29s\tremaining: 40.8s\n",
      "1172:\tlearn 0.6777964274\ttest 0.6395135437\tbestTest 0.6396031243\t\ttotal: 28m 31s\tremaining: 39.4s\n",
      "1173:\tlearn 0.6778140848\ttest 0.6395074673\tbestTest 0.6396031243\t\ttotal: 28m 32s\tremaining: 37.9s\n",
      "1174:\tlearn 0.6778338288\ttest 0.6394938805\tbestTest 0.6396031243\t\ttotal: 28m 34s\tremaining: 36.5s\n",
      "1175:\tlearn 0.6778383486\ttest 0.6394956048\tbestTest 0.6396031243\t\ttotal: 28m 35s\tremaining: 35s\n",
      "1176:\tlearn 0.6778698855\ttest 0.6394951342\tbestTest 0.6396031243\t\ttotal: 28m 37s\tremaining: 33.6s\n",
      "1177:\tlearn 0.6779165027\ttest 0.6394781287\tbestTest 0.6396031243\t\ttotal: 28m 39s\tremaining: 32.1s\n",
      "1178:\tlearn 0.6779524113\ttest 0.6394959795\tbestTest 0.6396031243\t\ttotal: 28m 40s\tremaining: 30.6s\n",
      "1179:\tlearn 0.6779648271\ttest 0.6395052802\tbestTest 0.6396031243\t\ttotal: 28m 41s\tremaining: 29.2s\n",
      "1180:\tlearn 0.6779720239\ttest 0.6395097737\tbestTest 0.6396031243\t\ttotal: 28m 43s\tremaining: 27.7s\n",
      "1181:\tlearn 0.6779975055\ttest 0.6395208829\tbestTest 0.6396031243\t\ttotal: 28m 44s\tremaining: 26.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1182:\tlearn 0.6780380124\ttest 0.6395297091\tbestTest 0.6396031243\t\ttotal: 28m 46s\tremaining: 24.8s\n",
      "1183:\tlearn 0.6780519959\ttest 0.6395315475\tbestTest 0.6396031243\t\ttotal: 28m 47s\tremaining: 23.3s\n",
      "1184:\tlearn 0.678057979\ttest 0.6395300436\tbestTest 0.6396031243\t\ttotal: 28m 49s\tremaining: 21.9s\n",
      "1185:\tlearn 0.6780942708\ttest 0.6395231608\tbestTest 0.6396031243\t\ttotal: 28m 50s\tremaining: 20.4s\n",
      "1186:\tlearn 0.6781428361\ttest 0.6395035689\tbestTest 0.6396031243\t\ttotal: 28m 52s\tremaining: 19s\n",
      "1187:\tlearn 0.6781420938\ttest 0.6395059219\tbestTest 0.6396031243\t\ttotal: 28m 53s\tremaining: 17.5s\n",
      "1188:\tlearn 0.6781679607\ttest 0.6395130005\tbestTest 0.6396031243\t\ttotal: 28m 54s\tremaining: 16.1s\n",
      "1189:\tlearn 0.6781762749\ttest 0.63951616\tbestTest 0.6396031243\t\ttotal: 28m 56s\tremaining: 14.6s\n",
      "1190:\tlearn 0.6781935205\ttest 0.639497849\tbestTest 0.6396031243\t\ttotal: 28m 57s\tremaining: 13.1s\n",
      "1191:\tlearn 0.6781997001\ttest 0.6394943576\tbestTest 0.6396031243\t\ttotal: 28m 59s\tremaining: 11.7s\n",
      "1192:\tlearn 0.6782085178\ttest 0.6394794472\tbestTest 0.6396031243\t\ttotal: 29m\tremaining: 10.2s\n",
      "1193:\tlearn 0.6782318605\ttest 0.6394825885\tbestTest 0.6396031243\t\ttotal: 29m 1s\tremaining: 8.75s\n",
      "1194:\tlearn 0.678245617\ttest 0.6394890539\tbestTest 0.6396031243\t\ttotal: 29m 3s\tremaining: 7.29s\n",
      "1195:\tlearn 0.6782716268\ttest 0.6394919048\tbestTest 0.6396031243\t\ttotal: 29m 4s\tremaining: 5.83s\n",
      "1196:\tlearn 0.6782858537\ttest 0.639493922\tbestTest 0.6396031243\t\ttotal: 29m 6s\tremaining: 4.38s\n",
      "1197:\tlearn 0.6782980034\ttest 0.6394853603\tbestTest 0.6396031243\t\ttotal: 29m 7s\tremaining: 2.92s\n",
      "1198:\tlearn 0.678335156\ttest 0.6394757212\tbestTest 0.6396031243\t\ttotal: 29m 9s\tremaining: 1.46s\n",
      "1199:\tlearn 0.6783828958\ttest 0.6394959445\tbestTest 0.6396031243\t\ttotal: 29m 10s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.6396031243\n",
      "bestIteration = 1124\n",
      "\n",
      "Shrink model to first 1125 iterations.\n",
      "0.279206248505\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "from catboost import CatBoostClassifier\n",
    "from multiprocessing import *\n",
    "\n",
    "train = pd.read_csv(base_path + 'train_p.csv')\n",
    "test = pd.read_csv(base_path + 'test_p.csv')\n",
    "col = [c for c in train.columns if c not in ['id','target']]\n",
    "print(len(col))\n",
    "col = [c for c in col if not c.startswith('ps_calc_')]\n",
    "print(len(col))\n",
    "\n",
    "train = train.replace(-1, np.NaN)\n",
    "d_median = train.median(axis=0)\n",
    "d_mean = train.mean(axis=0)\n",
    "train = train.fillna(-1)\n",
    "\n",
    "def transform_df(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    dcol = [c for c in df.columns if c not in ['id','target']]\n",
    "    df['ps_car_13_x_ps_reg_03'] = df['ps_car_13'] * df['ps_reg_03']\n",
    "    df['negative_one_vals'] = np.sum((df[dcol]==-1).values, axis=1)\n",
    "    for c in dcol:\n",
    "        if '_bin' not in c: #standard arithmetic\n",
    "            df[c+str('_median_range')] = (df[c].values > d_median[c]).astype(np.int)\n",
    "            df[c+str('_mean_range')] = (df[c].values > d_mean[c]).astype(np.int)\n",
    "            #df[c+str('_sq')] = np.power(df[c].values,2).astype(np.float32)\n",
    "            #df[c+str('_sqr')] = np.square(df[c].values).astype(np.float32)\n",
    "            #df[c+str('_log')] = np.log(np.abs(df[c].values) + 1)\n",
    "            #df[c+str('_exp')] = np.exp(df[c].values) - 1\n",
    "    \n",
    "    return df\n",
    "\n",
    "def multi_transform(df):\n",
    "    print('Init Shape: ', df.shape)\n",
    "    #p = Pool(cpu_count())\n",
    "    df = p.map(transform_df, np.array_split(df, cpu_count()))\n",
    "    df = pd.concat(df, axis=0, ignore_index=True).reset_index(drop=True)\n",
    "    #p.close(); p.join()\n",
    "    print('After Shape: ', df.shape)\n",
    "    return df\n",
    "\n",
    "def gini(y, pred):\n",
    "    fpr, tpr, thr = metrics.roc_curve(y, pred, pos_label=1)\n",
    "    g = 2 * metrics.auc(fpr, tpr) -1\n",
    "    return g\n",
    "\n",
    "def gini_catboost(pred, y):\n",
    "    return gini(y, pred)\n",
    "\n",
    "x1, x2, y1, y2 = model_selection.train_test_split(train, train['target'], test_size=0.25, random_state=99)\n",
    "\n",
    "x1 = transform_df(x1)\n",
    "x2 = transform_df(x2)\n",
    "test = transform_df(test)\n",
    "train = transform_df(train)\n",
    "\n",
    "col = [c for c in x1.columns if c not in ['id','target']]\n",
    "col = [c for c in col if not c.startswith('ps_calc_')]\n",
    "print(x1.values.shape, x2.values.shape)\n",
    "\n",
    "#remove duplicates just in case\n",
    "#tdups = transform_df(train)\n",
    "#dups = tdups[tdups.duplicated(subset=col, keep=False)]\n",
    "\n",
    "#x1 = x1[~(x1['id'].isin(dups['id'].values))]\n",
    "#x2 = x2[~(x2['id'].isin(dups['id'].values))]\n",
    "#print(x1.values.shape, x2.values.shape)\n",
    "\n",
    "y1 = x1['target']\n",
    "y2 = x2['target']\n",
    "x1 = x1[col]\n",
    "x2 = x2[col]\n",
    "\n",
    "model3 = CatBoostClassifier(iterations=1200, learning_rate=0.02, depth=7, loss_function='Logloss', eval_metric='AUC', random_seed=99, od_type='Iter', od_wait=100) \n",
    "model3.fit(x1[col], y1, eval_set=(x2[col], y2), use_best_model=True, verbose=True)\n",
    "print(gini_catboost(model3.predict_proba(x2[col])[:,1], y2))\n",
    "test['target'] = model3.predict_proba(test[col])[:,1]\n",
    "test['target'] = (np.exp(test['target'].values) - 1.0).clip(0,1)\n",
    "train['target'] = model3.predict_proba(train[col])[:,1]\n",
    "train['target'] = (np.exp(train['target'].values) - 1.0).clip(0,1)\n",
    "test[['id','target']].to_csv(base_path + 'test_catboost_submission.csv', index=False, float_format='%.5f')\n",
    "train[['id','target']].to_csv(base_path + 'train_catboost_submission.csv', index=False, float_format='%.5f')\n",
    "\n",
    "#Extras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame({'imp': model3.feature_importances_, 'col':col})\n",
    "df = df.sort_values(['imp','col'], ascending=[True, False])\n",
    "_ = df.plot(kind='barh', x='col', y='imp', figsize=(7,12))\n",
    "plt.savefig('catboost_feature_importance.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoosting Upsampleing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current feature                                 ps_reg_01_plus_ps_car_04_cat    2 in   0.1[0]\ttrain-gini:0.208617\tvalid-gini:0.19601\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 20 rounds.\n",
      "[100]\ttrain-gini:0.325499\tvalid-gini:0.274226\n",
      "Stopping. Best iteration:\n",
      "[178]\ttrain-gini:0.350843\tvalid-gini:0.278052\n",
      "\n",
      "[0]\ttrain-gini:0.195808\tvalid-gini:0.194938\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 20 rounds.\n",
      "[100]\ttrain-gini:0.327769\tvalid-gini:0.27977\n",
      "[200]\ttrain-gini:0.358617\tvalid-gini:0.281786\n",
      "Stopping. Best iteration:\n",
      "[188]\ttrain-gini:0.354598\tvalid-gini:0.282196\n",
      "\n",
      "[0]\ttrain-gini:0.199196\tvalid-gini:0.208818\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 20 rounds.\n",
      "[100]\ttrain-gini:0.321462\tvalid-gini:0.304144\n",
      "Stopping. Best iteration:\n",
      "[144]\ttrain-gini:0.337048\tvalid-gini:0.305773\n",
      "\n",
      "[0]\ttrain-gini:0.200138\tvalid-gini:0.193684\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 20 rounds.\n",
      "[100]\ttrain-gini:0.324508\tvalid-gini:0.278173\n",
      "Stopping. Best iteration:\n",
      "[173]\ttrain-gini:0.349346\tvalid-gini:0.281553\n",
      "\n",
      "[0]\ttrain-gini:0.192587\tvalid-gini:0.181169\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 20 rounds.\n",
      "[100]\ttrain-gini:0.326952\tvalid-gini:0.275318\n",
      "Stopping. Best iteration:\n",
      "[172]\ttrain-gini:0.350653\tvalid-gini:0.277745\n",
      "\n",
      "Full OOF score : -0.001459\n",
      "Best mean score : 0.000000 + 0.000000 @ 199\n",
      "ps_reg_01_plus_ps_car_04_cat_avg   :     0.0000\n",
      "ps_reg_01_plus_ps_car_02_cat_avg   :     0.0000\n",
      "ps_ind_04_cat_avg                  :     0.0000\n",
      "ps_car_08_cat_avg                  :     0.0000\n",
      "ps_car_05_cat_avg                  :     0.0000\n",
      "ps_ind_02_cat_avg                  :     0.0000\n",
      "ps_car_02_cat_avg                  :     0.0000\n",
      "ps_car_09_cat_avg                  :     0.0000\n",
      "ps_car_04_cat_avg                  :     0.0000\n",
      "ps_car_06_cat_avg                  :     0.0000\n",
      "ps_car_03_cat_avg                  :     0.0000\n",
      "ps_car_07_cat_avg                  :     0.0000\n",
      "ps_car_01_cat_avg                  :     0.0000\n",
      "ps_ind_05_cat_avg                  :     0.0000\n",
      "ps_reg_01_plus_ps_car_04_cat       :     0.0000\n",
      "ps_reg_01_plus_ps_car_02_cat       :     0.0000\n",
      "ps_ind_14                          :     0.0000\n",
      "ps_ind_12_bin                      :     0.0000\n",
      "ps_ind_04_cat                      :     0.0000\n",
      "ps_car_08_cat                      :     0.0000\n",
      "ps_calc_05                         :     0.0000\n",
      "ps_calc_09                         :     0.0000\n",
      "ps_car_05_cat                      :     0.0000\n",
      "ps_car_11                          :     0.0000\n",
      "ps_ind_02_cat                      :     0.0000\n",
      "ps_car_02_cat                      :     0.0000\n",
      "ps_car_09_cat                      :     0.0000\n",
      "ps_car_04_cat                      :     0.0000\n",
      "ps_car_06_cat                      :     0.0000\n",
      "ps_ind_0609_bin                    :     0.0000\n",
      "ps_ind_161718_bin                  :     0.0000\n",
      "ps_ind_01                          :     0.0000\n",
      "ps_car_15                          :     0.0000\n",
      "ps_reg_01                          :     0.0000\n",
      "ps_car_03_cat                      :     0.0000\n",
      "ps_car_07_cat                      :     0.0000\n",
      "ps_car_01_cat                      :     0.0000\n",
      "ps_car_12                          :     0.0000\n",
      "ps_car_14                          :     0.0000\n",
      "ps_reg_02                          :     0.0000\n",
      "ps_ind_15                          :     0.0000\n",
      "ps_ind_03                          :     0.0000\n",
      "ps_ind_05_cat                      :     0.0000\n",
      "ps_reg_03                          :     0.0000\n",
      "ps_car_13                          :     0.0000\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "\"\"\"\n",
    "This simple scripts demonstrates the use of xgboost eval results to get the best round\n",
    "for the current fold and accross folds. \n",
    "It also shows an upsampling method that limits cross-validation overfitting.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import gc\n",
    "from numba import jit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time \n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "@jit\n",
    "def eval_gini(y_true, y_prob):\n",
    "    \"\"\"\n",
    "    Original author CPMP : https://www.kaggle.com/cpmpml\n",
    "    In kernel : https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = eval_gini(labels, preds)\n",
    "    return [('gini', gini_score)]\n",
    "\n",
    "\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "\n",
    "def target_encode(trn_series=None,\n",
    "                  tst_series=None,\n",
    "                  target=None,\n",
    "                  min_samples_leaf=1,\n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    \"\"\"\n",
    "    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int) : minimum samples to take category average into account\n",
    "    smoothing (int) : smoothing effect to balance categorical average vs prior\n",
    "    \"\"\"\n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean\n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)\n",
    "\n",
    "gc.enable()\n",
    "\n",
    "trn_df = pd.read_csv(base_path + \"train_p.csv\", index_col=0)\n",
    "sub_df = pd.read_csv(base_path + \"test_p.csv\", index_col=0)\n",
    "\n",
    "target = trn_df[\"target\"]\n",
    "del trn_df[\"target\"]\n",
    "\n",
    "train_features = [\n",
    "    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n",
    "\"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n",
    "\"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n",
    "\"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n",
    "\"ps_ind_15\",  #            :  922.18 / shadow  242.00\n",
    "\"ps_reg_02\",  #            :  920.65 / shadow  267.50\n",
    "\"ps_car_14\",  #            :  798.48 / shadow  549.58\n",
    "\"ps_car_12\",  #            :  731.93 / shadow  293.62\n",
    "\"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n",
    "\"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n",
    "\"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n",
    "\"ps_reg_01\",  #            :  598.60 / shadow  178.57\n",
    "\"ps_car_15\",  #            :  593.35 / shadow  226.43\n",
    "\"ps_ind_01\",  #            :  547.32 / shadow  154.58\n",
    "\"ps_ind_161718_bin\",  #        :  475.37 / shadow   34.17\n",
    "\"ps_ind_0609_bin\",  #        :  435.28 / shadow   28.92\n",
    "\"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n",
    "\"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n",
    "\"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n",
    "\"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n",
    "\"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n",
    "\"ps_car_11\",  #            :  173.28 / shadow   76.45\n",
    "\"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n",
    "\"ps_calc_09\",  #           :  169.13 / shadow  129.72\n",
    "\"ps_calc_05\",  #           :  148.83 / shadow  120.68\n",
    "\"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n",
    "\"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n",
    "\"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n",
    "\"ps_ind_14\",  #            :   37.37 / shadow   16.65\n",
    "]\n",
    "# add combinations\n",
    "combs = [\n",
    "    ('ps_reg_01', 'ps_car_02_cat'),  \n",
    "    ('ps_reg_01', 'ps_car_04_cat'),\n",
    "]\n",
    "start = time.time()\n",
    "for n_c, (f1, f2) in enumerate(combs):\n",
    "    name1 = f1 + \"_plus_\" + f2\n",
    "    print('current feature %60s %4d in %5.1f'\n",
    "          % (name1, n_c + 1, (time.time() - start) / 60), end='')\n",
    "    print('\\r' * 75, end='')\n",
    "    trn_df[name1] = trn_df[f1].apply(lambda x: str(x)) + \"_\" + trn_df[f2].apply(lambda x: str(x))\n",
    "    sub_df[name1] = sub_df[f1].apply(lambda x: str(x)) + \"_\" + sub_df[f2].apply(lambda x: str(x))\n",
    "    # Label Encode\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(trn_df[name1].values) + list(sub_df[name1].values))\n",
    "    trn_df[name1] = lbl.transform(list(trn_df[name1].values))\n",
    "    sub_df[name1] = lbl.transform(list(sub_df[name1].values))\n",
    "\n",
    "    train_features.append(name1)\n",
    "    \n",
    "trn_df = trn_df[train_features]\n",
    "sub_df = sub_df[train_features]\n",
    "\n",
    "f_cats = [f for f in trn_df.columns if \"_cat\" in f]\n",
    "\n",
    "for f in f_cats:\n",
    "    trn_df[f + \"_avg\"], sub_df[f + \"_avg\"] = target_encode(trn_series=trn_df[f],\n",
    "                                         tst_series=sub_df[f],\n",
    "                                         target=target,\n",
    "                                         min_samples_leaf=200,\n",
    "                                         smoothing=10,\n",
    "                                         noise_level=0)\n",
    "\n",
    "n_splits = 5\n",
    "n_estimators = 200\n",
    "folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=15) \n",
    "imp_df = np.zeros((len(trn_df.columns), n_splits))\n",
    "xgb_evals = np.zeros((n_estimators, n_splits))\n",
    "oof = np.empty(len(trn_df))\n",
    "sub_preds = np.zeros(len(sub_df))\n",
    "sub_preds_train = np.zeros(len(trn_df))\n",
    "increase = True\n",
    "np.random.seed(0)\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(target, target)):\n",
    "    trn_dat, trn_tgt = trn_df.iloc[trn_idx], target.iloc[trn_idx]\n",
    "    val_dat, val_tgt = trn_df.iloc[val_idx], target.iloc[val_idx]\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "    params = {'n_estimators':n_estimators,\n",
    "                        'max_depth':4,\n",
    "                        'objective':\"binary:logistic\",\n",
    "                        'learning_rate':.1, \n",
    "                        'subsample':.8, \n",
    "                        'colsample_bytree':.8,\n",
    "                        'gamma':1,\n",
    "                        'reg_alpha':0,\n",
    "                        'reg_lambda':1,\n",
    "                        'nthread':2}\n",
    "    # Upsample during cross validation to avoid having the same samples\n",
    "    # in both train and validation sets\n",
    "    # Validation set is not up-sampled to monitor overfitting\n",
    "    if increase:\n",
    "        # Get positive examples\n",
    "        pos = pd.Series(trn_tgt == 1)\n",
    "        # Add positive examples\n",
    "        trn_dat = pd.concat([trn_dat, trn_dat.loc[pos]], axis=0)\n",
    "        trn_tgt = pd.concat([trn_tgt, trn_tgt.loc[pos]], axis=0)\n",
    "        # Shuffle data\n",
    "        idx = np.arange(len(trn_dat))\n",
    "        np.random.shuffle(idx)\n",
    "        trn_dat = trn_dat.iloc[idx]\n",
    "        trn_tgt = trn_tgt.iloc[idx]\n",
    "        \n",
    "    d_train = xgb.DMatrix(trn_dat, trn_tgt) \n",
    "    d_valid = xgb.DMatrix(val_dat, val_tgt) \n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "        \n",
    "    clf = xgb.train(params, d_train, 10**6, watchlist, early_stopping_rounds=20, \n",
    "                          feval=gini_xgb, maximize=True, verbose_eval=100)\n",
    "            \n",
    "\n",
    "    sub_preds += clf.predict(xgb.DMatrix(sub_df), ntree_limit=clf.best_ntree_limit) / n_splits\n",
    "    sub_preds_train += clf.predict(xgb.DMatrix(trn_df), ntree_limit=clf.best_ntree_limit) / n_splits\n",
    "\n",
    "    # Display results\n",
    "#     print(\"Fold %2d : %.6f @%4d / best score is %.6f @%4d\"\n",
    "#           % (fold_ + 1,\n",
    "#              eval_gini(val_tgt, oof[val_idx]),\n",
    "#              n_estimators,\n",
    "#              xgb_evals[best_round, fold_],\n",
    "#              best_round))\n",
    "          \n",
    "print(\"Full OOF score : %.6f\" % eval_gini(target, oof))\n",
    "\n",
    "# Compute mean score and std\n",
    "mean_eval = np.mean(xgb_evals, axis=1)\n",
    "std_eval = np.std(xgb_evals, axis=1)\n",
    "best_round = np.argsort(mean_eval)[::-1][0]\n",
    "\n",
    "print(\"Best mean score : %.6f + %.6f @%4d\"\n",
    "      % (mean_eval[best_round], std_eval[best_round], best_round))\n",
    "    \n",
    "importances = sorted([(trn_df.columns[i], imp) for i, imp in enumerate(imp_df.mean(axis=1))],\n",
    "                     key=lambda x: x[1])\n",
    "\n",
    "for f, imp in importances[::-1]:\n",
    "    print(\"%-34s : %10.4f\" % (f, imp))\n",
    "    \n",
    "sub_df[\"target\"] = sub_preds\n",
    "trn_df[\"target\"] = sub_preds_train\n",
    "\n",
    "sub_df[[\"target\"]].to_csv(base_path + \"test_submission.csv\", index=True, float_format=\"%.9f\")\n",
    "trn_df[[\"target\"]].to_csv(base_path + \"train_submission.csv\", index=True, float_format=\"%.9f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started\n",
      "Fold: 0\n",
      "Fold: 1\n",
      "Fold: 2\n",
      "Fold: 3\n",
      "Fold: 4\n",
      "Scale values\n",
      "GPAri Gini Score: 0.300824656509\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "def GiniScore(y_actual, y_pred):\n",
    "  return 2*roc_auc_score(y_actual, y_pred)-1\n",
    "\n",
    "\n",
    "def Outputs(p):\n",
    "    return 1./(1.+np.exp(-p))\n",
    "\n",
    "\n",
    "def GPI(data):\n",
    "    v = pd.DataFrame()\n",
    "    v[\"0\"] = -3.274750\n",
    "    v[\"1\"] = 0.020000*np.tanh((data[\"loo_ps_ind_06_bin\"] + (data[\"ps_reg_01\"] + (data[\"ps_car_12\"] + (data[\"loo_ps_car_03_cat\"] + data[\"loo_ps_car_07_cat\"])))))\n",
    "    v[\"2\"] = 0.020000*np.tanh((data[\"loo_ps_ind_17_bin\"] + ((data[\"ps_reg_03\"] + data[\"ps_car_12\"]) + (data[\"loo_ps_ind_06_bin\"] + data[\"loo_ps_ind_05_cat\"]))))\n",
    "    v[\"3\"] = 0.020000*np.tanh((data[\"loo_ps_car_01_cat\"] + (data[\"loo_ps_ind_17_bin\"] + ((data[\"ps_car_12\"] + data[\"ps_reg_03\"]) + data[\"loo_ps_ind_07_bin\"]))))\n",
    "    v[\"4\"] = 0.020000*np.tanh((data[\"loo_ps_car_01_cat\"] + ((data[\"loo_ps_car_04_cat\"] + (data[\"ps_reg_03\"] + data[\"ps_car_15\"])) * 3.0)))\n",
    "    v[\"5\"] = 0.020000*np.tanh(((data[\"ps_car_13\"] + ((data[\"loo_ps_car_05_cat\"] + (data[\"ps_reg_01\"] + data[\"loo_ps_car_09_cat\"]))/2.0)) * (10.28825187683105469)))\n",
    "    v[\"6\"] = 0.020000*np.tanh(((8.0) * (data[\"loo_ps_car_04_cat\"] + ((data[\"loo_ps_car_01_cat\"] + data[\"loo_ps_ind_05_cat\"]) + data[\"ps_car_15\"]))))\n",
    "    v[\"7\"] = 0.020000*np.tanh(((data[\"ps_car_13\"] + (((data[\"loo_ps_car_01_cat\"] + data[\"ps_reg_03\"]) + data[\"loo_ps_ind_16_bin\"])/2.0)) * 8.428570))\n",
    "    v[\"8\"] = 0.020000*np.tanh(((10.86397266387939453) * (((data[\"ps_reg_03\"] + data[\"loo_ps_car_07_cat\"]) + data[\"loo_ps_ind_06_bin\"]) + data[\"loo_ps_car_11_cat\"])))\n",
    "    v[\"9\"] = 0.020000*np.tanh((data[\"ps_reg_03\"] + (data[\"loo_ps_ind_16_bin\"] + (data[\"loo_ps_ind_07_bin\"] + (data[\"ps_car_13\"] + data[\"loo_ps_car_03_cat\"])))))\n",
    "    v[\"10\"] = 0.020000*np.tanh((((data[\"ps_car_13\"] + data[\"ps_reg_02\"]) - data[\"ps_ind_15\"]) + (data[\"loo_ps_car_11_cat\"] + data[\"loo_ps_ind_17_bin\"])))\n",
    "    v[\"11\"] = 0.020000*np.tanh(((data[\"ps_car_13\"] + data[\"ps_reg_02\"]) + (data[\"loo_ps_ind_07_bin\"] + (data[\"loo_ps_ind_17_bin\"] + data[\"loo_ps_car_01_cat\"]))))\n",
    "    v[\"12\"] = 0.020000*np.tanh(((data[\"ps_car_13\"] + (data[\"ps_reg_02\"] + ((data[\"loo_ps_car_09_cat\"] + data[\"loo_ps_ind_16_bin\"])/2.0))) * 8.428570))\n",
    "    v[\"13\"] = 0.020000*np.tanh((data[\"ps_reg_02\"] + (data[\"loo_ps_ind_08_bin\"] + ((data[\"loo_ps_ind_16_bin\"] + data[\"ps_car_13\"]) + data[\"loo_ps_ind_07_bin\"]))))\n",
    "    v[\"14\"] = 0.020000*np.tanh((29.500000 * (((data[\"ps_car_13\"] + (data[\"loo_ps_car_09_cat\"] + data[\"loo_ps_ind_16_bin\"]))/2.0) + data[\"loo_ps_ind_05_cat\"])))\n",
    "    v[\"15\"] = 0.020000*np.tanh((29.500000 * ((data[\"loo_ps_car_04_cat\"] + (data[\"loo_ps_car_03_cat\"] + data[\"ps_car_13\"])) + 0.945455)))\n",
    "    v[\"16\"] = 0.020000*np.tanh((8.428570 * ((data[\"loo_ps_ind_05_cat\"] + data[\"loo_ps_car_06_cat\"]) + (data[\"loo_ps_car_07_cat\"] + data[\"loo_ps_ind_17_bin\"]))))\n",
    "    v[\"17\"] = 0.020000*np.tanh((((0.633333 + (data[\"loo_ps_ind_17_bin\"] + data[\"ps_car_13\"])) + data[\"ps_reg_03\"]) * 29.500000))\n",
    "    v[\"18\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_17_bin\"] + data[\"loo_ps_car_11_cat\"]) + (data[\"loo_ps_car_07_cat\"] - data[\"ps_ind_15\"])) + data[\"ps_ind_03\"]))\n",
    "    v[\"19\"] = 0.020000*np.tanh(((data[\"loo_ps_car_07_cat\"] + (data[\"loo_ps_ind_05_cat\"] + (data[\"loo_ps_ind_09_bin\"] + data[\"loo_ps_ind_06_bin\"]))) * (4.85490655899047852)))\n",
    "    v[\"20\"] = 0.020000*np.tanh(((((data[\"loo_ps_ind_06_bin\"] + data[\"loo_ps_car_11_cat\"]) + data[\"loo_ps_car_07_cat\"]) + data[\"loo_ps_car_09_cat\"]) - data[\"ps_ind_15\"]))\n",
    "    v[\"21\"] = 0.020000*np.tanh((8.428570 * ((data[\"loo_ps_ind_05_cat\"] + data[\"ps_car_13\"]) + ((data[\"loo_ps_car_05_cat\"] + data[\"loo_ps_car_01_cat\"])/2.0))))\n",
    "    v[\"22\"] = 0.020000*np.tanh((((data[\"ps_ind_03\"] + (data[\"loo_ps_ind_16_bin\"] + (data[\"loo_ps_ind_05_cat\"] + data[\"loo_ps_ind_06_bin\"])))/2.0) * 29.500000))\n",
    "    v[\"23\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_17_bin\"] + (data[\"loo_ps_ind_09_bin\"] + (data[\"ps_reg_03\"] + data[\"loo_ps_ind_05_cat\"]))) * 29.500000))\n",
    "    v[\"24\"] = 0.020000*np.tanh((data[\"loo_ps_car_03_cat\"] - (data[\"ps_ind_15\"] - (data[\"loo_ps_ind_05_cat\"] + ((data[\"loo_ps_ind_07_bin\"] + data[\"loo_ps_ind_17_bin\"])/2.0)))))\n",
    "    v[\"25\"] = 0.020000*np.tanh(((data[\"ps_reg_02\"] + ((data[\"loo_ps_car_07_cat\"] - -1.0) + data[\"ps_car_13\"])) * (13.29769420623779297)))\n",
    "    v[\"26\"] = 0.020000*np.tanh((29.500000 * ((((data[\"loo_ps_car_01_cat\"] + data[\"ps_car_13\"])/2.0) + (data[\"loo_ps_ind_05_cat\"] + data[\"loo_ps_ind_17_bin\"]))/2.0)))\n",
    "    v[\"27\"] = 0.020000*np.tanh((data[\"ps_reg_03\"] + (1.480000 + (data[\"loo_ps_ind_06_bin\"] + (data[\"loo_ps_car_11_cat\"] + data[\"loo_ps_car_01_cat\"])))))\n",
    "    v[\"28\"] = 0.020000*np.tanh((data[\"loo_ps_car_11_cat\"] + ((data[\"loo_ps_ind_05_cat\"] + (data[\"loo_ps_car_09_cat\"] - data[\"ps_ind_15\"])) + data[\"loo_ps_car_03_cat\"])))\n",
    "    v[\"29\"] = 0.020000*np.tanh(((10.24501132965087891) * (data[\"loo_ps_ind_05_cat\"] + (data[\"ps_ind_03\"] + (data[\"loo_ps_ind_09_bin\"] - data[\"ps_ind_15\"])))))\n",
    "    v[\"30\"] = 0.020000*np.tanh(((data[\"loo_ps_car_11_cat\"] + (data[\"loo_ps_ind_05_cat\"] + data[\"loo_ps_car_07_cat\"])) + (data[\"loo_ps_car_09_cat\"] - data[\"missing\"])))\n",
    "    v[\"31\"] = 0.020000*np.tanh((29.500000 * (data[\"loo_ps_car_01_cat\"] + ((data[\"loo_ps_car_07_cat\"] + data[\"loo_ps_ind_05_cat\"]) + data[\"loo_ps_ind_16_bin\"]))))\n",
    "    v[\"32\"] = 0.020000*np.tanh(((data[\"ps_reg_03\"] + ((data[\"ps_ind_01\"] + 0.887097) + data[\"loo_ps_car_09_cat\"])) * (10.0)))\n",
    "    v[\"33\"] = 0.020000*np.tanh(((data[\"loo_ps_car_03_cat\"] + (data[\"loo_ps_car_03_cat\"] - (data[\"ps_ind_15\"] - 1.480000))) * 29.500000))\n",
    "    v[\"34\"] = 0.020000*np.tanh((data[\"loo_ps_car_09_cat\"] + ((14.32789230346679688) * (data[\"ps_ind_03\"] + (data[\"ps_ind_03\"] * data[\"ps_ind_03\"])))))\n",
    "    v[\"35\"] = 0.020000*np.tanh((29.500000 * (data[\"loo_ps_ind_17_bin\"] + (((data[\"ps_car_13\"] + data[\"ps_ind_03\"])/2.0) + data[\"loo_ps_ind_05_cat\"]))))\n",
    "    v[\"36\"] = 0.020000*np.tanh(((9.0) * (data[\"ps_reg_02\"] + (data[\"loo_ps_car_07_cat\"] + ((data[\"ps_car_15\"] + 1.0)/2.0)))))\n",
    "    v[\"37\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_05_cat\"] + (data[\"loo_ps_ind_08_bin\"] + ((data[\"loo_ps_ind_16_bin\"] + data[\"loo_ps_ind_07_bin\"])/2.0))) * 8.428570))\n",
    "    v[\"38\"] = 0.020000*np.tanh(((2.0 * ((data[\"loo_ps_car_03_cat\"] + data[\"loo_ps_car_07_cat\"]) + data[\"loo_ps_ind_05_cat\"])) + data[\"loo_ps_car_04_cat\"]))\n",
    "    v[\"39\"] = 0.020000*np.tanh((29.500000 * (data[\"loo_ps_ind_07_bin\"] + ((data[\"loo_ps_car_07_cat\"] + 1.089890) - data[\"ps_ind_15\"]))))\n",
    "    v[\"40\"] = 0.020000*np.tanh(((10.18701076507568359) * ((data[\"ps_ind_03\"] * data[\"ps_ind_03\"]) + (data[\"loo_ps_ind_05_cat\"] + data[\"ps_ind_03\"]))))\n",
    "    v[\"41\"] = 0.020000*np.tanh((8.428570 * (data[\"loo_ps_ind_02_cat\"] + (data[\"ps_car_13\"] + (data[\"loo_ps_car_07_cat\"] + data[\"loo_ps_ind_09_bin\"])))))\n",
    "    v[\"42\"] = 0.020000*np.tanh((8.428570 * (((data[\"loo_ps_car_01_cat\"] - 0.435484) + data[\"loo_ps_ind_05_cat\"]) + data[\"loo_ps_ind_17_bin\"])))\n",
    "    v[\"43\"] = 0.020000*np.tanh((data[\"loo_ps_car_09_cat\"] + (29.500000 * (data[\"ps_ind_03\"] + (data[\"ps_ind_03\"] * data[\"ps_ind_03\"])))))\n",
    "    v[\"44\"] = 0.020000*np.tanh((8.428570 * ((data[\"loo_ps_ind_05_cat\"] + data[\"loo_ps_car_09_cat\"]) - (data[\"ps_ind_15\"] + data[\"loo_ps_ind_18_bin\"]))))\n",
    "    v[\"45\"] = 0.020000*np.tanh((data[\"ps_ind_01\"] + ((5.76565647125244141) * (data[\"loo_ps_ind_07_bin\"] + (0.887097 - data[\"ps_ind_15\"])))))\n",
    "    v[\"46\"] = 0.020000*np.tanh(((7.0) * (2.352940 * ((data[\"ps_ind_03\"] * data[\"ps_ind_03\"]) + data[\"ps_ind_03\"]))))\n",
    "    v[\"47\"] = 0.020000*np.tanh((29.500000 * ((data[\"loo_ps_ind_17_bin\"] + (data[\"loo_ps_ind_17_bin\"] + data[\"loo_ps_ind_05_cat\"])) - data[\"ps_ind_03\"])))\n",
    "    v[\"48\"] = 0.020000*np.tanh(((9.90538215637207031) * (((data[\"loo_ps_ind_06_bin\"] + data[\"loo_ps_car_07_cat\"]) + data[\"loo_ps_ind_09_bin\"]) + data[\"loo_ps_ind_09_bin\"])))\n",
    "    v[\"49\"] = 0.020000*np.tanh((data[\"ps_ind_01\"] + ((data[\"loo_ps_car_01_cat\"] + (data[\"ps_ind_01\"] + data[\"loo_ps_ind_06_bin\"])) + data[\"loo_ps_car_09_cat\"])))\n",
    "    v[\"50\"] = 0.020000*np.tanh((29.500000 * (data[\"loo_ps_ind_02_cat\"] + (data[\"loo_ps_car_09_cat\"] + ((data[\"loo_ps_car_07_cat\"] + data[\"loo_ps_ind_05_cat\"])/2.0)))))\n",
    "    v[\"51\"] = 0.020000*np.tanh((29.500000 * (data[\"ps_car_13\"] + (data[\"loo_ps_ind_05_cat\"] + (data[\"loo_ps_ind_06_bin\"] - 2.352940)))))\n",
    "    v[\"52\"] = 0.020000*np.tanh((29.500000 * (data[\"loo_ps_ind_04_cat\"] + (data[\"loo_ps_ind_05_cat\"] + (data[\"loo_ps_ind_07_bin\"] * data[\"ps_ind_03\"])))))\n",
    "    v[\"53\"] = 0.020000*np.tanh((29.500000 * (((9.0) * ((data[\"loo_ps_ind_04_cat\"] + data[\"ps_reg_03\"])/2.0)) - data[\"ps_ind_15\"])))\n",
    "    v[\"54\"] = 0.020000*np.tanh((data[\"loo_ps_ind_17_bin\"] + (data[\"loo_ps_ind_04_cat\"] + (data[\"loo_ps_ind_17_bin\"] + (data[\"ps_reg_02\"] * data[\"loo_ps_ind_05_cat\"])))))\n",
    "    v[\"55\"] = 0.020000*np.tanh((data[\"loo_ps_car_09_cat\"] + ((data[\"loo_ps_ind_06_bin\"] * (data[\"ps_ind_03\"] + data[\"loo_ps_ind_05_cat\"])) - data[\"ps_car_11\"])))\n",
    "    v[\"56\"] = 0.020000*np.tanh(((data[\"ps_ind_01\"] + (data[\"ps_ind_03\"] + data[\"loo_ps_ind_05_cat\"])) * (data[\"loo_ps_ind_07_bin\"] + data[\"loo_ps_car_05_cat\"])))\n",
    "    v[\"57\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_16_bin\"] * data[\"loo_ps_car_03_cat\"]) - (data[\"ps_ind_15\"] - ((data[\"ps_reg_02\"] + data[\"loo_ps_ind_02_cat\"])/2.0))))\n",
    "    v[\"58\"] = 0.020000*np.tanh((((data[\"ps_car_13\"] + -2.0) + (data[\"loo_ps_ind_05_cat\"] - data[\"ps_ind_15\"])) - data[\"ps_car_11\"]))\n",
    "    v[\"59\"] = 0.020000*np.tanh(((data[\"ps_car_15\"] + (3.0 * data[\"loo_ps_ind_17_bin\"])) + (data[\"ps_ind_03\"] * data[\"ps_ind_03\"])))\n",
    "    v[\"60\"] = 0.020000*np.tanh((29.500000 * ((data[\"ps_ind_03\"] * data[\"ps_ind_03\"]) + data[\"ps_ind_03\"])))\n",
    "    v[\"61\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_17_bin\"] + data[\"missing\"]) + (data[\"loo_ps_car_11_cat\"] + data[\"loo_ps_ind_17_bin\"])) * data[\"loo_ps_car_05_cat\"]))\n",
    "    v[\"62\"] = 0.020000*np.tanh((8.428570 + (((data[\"loo_ps_car_03_cat\"] * data[\"loo_ps_ind_09_bin\"]) + data[\"loo_ps_car_01_cat\"]) * 29.500000)))\n",
    "    v[\"63\"] = 0.020000*np.tanh(((data[\"ps_ind_01\"] + (data[\"loo_ps_car_11_cat\"] + data[\"loo_ps_car_05_cat\"])) * (data[\"loo_ps_ind_05_cat\"] - data[\"ps_car_11\"])))\n",
    "    v[\"64\"] = 0.020000*np.tanh((data[\"loo_ps_car_09_cat\"] + (data[\"ps_ind_01\"] + (data[\"loo_ps_ind_09_bin\"] * (data[\"ps_ind_03\"] + data[\"ps_ind_01\"])))))\n",
    "    v[\"65\"] = 0.020000*np.tanh(((data[\"loo_ps_car_11_cat\"] + data[\"loo_ps_ind_02_cat\"]) + (data[\"loo_ps_car_05_cat\"] * (data[\"loo_ps_ind_09_bin\"] + data[\"loo_ps_ind_06_bin\"]))))\n",
    "    v[\"66\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_05_cat\"] * data[\"loo_ps_ind_06_bin\"]) * 29.500000) + (data[\"loo_ps_ind_02_cat\"] * data[\"loo_ps_ind_05_cat\"])))\n",
    "    v[\"67\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_05_cat\"] - data[\"ps_reg_01\"]) * ((data[\"ps_ind_01\"] + data[\"loo_ps_ind_06_bin\"]) + data[\"loo_ps_car_11_cat\"])))\n",
    "    v[\"68\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_05_cat\"] - data[\"ps_car_11\"]) * (3.0 * (data[\"loo_ps_ind_17_bin\"] + data[\"loo_ps_car_04_cat\"]))))\n",
    "    v[\"69\"] = 0.019996*np.tanh((((data[\"ps_reg_02\"] - data[\"ps_car_11\"]) + (data[\"loo_ps_ind_04_cat\"] * 3.0)) - data[\"ps_ind_15\"]))\n",
    "    v[\"70\"] = 0.020000*np.tanh((-((data[\"loo_ps_ind_02_cat\"] * (data[\"ps_ind_03\"] + (data[\"ps_ind_03\"] + data[\"ps_ind_03\"]))))))\n",
    "    v[\"71\"] = 0.020000*np.tanh((data[\"loo_ps_ind_17_bin\"] + (data[\"missing\"] + ((8.37885093688964844) * (data[\"loo_ps_ind_17_bin\"] + data[\"loo_ps_ind_02_cat\"])))))\n",
    "    v[\"72\"] = 0.020000*np.tanh((data[\"loo_ps_car_09_cat\"] + (data[\"ps_reg_03\"] + (1.480000 * (data[\"loo_ps_car_04_cat\"] * data[\"ps_ind_01\"])))))\n",
    "    v[\"73\"] = 0.020000*np.tanh(((((5.0) * data[\"loo_ps_ind_05_cat\"]) + data[\"loo_ps_car_09_cat\"]) * (data[\"loo_ps_ind_17_bin\"] + data[\"ps_reg_03\"])))\n",
    "    v[\"74\"] = 0.020000*np.tanh(((((data[\"loo_ps_ind_07_bin\"] + data[\"loo_ps_car_01_cat\"])/2.0) * data[\"loo_ps_ind_16_bin\"]) + (data[\"ps_ind_15\"] * data[\"loo_ps_ind_18_bin\"])))\n",
    "    v[\"75\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_05_cat\"] * data[\"loo_ps_car_01_cat\"]) + data[\"loo_ps_car_05_cat\"]) * (data[\"loo_ps_ind_05_cat\"] - data[\"ps_ind_15\"])))\n",
    "    v[\"76\"] = 0.020000*np.tanh((data[\"loo_ps_ind_16_bin\"] * ((data[\"loo_ps_car_04_cat\"] + data[\"loo_ps_ind_05_cat\"]) + (data[\"loo_ps_car_07_cat\"] + data[\"ps_ind_03\"]))))\n",
    "    v[\"77\"] = 0.020000*np.tanh(((data[\"loo_ps_car_05_cat\"] + data[\"loo_ps_car_03_cat\"]) * (data[\"ps_ind_03\"] + (data[\"missing\"] + data[\"loo_ps_ind_05_cat\"]))))\n",
    "    v[\"78\"] = 0.020000*np.tanh(((data[\"ps_ind_01\"] * data[\"loo_ps_car_03_cat\"]) + (data[\"loo_ps_car_08_cat\"] + (data[\"loo_ps_ind_17_bin\"] * data[\"loo_ps_car_03_cat\"]))))\n",
    "    v[\"79\"] = 0.020000*np.tanh((data[\"ps_ind_03\"] * (3.0 * (3.0 * (-(data[\"loo_ps_ind_02_cat\"]))))))\n",
    "    v[\"80\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_05_cat\"] + data[\"loo_ps_ind_05_cat\"]) * (data[\"loo_ps_car_09_cat\"] + data[\"ps_reg_03\"])) - data[\"loo_ps_ind_16_bin\"]))\n",
    "    v[\"81\"] = 0.020000*np.tanh((data[\"loo_ps_car_03_cat\"] * ((data[\"loo_ps_ind_09_bin\"] - data[\"ps_car_15\"]) + (data[\"loo_ps_ind_02_cat\"] - data[\"loo_ps_ind_18_bin\"]))))\n",
    "    v[\"82\"] = 0.020000*np.tanh((((data[\"ps_ind_01\"] + data[\"loo_ps_ind_06_bin\"]) * (data[\"loo_ps_ind_16_bin\"] - data[\"ps_reg_01\"])) + data[\"loo_ps_car_07_cat\"]))\n",
    "    v[\"83\"] = 0.020000*np.tanh((data[\"ps_ind_15\"] * (data[\"loo_ps_ind_16_bin\"] - ((data[\"loo_ps_car_11_cat\"] + data[\"missing\"]) + data[\"loo_ps_ind_17_bin\"]))))\n",
    "    v[\"84\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_07_bin\"] + data[\"loo_ps_ind_02_cat\"])/2.0) + (data[\"ps_ind_01\"] * (0.600000 - data[\"ps_ind_15\"]))))\n",
    "    v[\"85\"] = 0.020000*np.tanh(((data[\"ps_ind_01\"] + data[\"loo_ps_car_04_cat\"]) * ((data[\"loo_ps_ind_05_cat\"] - data[\"ps_ind_15\"]) + -1.0)))\n",
    "    v[\"86\"] = 0.020000*np.tanh((data[\"loo_ps_ind_04_cat\"] + (data[\"ps_reg_03\"] + (data[\"ps_reg_03\"] + (data[\"loo_ps_ind_17_bin\"] * data[\"loo_ps_car_07_cat\"])))))\n",
    "    v[\"87\"] = 0.020000*np.tanh((data[\"loo_ps_ind_05_cat\"] * ((((4.0) * data[\"loo_ps_ind_17_bin\"]) + data[\"loo_ps_car_06_cat\"]) - data[\"ps_reg_01\"])))\n",
    "    v[\"88\"] = 0.020000*np.tanh(((-1.0 + data[\"loo_ps_ind_12_bin\"]) - (data[\"loo_ps_car_10_cat\"] + (data[\"ps_car_11\"] - data[\"loo_ps_car_09_cat\"]))))\n",
    "    v[\"89\"] = 0.020000*np.tanh((data[\"loo_ps_ind_05_cat\"] * ((data[\"loo_ps_car_09_cat\"] + ((-1.0 + data[\"ps_reg_03\"])/2.0)) + data[\"ps_reg_03\"])))\n",
    "    v[\"90\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_09_bin\"] + data[\"loo_ps_ind_05_cat\"]) * ((data[\"loo_ps_ind_05_cat\"] + data[\"loo_ps_ind_17_bin\"])/2.0)) - data[\"loo_ps_ind_05_cat\"]))\n",
    "    v[\"91\"] = 0.020000*np.tanh((-(((data[\"loo_ps_ind_02_cat\"] + data[\"loo_ps_ind_02_cat\"]) * (data[\"ps_ind_03\"] + data[\"loo_ps_ind_06_bin\"])))))\n",
    "    v[\"92\"] = 0.020000*np.tanh((data[\"loo_ps_ind_04_cat\"] + (data[\"ps_reg_03\"] * ((-(data[\"ps_reg_01\"])) + data[\"loo_ps_ind_17_bin\"]))))\n",
    "    v[\"93\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_02_cat\"] * 29.500000) * (data[\"loo_ps_car_08_cat\"] + (data[\"loo_ps_car_08_cat\"] - data[\"ps_ind_03\"]))))\n",
    "    v[\"94\"] = 0.020000*np.tanh((((data[\"loo_ps_car_03_cat\"] * data[\"loo_ps_car_09_cat\"]) * (data[\"loo_ps_car_04_cat\"] * data[\"loo_ps_car_04_cat\"])) - data[\"loo_ps_car_04_cat\"]))\n",
    "    v[\"95\"] = 0.020000*np.tanh(((data[\"loo_ps_car_07_cat\"] + -1.0) - (data[\"ps_car_12\"] * (2.0 * data[\"ps_car_11\"]))))\n",
    "    v[\"96\"] = 0.020000*np.tanh((-((data[\"ps_reg_03\"] * ((data[\"loo_ps_car_01_cat\"] - data[\"loo_ps_car_03_cat\"]) + data[\"loo_ps_ind_08_bin\"])))))\n",
    "    v[\"97\"] = 0.020000*np.tanh((data[\"loo_ps_ind_16_bin\"] * (data[\"loo_ps_car_07_cat\"] + (((data[\"loo_ps_ind_07_bin\"] + data[\"ps_car_12\"])/2.0) - data[\"ps_reg_01\"]))))\n",
    "    v[\"98\"] = 0.020000*np.tanh(((((data[\"loo_ps_ind_07_bin\"] + data[\"ps_ind_15\"])/2.0) + data[\"loo_ps_ind_17_bin\"]) * (data[\"loo_ps_ind_05_cat\"] + data[\"loo_ps_ind_05_cat\"])))\n",
    "    v[\"99\"] = 0.019992*np.tanh(((data[\"loo_ps_ind_05_cat\"] * data[\"loo_ps_car_09_cat\"]) + (-((data[\"ps_reg_01\"] * data[\"ps_ind_03\"])))))\n",
    "    v[\"100\"] = 0.019988*np.tanh((data[\"loo_ps_ind_04_cat\"] + (data[\"loo_ps_car_05_cat\"] * (data[\"ps_ind_01\"] + (data[\"ps_ind_01\"] + data[\"loo_ps_car_01_cat\"])))))\n",
    "    v[\"101\"] = 0.020000*np.tanh((data[\"loo_ps_ind_05_cat\"] * (data[\"loo_ps_ind_05_cat\"] * np.tanh((data[\"loo_ps_ind_05_cat\"] + (-(2.352940)))))))\n",
    "    v[\"102\"] = 0.020000*np.tanh((-((data[\"ps_reg_01\"] * (data[\"loo_ps_car_09_cat\"] + (data[\"ps_reg_03\"] + data[\"loo_ps_ind_05_cat\"]))))))\n",
    "    v[\"103\"] = 0.020000*np.tanh(((-1.0 + (data[\"loo_ps_car_09_cat\"] + ((data[\"ps_reg_01\"] * data[\"ps_reg_01\"]) + data[\"ps_reg_01\"])))/2.0))\n",
    "    v[\"104\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_17_bin\"] + ((data[\"loo_ps_ind_02_cat\"] + -2.0)/2.0)) * (data[\"loo_ps_ind_05_cat\"] - data[\"ps_car_15\"])))\n",
    "    v[\"105\"] = 0.019992*np.tanh((((data[\"loo_ps_ind_17_bin\"] + data[\"loo_ps_car_07_cat\"]) + data[\"loo_ps_ind_17_bin\"]) * ((data[\"ps_reg_02\"] + data[\"loo_ps_car_09_cat\"])/2.0)))\n",
    "    v[\"106\"] = 0.020000*np.tanh((data[\"loo_ps_ind_05_cat\"] * (data[\"loo_ps_ind_07_bin\"] + (data[\"loo_ps_ind_07_bin\"] + (data[\"loo_ps_car_09_cat\"] + -1.0)))))\n",
    "    v[\"107\"] = 0.020000*np.tanh(((data[\"ps_car_15\"] + (data[\"loo_ps_ind_07_bin\"] * data[\"loo_ps_ind_17_bin\"])) - (data[\"ps_reg_03\"] * data[\"loo_ps_car_01_cat\"])))\n",
    "    v[\"108\"] = 0.020000*np.tanh((data[\"loo_ps_ind_04_cat\"] * ((data[\"loo_ps_ind_04_cat\"] - (data[\"loo_ps_ind_06_bin\"] - 0.432099)) - data[\"loo_ps_car_01_cat\"])))\n",
    "    v[\"109\"] = 0.019988*np.tanh((data[\"loo_ps_ind_02_cat\"] - (data[\"ps_ind_01\"] * (-2.0 + (data[\"ps_ind_01\"] * data[\"ps_ind_01\"])))))\n",
    "    v[\"110\"] = 0.020000*np.tanh(((29.500000 + (data[\"ps_car_15\"] * 29.500000)) * (0.791667 - data[\"ps_car_15\"])))\n",
    "    v[\"111\"] = 0.020000*np.tanh(((((data[\"loo_ps_ind_04_cat\"] + -1.0) + data[\"loo_ps_car_08_cat\"])/2.0) + (data[\"loo_ps_ind_05_cat\"] * data[\"ps_reg_03\"])))\n",
    "    v[\"112\"] = 0.020000*np.tanh((data[\"loo_ps_car_01_cat\"] * ((data[\"ps_reg_03\"] * ((data[\"loo_ps_car_05_cat\"] + data[\"ps_reg_03\"])/2.0)) - data[\"ps_car_15\"])))\n",
    "    v[\"113\"] = 0.020000*np.tanh((data[\"ps_reg_02\"] * ((data[\"loo_ps_ind_17_bin\"] - data[\"loo_ps_car_01_cat\"]) - (data[\"ps_ind_01\"] - data[\"loo_ps_ind_17_bin\"]))))\n",
    "    v[\"114\"] = 0.020000*np.tanh((data[\"ps_ind_03\"] * (data[\"ps_reg_03\"] - (1.480000 + (data[\"ps_ind_15\"] - data[\"ps_reg_03\"])))))\n",
    "    v[\"115\"] = 0.019988*np.tanh(((((data[\"loo_ps_car_01_cat\"] + (data[\"ps_car_11\"] * data[\"ps_car_11\"]))/2.0) + (data[\"ps_reg_01\"] * data[\"missing\"]))/2.0))\n",
    "    v[\"116\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_04_cat\"] * ((data[\"loo_ps_ind_04_cat\"] - data[\"ps_ind_01\"]) + data[\"ps_ind_03\"])) - data[\"loo_ps_ind_02_cat\"]))\n",
    "    v[\"117\"] = 0.020000*np.tanh((data[\"loo_ps_car_04_cat\"] * ((data[\"loo_ps_car_09_cat\"] - data[\"ps_car_11\"]) - ((data[\"loo_ps_car_06_cat\"] + data[\"loo_ps_car_04_cat\"])/2.0))))\n",
    "    v[\"118\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_04_cat\"] + data[\"ps_ind_03\"])/2.0) * ((data[\"loo_ps_car_02_cat\"] - data[\"ps_reg_01\"]) + data[\"loo_ps_car_07_cat\"])))\n",
    "    v[\"119\"] = 0.020000*np.tanh(((((data[\"ps_car_15\"] * (-(data[\"loo_ps_car_03_cat\"]))) + data[\"loo_ps_car_01_cat\"])/2.0) - data[\"loo_ps_car_07_cat\"]))\n",
    "    v[\"120\"] = 0.020000*np.tanh((data[\"loo_ps_ind_05_cat\"] * ((data[\"loo_ps_ind_05_cat\"] * (data[\"loo_ps_car_03_cat\"] * data[\"loo_ps_car_11_cat\"])) - 0.633333)))\n",
    "    v[\"121\"] = 0.020000*np.tanh(((((data[\"loo_ps_ind_05_cat\"] + data[\"ps_car_12\"]) + data[\"loo_ps_ind_18_bin\"])/2.0) * ((data[\"missing\"] + data[\"ps_reg_02\"])/2.0)))\n",
    "    v[\"122\"] = 0.020000*np.tanh(((((data[\"ps_ind_03\"] + data[\"loo_ps_ind_04_cat\"])/2.0) * ((data[\"ps_ind_03\"] + data[\"loo_ps_ind_04_cat\"])/2.0)) - 0.432099))\n",
    "    v[\"123\"] = 0.020000*np.tanh(((data[\"ps_reg_03\"] * data[\"ps_reg_03\"]) * (((data[\"loo_ps_ind_05_cat\"] - data[\"ps_reg_03\"]) + data[\"ps_car_12\"])/2.0)))\n",
    "    v[\"124\"] = 0.020000*np.tanh((data[\"loo_ps_ind_02_cat\"] * (data[\"ps_car_13\"] + ((data[\"loo_ps_car_04_cat\"] - data[\"ps_ind_03\"]) - 1.089890))))\n",
    "    v[\"125\"] = 0.020000*np.tanh((((data[\"loo_ps_car_09_cat\"] + -2.0)/2.0) * (data[\"loo_ps_ind_02_cat\"] + (data[\"ps_car_11\"] * data[\"ps_ind_01\"]))))\n",
    "    v[\"126\"] = 0.019988*np.tanh(((data[\"loo_ps_ind_02_cat\"] + ((data[\"loo_ps_car_07_cat\"] * data[\"loo_ps_ind_08_bin\"]) - (data[\"ps_ind_15\"] * data[\"loo_ps_car_06_cat\"])))/2.0))\n",
    "    v[\"127\"] = 0.020000*np.tanh((data[\"loo_ps_car_09_cat\"] * (data[\"loo_ps_car_09_cat\"] * np.tanh(((data[\"loo_ps_ind_07_bin\"] + (-(data[\"ps_ind_03\"])))/2.0)))))\n",
    "    v[\"128\"] = 0.020000*np.tanh((((data[\"missing\"] - data[\"ps_car_11\"]) * (data[\"loo_ps_car_01_cat\"] - data[\"loo_ps_car_06_cat\"])) - data[\"loo_ps_car_11_cat\"]))\n",
    "    v[\"129\"] = 0.020000*np.tanh((data[\"ps_reg_01\"] * (-((np.tanh((data[\"ps_reg_03\"] + data[\"loo_ps_ind_05_cat\"])) + data[\"loo_ps_ind_18_bin\"])))))\n",
    "    v[\"130\"] = 0.020000*np.tanh((data[\"loo_ps_ind_02_cat\"] * ((data[\"missing\"] + data[\"ps_car_11\"]) + data[\"ps_ind_15\"])))\n",
    "    v[\"131\"] = 0.019996*np.tanh((((data[\"loo_ps_ind_02_cat\"] - data[\"loo_ps_car_04_cat\"]) + ((data[\"loo_ps_ind_07_bin\"] * data[\"ps_car_13\"]) * data[\"ps_reg_03\"]))/2.0))\n",
    "    v[\"132\"] = 0.020000*np.tanh((data[\"ps_reg_01\"] - (0.791667 - (((data[\"loo_ps_car_11_cat\"] * data[\"loo_ps_car_11_cat\"]) + data[\"loo_ps_ind_02_cat\"])/2.0))))\n",
    "    v[\"133\"] = 0.020000*np.tanh(((data[\"ps_ind_14\"] + ((data[\"loo_ps_ind_04_cat\"] + data[\"ps_ind_15\"])/2.0)) * ((data[\"ps_ind_15\"] + data[\"loo_ps_ind_04_cat\"])/2.0)))\n",
    "    v[\"134\"] = 0.020000*np.tanh(((0.791667 - data[\"ps_ind_01\"]) * (((data[\"ps_ind_03\"] + data[\"loo_ps_ind_04_cat\"])/2.0) * data[\"loo_ps_ind_05_cat\"])))\n",
    "    v[\"135\"] = 0.019992*np.tanh(((-2.0 + (data[\"ps_car_12\"] * ((data[\"ps_car_12\"] - 1.089890) + data[\"loo_ps_ind_04_cat\"])))/2.0))\n",
    "    v[\"136\"] = 0.019977*np.tanh(((data[\"loo_ps_car_09_cat\"] * (data[\"loo_ps_car_01_cat\"] * (data[\"loo_ps_ind_02_cat\"] + data[\"loo_ps_ind_17_bin\"]))) - data[\"loo_ps_ind_02_cat\"]))\n",
    "    v[\"137\"] = 0.019996*np.tanh(((-1.0 + ((data[\"ps_reg_03\"] * data[\"ps_reg_03\"]) * data[\"loo_ps_ind_05_cat\"])) * data[\"loo_ps_ind_05_cat\"]))\n",
    "    v[\"138\"] = 0.020000*np.tanh((((data[\"ps_car_11\"] * (data[\"ps_ind_14\"] - data[\"ps_car_12\"])) + data[\"loo_ps_car_09_cat\"])/2.0))\n",
    "    v[\"139\"] = 0.019996*np.tanh((data[\"loo_ps_car_07_cat\"] * ((((data[\"missing\"] * data[\"missing\"]) + data[\"ps_ind_15\"])/2.0) + data[\"loo_ps_ind_17_bin\"])))\n",
    "    v[\"140\"] = 0.020000*np.tanh((data[\"ps_reg_01\"] * ((data[\"ps_reg_01\"] - data[\"ps_reg_03\"]) - data[\"loo_ps_ind_17_bin\"])))\n",
    "    v[\"141\"] = 0.019996*np.tanh(((data[\"loo_ps_ind_04_cat\"] - ((data[\"ps_car_13\"] + (data[\"loo_ps_ind_05_cat\"] * data[\"loo_ps_ind_05_cat\"]))/2.0)) * data[\"loo_ps_car_07_cat\"]))\n",
    "    v[\"142\"] = 0.020000*np.tanh(((data[\"ps_ind_15\"] + (((data[\"ps_reg_03\"] * data[\"ps_reg_03\"]) - 0.432099) + data[\"loo_ps_ind_16_bin\"]))/2.0))\n",
    "    v[\"143\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_04_cat\"] + (data[\"loo_ps_ind_08_bin\"] - (data[\"loo_ps_car_04_cat\"] + (data[\"loo_ps_ind_08_bin\"] * data[\"ps_car_13\"]))))/2.0))\n",
    "    v[\"144\"] = 0.019996*np.tanh(((((-1.0 - data[\"ps_ind_03\"]) - data[\"ps_ind_03\"]) * data[\"loo_ps_ind_02_cat\"]) - 0.432099))\n",
    "    v[\"145\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_02_cat\"] * (data[\"loo_ps_ind_02_cat\"] - 0.788462)) * data[\"loo_ps_ind_02_cat\"]) - data[\"loo_ps_car_10_cat\"]))\n",
    "    v[\"146\"] = 0.020000*np.tanh((data[\"loo_ps_ind_04_cat\"] * ((data[\"loo_ps_ind_04_cat\"] + data[\"ps_ind_03\"]) * (0.791667 - data[\"ps_ind_03\"]))))\n",
    "    v[\"147\"] = 0.020000*np.tanh((np.tanh(data[\"loo_ps_ind_05_cat\"]) * (((-(data[\"loo_ps_ind_18_bin\"])) + (data[\"ps_car_14\"] + data[\"missing\"]))/2.0)))\n",
    "    v[\"148\"] = 0.020000*np.tanh((data[\"ps_reg_03\"] * (((data[\"loo_ps_ind_09_bin\"] - data[\"loo_ps_ind_18_bin\"]) - data[\"ps_car_15\"]) - data[\"loo_ps_ind_02_cat\"])))\n",
    "    v[\"149\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_04_cat\"] + (data[\"ps_ind_15\"] * (-((data[\"loo_ps_ind_17_bin\"] - data[\"ps_ind_14\"])))))/2.0))\n",
    "    v[\"150\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_04_cat\"] * data[\"loo_ps_car_03_cat\"]) + (-(((data[\"loo_ps_car_01_cat\"] + data[\"loo_ps_car_10_cat\"])/2.0))))/2.0))\n",
    "    v[\"151\"] = 0.020000*np.tanh(((0.666667 - data[\"ps_ind_03\"]) * ((data[\"loo_ps_car_07_cat\"] + (data[\"ps_reg_01\"] + data[\"ps_ind_15\"]))/2.0)))\n",
    "    v[\"152\"] = 0.020000*np.tanh(((data[\"loo_ps_car_03_cat\"] * data[\"loo_ps_ind_05_cat\"]) * ((data[\"loo_ps_car_06_cat\"] + ((-1.0 + data[\"loo_ps_ind_04_cat\"])/2.0))/2.0)))\n",
    "    v[\"153\"] = 0.020000*np.tanh(((data[\"ps_ind_03\"] * data[\"ps_ind_03\"]) * (-2.0 + (data[\"ps_ind_03\"] * data[\"ps_ind_03\"]))))\n",
    "    v[\"154\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_13_bin\"] - data[\"loo_ps_ind_11_bin\"]) * ((data[\"loo_ps_ind_02_cat\"] + (7.0)) * 29.500000)))\n",
    "    v[\"155\"] = 0.019977*np.tanh((((data[\"loo_ps_ind_02_cat\"] + data[\"loo_ps_car_08_cat\"]) * (data[\"loo_ps_ind_02_cat\"] * 2.0)) - 1.089890))\n",
    "    v[\"156\"] = 0.020000*np.tanh(((data[\"ps_car_12\"] + (data[\"loo_ps_ind_16_bin\"] * ((-(data[\"ps_reg_01\"])) * data[\"loo_ps_car_05_cat\"])))/2.0))\n",
    "    v[\"157\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_04_cat\"] - data[\"loo_ps_ind_05_cat\"]) + (data[\"loo_ps_ind_05_cat\"] * data[\"ps_ind_15\"]))/2.0))\n",
    "    v[\"158\"] = 0.020000*np.tanh(((data[\"loo_ps_car_01_cat\"] * (((data[\"loo_ps_car_02_cat\"] + data[\"loo_ps_ind_17_bin\"])/2.0) * data[\"loo_ps_ind_02_cat\"])) * data[\"loo_ps_car_07_cat\"]))\n",
    "    v[\"159\"] = 0.020000*np.tanh((data[\"loo_ps_ind_02_cat\"] * (((data[\"loo_ps_ind_05_cat\"] * data[\"loo_ps_ind_16_bin\"]) + -3.0) * data[\"loo_ps_ind_04_cat\"])))\n",
    "    v[\"160\"] = 0.020000*np.tanh((data[\"loo_ps_car_05_cat\"] * ((data[\"loo_ps_ind_02_cat\"] + (-((data[\"loo_ps_car_06_cat\"] * data[\"loo_ps_car_02_cat\"]))))/2.0)))\n",
    "    v[\"161\"] = 0.019961*np.tanh((-((data[\"loo_ps_car_03_cat\"] * (0.753247 - (data[\"ps_ind_01\"] * data[\"ps_ind_01\"]))))))\n",
    "    v[\"162\"] = 0.020000*np.tanh(((data[\"ps_car_13\"] + data[\"loo_ps_ind_17_bin\"]) * ((data[\"ps_ind_03\"] + (data[\"ps_ind_03\"] + data[\"loo_ps_car_07_cat\"]))/2.0)))\n",
    "    v[\"163\"] = 0.019988*np.tanh(((data[\"ps_ind_01\"] + ((data[\"loo_ps_ind_09_bin\"] + ((data[\"ps_ind_01\"] + data[\"missing\"])/2.0))/2.0)) * data[\"missing\"]))\n",
    "    v[\"164\"] = 0.019988*np.tanh((data[\"ps_reg_03\"] * (-(((((data[\"loo_ps_ind_02_cat\"] + (-(data[\"ps_reg_03\"])))/2.0) + data[\"ps_reg_01\"])/2.0)))))\n",
    "    v[\"165\"] = 0.020000*np.tanh(((1.480000 + (data[\"loo_ps_ind_11_bin\"] * 29.500000)) * 29.500000))\n",
    "    v[\"166\"] = 0.020000*np.tanh((data[\"loo_ps_ind_04_cat\"] - ((2.0 + data[\"ps_car_11\"]) * (2.352940 * 2.352940))))\n",
    "    v[\"167\"] = 0.020000*np.tanh(((data[\"ps_car_11\"] + (((-(data[\"loo_ps_car_04_cat\"])) + ((data[\"loo_ps_ind_04_cat\"] + data[\"loo_ps_car_02_cat\"])/2.0))/2.0))/2.0))\n",
    "    v[\"168\"] = 0.019996*np.tanh((((data[\"loo_ps_car_09_cat\"] * (-(data[\"ps_reg_01\"]))) + (data[\"ps_reg_01\"] - data[\"ps_ind_03\"]))/2.0))\n",
    "    v[\"169\"] = 0.019996*np.tanh((data[\"loo_ps_car_09_cat\"] * ((data[\"loo_ps_car_09_cat\"] * data[\"loo_ps_ind_17_bin\"]) - (0.791667 - data[\"ps_reg_02\"]))))\n",
    "    v[\"170\"] = 0.019992*np.tanh(((data[\"ps_car_15\"] * (data[\"loo_ps_ind_06_bin\"] - data[\"ps_ind_03\"])) * data[\"loo_ps_car_04_cat\"]))\n",
    "    v[\"171\"] = 0.020000*np.tanh(((-(data[\"ps_reg_03\"])) * (data[\"missing\"] + ((data[\"loo_ps_car_03_cat\"] + data[\"ps_car_14\"])/2.0))))\n",
    "    v[\"172\"] = 0.019996*np.tanh((data[\"ps_ind_01\"] * ((data[\"loo_ps_ind_05_cat\"] * ((data[\"loo_ps_ind_02_cat\"] + data[\"ps_ind_01\"])/2.0)) - data[\"loo_ps_ind_04_cat\"])))\n",
    "    v[\"173\"] = 0.019953*np.tanh(((data[\"ps_reg_01\"] * (-(((data[\"loo_ps_ind_06_bin\"] + np.tanh(data[\"loo_ps_ind_17_bin\"]))/2.0)))) - data[\"loo_ps_car_10_cat\"]))\n",
    "    v[\"174\"] = 0.020000*np.tanh((data[\"loo_ps_ind_02_cat\"] * (((data[\"loo_ps_ind_02_cat\"] * data[\"loo_ps_ind_02_cat\"]) - 0.887097) + data[\"ps_ind_01\"])))\n",
    "    v[\"175\"] = 0.020000*np.tanh((((data[\"ps_reg_01\"] + (data[\"loo_ps_car_01_cat\"] * 0.117647))/2.0) * (data[\"loo_ps_car_01_cat\"] * data[\"loo_ps_car_01_cat\"])))\n",
    "    v[\"176\"] = 0.019988*np.tanh((((data[\"loo_ps_ind_04_cat\"] * np.tanh(data[\"loo_ps_ind_17_bin\"])) + np.tanh((-3.0 + data[\"ps_car_13\"])))/2.0))\n",
    "    v[\"177\"] = 0.020000*np.tanh((1.089890 + ((11.83836174011230469) * ((0.666667 * 1.089890) - data[\"ps_car_15\"]))))\n",
    "    v[\"178\"] = 0.019996*np.tanh(((-1.0 + (data[\"loo_ps_ind_17_bin\"] * ((data[\"loo_ps_ind_09_bin\"] + ((data[\"loo_ps_ind_04_cat\"] + -3.0)/2.0))/2.0)))/2.0))\n",
    "    v[\"179\"] = 0.020000*np.tanh((data[\"loo_ps_car_03_cat\"] * (data[\"loo_ps_car_04_cat\"] * (data[\"loo_ps_ind_04_cat\"] - np.tanh(data[\"ps_car_15\"])))))\n",
    "    v[\"180\"] = 0.019887*np.tanh((data[\"loo_ps_car_08_cat\"] + (data[\"ps_ind_03\"] * (data[\"loo_ps_car_02_cat\"] * data[\"ps_ind_01\"]))))\n",
    "    v[\"181\"] = 0.020000*np.tanh(((((data[\"ps_reg_01\"] + (-(data[\"ps_car_13\"])))/2.0) * data[\"ps_ind_15\"]) * data[\"loo_ps_car_01_cat\"]))\n",
    "    v[\"182\"] = 0.020000*np.tanh((data[\"ps_reg_01\"] * (data[\"loo_ps_ind_07_bin\"] * (((data[\"loo_ps_ind_02_cat\"] + data[\"loo_ps_car_08_cat\"])/2.0) - data[\"ps_reg_03\"]))))\n",
    "    v[\"183\"] = 0.020000*np.tanh((((data[\"ps_ind_14\"] + (data[\"loo_ps_ind_04_cat\"] * data[\"loo_ps_ind_17_bin\"]))/2.0) * (data[\"loo_ps_car_01_cat\"] * data[\"loo_ps_ind_04_cat\"])))\n",
    "    v[\"184\"] = 0.020000*np.tanh((data[\"loo_ps_ind_17_bin\"] * ((data[\"loo_ps_ind_02_cat\"] + (data[\"ps_ind_15\"] * (-(data[\"ps_car_15\"]))))/2.0)))\n",
    "    v[\"185\"] = 0.019973*np.tanh((data[\"loo_ps_ind_17_bin\"] * ((data[\"loo_ps_car_01_cat\"] - data[\"ps_ind_14\"]) * (data[\"ps_car_11\"] + data[\"loo_ps_car_09_cat\"]))))\n",
    "    v[\"186\"] = 0.019918*np.tanh((data[\"loo_ps_ind_02_cat\"] * (((data[\"loo_ps_ind_02_cat\"] * data[\"loo_ps_ind_02_cat\"]) - 0.666667) + data[\"loo_ps_ind_18_bin\"])))\n",
    "    v[\"187\"] = 0.020000*np.tanh((data[\"loo_ps_ind_02_cat\"] * (data[\"loo_ps_ind_04_cat\"] * (data[\"ps_car_13\"] + (data[\"loo_ps_car_04_cat\"] + data[\"ps_car_12\"])))))\n",
    "    v[\"188\"] = 0.020000*np.tanh((data[\"loo_ps_car_07_cat\"] * (data[\"loo_ps_ind_05_cat\"] * (data[\"ps_car_13\"] + data[\"ps_car_13\"]))))\n",
    "    v[\"189\"] = 0.019992*np.tanh((data[\"ps_car_13\"] * (data[\"loo_ps_car_01_cat\"] * (data[\"ps_car_13\"] - 2.0))))\n",
    "    v[\"190\"] = 0.020000*np.tanh((data[\"loo_ps_ind_04_cat\"] * (data[\"loo_ps_ind_05_cat\"] * (-(data[\"ps_reg_02\"])))))\n",
    "    v[\"191\"] = 0.020000*np.tanh((data[\"loo_ps_car_07_cat\"] * (((data[\"loo_ps_ind_02_cat\"] * 0.432099) * data[\"loo_ps_car_07_cat\"]) - data[\"loo_ps_car_02_cat\"])))\n",
    "    v[\"192\"] = 0.020000*np.tanh((data[\"ps_reg_01\"] * (data[\"loo_ps_car_07_cat\"] * (-((data[\"loo_ps_ind_02_cat\"] + data[\"loo_ps_ind_18_bin\"]))))))\n",
    "    v[\"193\"] = 0.020000*np.tanh((data[\"loo_ps_ind_04_cat\"] * (data[\"loo_ps_car_08_cat\"] * (data[\"ps_reg_03\"] - ((data[\"ps_ind_03\"] + data[\"ps_ind_03\"])/2.0)))))\n",
    "    v[\"194\"] = 0.019996*np.tanh(((data[\"ps_ind_03\"] - ((0.600000 + data[\"loo_ps_ind_08_bin\"])/2.0)) * ((data[\"ps_ind_14\"] + data[\"loo_ps_ind_08_bin\"])/2.0)))\n",
    "    v[\"195\"] = 0.019992*np.tanh(((data[\"loo_ps_car_11_cat\"] * data[\"loo_ps_car_04_cat\"]) * (((data[\"ps_ind_01\"] + data[\"ps_ind_01\"]) + data[\"loo_ps_ind_06_bin\"])/2.0)))\n",
    "    v[\"196\"] = 0.019996*np.tanh(((data[\"loo_ps_car_04_cat\"] - ((data[\"ps_ind_01\"] + data[\"loo_ps_ind_02_cat\"])/2.0)) * (data[\"loo_ps_ind_02_cat\"] * data[\"ps_ind_03\"])))\n",
    "    v[\"197\"] = 0.020000*np.tanh((data[\"loo_ps_ind_05_cat\"] * (data[\"ps_car_11\"] * ((data[\"ps_reg_02\"] - data[\"loo_ps_car_01_cat\"]) - data[\"loo_ps_car_03_cat\"]))))\n",
    "    v[\"198\"] = 0.020000*np.tanh((data[\"ps_reg_03\"] * ((((data[\"loo_ps_car_04_cat\"] * data[\"loo_ps_car_08_cat\"]) + data[\"loo_ps_ind_02_cat\"])/2.0) * data[\"loo_ps_car_08_cat\"])))\n",
    "    v[\"199\"] = 0.020000*np.tanh((((data[\"ps_car_11\"] + data[\"loo_ps_car_04_cat\"])/2.0) * ((data[\"loo_ps_car_04_cat\"] * data[\"loo_ps_ind_02_cat\"]) - data[\"loo_ps_car_04_cat\"])))\n",
    "    v[\"200\"] = 0.019992*np.tanh((((data[\"ps_car_13\"] * data[\"ps_ind_14\"]) * data[\"ps_ind_15\"]) * (data[\"ps_car_13\"] * data[\"ps_car_13\"])))\n",
    "    v[\"201\"] = 0.019644*np.tanh((data[\"ps_ind_15\"] * (data[\"ps_reg_03\"] + ((data[\"ps_ind_15\"] * data[\"loo_ps_car_08_cat\"]) + data[\"ps_reg_03\"]))))\n",
    "    v[\"202\"] = 0.020000*np.tanh(((-((data[\"ps_reg_02\"] * ((data[\"loo_ps_car_08_cat\"] + data[\"ps_ind_15\"])/2.0)))) * data[\"ps_ind_03\"]))\n",
    "    v[\"203\"] = 0.020000*np.tanh((0.666667 - (data[\"ps_car_15\"] * (((data[\"loo_ps_car_08_cat\"] + data[\"loo_ps_car_10_cat\"]) + data[\"loo_ps_car_03_cat\"])/2.0))))\n",
    "    v[\"204\"] = 0.020000*np.tanh(((data[\"loo_ps_car_09_cat\"] * np.tanh(data[\"loo_ps_car_02_cat\"])) + (data[\"loo_ps_car_09_cat\"] * data[\"loo_ps_car_11_cat\"])))\n",
    "    v[\"205\"] = 0.020000*np.tanh((data[\"loo_ps_car_09_cat\"] * (data[\"loo_ps_ind_08_bin\"] - ((data[\"loo_ps_ind_18_bin\"] * data[\"ps_reg_01\"]) * data[\"ps_reg_01\"]))))\n",
    "    v[\"206\"] = 0.019980*np.tanh((data[\"loo_ps_ind_04_cat\"] * ((data[\"loo_ps_car_01_cat\"] - (data[\"loo_ps_ind_17_bin\"] * data[\"loo_ps_car_01_cat\"])) * data[\"ps_reg_02\"])))\n",
    "    v[\"207\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_08_bin\"] * (data[\"ps_ind_15\"] + data[\"loo_ps_car_01_cat\"])) - data[\"loo_ps_car_10_cat\"]) - data[\"loo_ps_car_10_cat\"]))\n",
    "    v[\"208\"] = 0.020000*np.tanh((0.148148 * (data[\"loo_ps_ind_02_cat\"] * (-((np.tanh(data[\"loo_ps_ind_18_bin\"]) * data[\"loo_ps_ind_16_bin\"]))))))\n",
    "    v[\"209\"] = 0.020000*np.tanh((((data[\"ps_car_15\"] + data[\"loo_ps_ind_04_cat\"])/2.0) * (data[\"ps_car_12\"] * ((data[\"loo_ps_ind_16_bin\"] + data[\"ps_car_12\"])/2.0))))\n",
    "    v[\"210\"] = 0.020000*np.tanh((data[\"loo_ps_car_11_cat\"] * (data[\"loo_ps_ind_17_bin\"] * ((data[\"loo_ps_ind_02_cat\"] + (-(data[\"loo_ps_car_07_cat\"])))/2.0))))\n",
    "    v[\"211\"] = 0.020000*np.tanh(((data[\"ps_ind_03\"] * ((data[\"loo_ps_ind_05_cat\"] + (data[\"loo_ps_ind_02_cat\"] * data[\"ps_ind_03\"]))/2.0)) - data[\"loo_ps_ind_02_cat\"]))\n",
    "    v[\"212\"] = 0.019711*np.tanh(((((data[\"loo_ps_ind_09_bin\"] * data[\"loo_ps_car_03_cat\"]) + (data[\"loo_ps_ind_09_bin\"] * data[\"loo_ps_car_07_cat\"]))/2.0) - 0.232323))\n",
    "    v[\"213\"] = 0.020000*np.tanh((data[\"ps_ind_03\"] * (0.633333 - ((data[\"ps_ind_01\"] + data[\"loo_ps_ind_02_cat\"]) * data[\"ps_ind_01\"]))))\n",
    "    v[\"214\"] = 0.020000*np.tanh((data[\"loo_ps_ind_12_bin\"] * (data[\"loo_ps_ind_11_bin\"] + ((data[\"ps_ind_15\"] + data[\"ps_reg_03\"]) + data[\"ps_reg_03\"]))))\n",
    "    v[\"215\"] = 0.020000*np.tanh((data[\"loo_ps_ind_16_bin\"] * ((data[\"loo_ps_car_08_cat\"] * (-(data[\"loo_ps_ind_02_cat\"]))) - data[\"loo_ps_car_07_cat\"])))\n",
    "    v[\"216\"] = 0.020000*np.tanh(((((data[\"loo_ps_ind_17_bin\"] + data[\"loo_ps_car_09_cat\"])/2.0) * data[\"loo_ps_ind_05_cat\"]) * data[\"ps_reg_02\"]))\n",
    "    v[\"217\"] = 0.019984*np.tanh((data[\"ps_car_14\"] * (data[\"loo_ps_car_07_cat\"] * ((data[\"ps_ind_15\"] + data[\"loo_ps_ind_09_bin\"])/2.0))))\n",
    "    v[\"218\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_09_bin\"] + ((data[\"loo_ps_ind_02_cat\"] + data[\"ps_reg_02\"])/2.0))/2.0) * ((data[\"missing\"] + data[\"ps_reg_02\"])/2.0)))\n",
    "    v[\"219\"] = 0.019984*np.tanh((data[\"ps_car_14\"] * ((data[\"loo_ps_car_08_cat\"] * (-(data[\"loo_ps_ind_04_cat\"]))) + (-(data[\"loo_ps_car_07_cat\"])))))\n",
    "    v[\"220\"] = 0.020000*np.tanh((((data[\"ps_ind_03\"] * ((data[\"loo_ps_ind_02_cat\"] * data[\"ps_ind_03\"]) * 2.0)) + data[\"ps_ind_03\"])/2.0))\n",
    "    v[\"221\"] = 0.019949*np.tanh((data[\"loo_ps_ind_06_bin\"] * (data[\"loo_ps_ind_16_bin\"] * ((data[\"loo_ps_car_07_cat\"] + ((data[\"ps_reg_02\"] + data[\"loo_ps_ind_08_bin\"])/2.0))/2.0))))\n",
    "    v[\"222\"] = 0.019984*np.tanh(((data[\"loo_ps_ind_17_bin\"] * data[\"ps_reg_03\"]) * (-(((data[\"loo_ps_ind_12_bin\"] + data[\"loo_ps_car_04_cat\"])/2.0)))))\n",
    "    v[\"223\"] = 0.019848*np.tanh(((data[\"ps_ind_01\"] * (data[\"loo_ps_ind_18_bin\"] * data[\"loo_ps_car_01_cat\"])) - (data[\"loo_ps_car_10_cat\"] * data[\"ps_ind_03\"])))\n",
    "    v[\"224\"] = 0.019973*np.tanh((((data[\"ps_ind_03\"] * 1.480000) * data[\"ps_reg_03\"]) * ((data[\"ps_car_12\"] + data[\"loo_ps_ind_17_bin\"])/2.0)))\n",
    "    v[\"225\"] = 0.020000*np.tanh((-((data[\"loo_ps_ind_17_bin\"] * (data[\"ps_car_15\"] - (data[\"loo_ps_ind_04_cat\"] * data[\"loo_ps_car_10_cat\"]))))))\n",
    "    v[\"226\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_04_cat\"] + data[\"loo_ps_ind_04_cat\"]) * (data[\"ps_ind_01\"] * (-(data[\"ps_ind_03\"])))))\n",
    "    v[\"227\"] = 0.020000*np.tanh((-((((data[\"loo_ps_ind_06_bin\"] + (data[\"loo_ps_car_08_cat\"] + data[\"loo_ps_ind_02_cat\"]))/2.0) * np.tanh(data[\"loo_ps_ind_18_bin\"])))))\n",
    "    v[\"228\"] = 0.019988*np.tanh((data[\"loo_ps_ind_07_bin\"] * (data[\"loo_ps_ind_17_bin\"] * (((data[\"loo_ps_car_08_cat\"] + data[\"ps_reg_02\"]) + data[\"loo_ps_ind_05_cat\"])/2.0))))\n",
    "    v[\"229\"] = 0.020000*np.tanh((data[\"loo_ps_ind_04_cat\"] * (data[\"ps_ind_15\"] * (data[\"ps_car_12\"] - np.tanh(0.753247)))))\n",
    "    v[\"230\"] = 0.014245*np.tanh((((data[\"ps_reg_02\"] + data[\"loo_ps_car_08_cat\"])/2.0) * (data[\"ps_reg_02\"] * (data[\"ps_reg_02\"] - 3.0))))\n",
    "    v[\"231\"] = 0.020000*np.tanh(((0.232323 + (data[\"loo_ps_car_11_cat\"] * (data[\"ps_ind_01\"] * (data[\"ps_reg_03\"] * data[\"ps_reg_02\"]))))/2.0))\n",
    "    v[\"232\"] = 0.019984*np.tanh((data[\"loo_ps_ind_08_bin\"] * (-(((((data[\"ps_reg_03\"] + data[\"loo_ps_car_11_cat\"])/2.0) + data[\"loo_ps_ind_12_bin\"])/2.0)))))\n",
    "    v[\"233\"] = 0.019969*np.tanh((-(np.tanh((data[\"ps_reg_02\"] * (data[\"loo_ps_car_06_cat\"] - (data[\"ps_ind_03\"] * data[\"loo_ps_ind_18_bin\"])))))))\n",
    "    v[\"234\"] = 0.019996*np.tanh((-(((data[\"ps_car_15\"] + ((data[\"ps_car_14\"] * data[\"loo_ps_car_02_cat\"]) - 0.753247))/2.0))))\n",
    "    v[\"235\"] = 0.020000*np.tanh(((data[\"loo_ps_car_07_cat\"] * (-(data[\"loo_ps_ind_17_bin\"]))) * (data[\"loo_ps_car_02_cat\"] + data[\"loo_ps_car_06_cat\"])))\n",
    "    v[\"236\"] = 0.019984*np.tanh((data[\"loo_ps_car_11_cat\"] * (data[\"loo_ps_car_01_cat\"] * (data[\"ps_reg_01\"] * ((0.791667 + data[\"loo_ps_car_07_cat\"])/2.0)))))\n",
    "    v[\"237\"] = 0.020000*np.tanh((data[\"loo_ps_car_08_cat\"] * (((-((data[\"loo_ps_car_03_cat\"] * data[\"ps_ind_01\"]))) + data[\"ps_ind_01\"])/2.0)))\n",
    "    v[\"238\"] = 0.019973*np.tanh((data[\"ps_car_11\"] * ((data[\"loo_ps_car_06_cat\"] + (data[\"ps_ind_03\"] * np.tanh((-(data[\"ps_car_11\"])))))/2.0)))\n",
    "    v[\"239\"] = 0.020000*np.tanh((data[\"loo_ps_car_01_cat\"] * (data[\"loo_ps_car_06_cat\"] * (((-(data[\"loo_ps_car_07_cat\"])) + data[\"loo_ps_car_05_cat\"])/2.0))))\n",
    "    v[\"240\"] = 0.020000*np.tanh((data[\"loo_ps_car_09_cat\"] * (data[\"ps_ind_01\"] * (data[\"loo_ps_car_09_cat\"] - (0.945455 - data[\"ps_ind_01\"])))))\n",
    "    v[\"241\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_02_cat\"] * (data[\"ps_ind_15\"] - data[\"loo_ps_ind_02_cat\"])) * data[\"ps_ind_15\"]) - data[\"loo_ps_ind_02_cat\"]))\n",
    "    v[\"242\"] = 0.019687*np.tanh(((-3.0 * ((data[\"ps_ind_15\"] + 1.0) + data[\"ps_ind_03\"])) * data[\"loo_ps_car_09_cat\"]))\n",
    "    v[\"243\"] = 0.020000*np.tanh((((0.633333 * data[\"ps_car_14\"]) * data[\"loo_ps_ind_17_bin\"]) * (data[\"loo_ps_ind_04_cat\"] - data[\"ps_car_12\"])))\n",
    "    v[\"244\"] = 0.019930*np.tanh((data[\"loo_ps_ind_08_bin\"] * ((data[\"ps_ind_03\"] + ((data[\"missing\"] + (data[\"loo_ps_ind_04_cat\"] - 1.0))/2.0))/2.0)))\n",
    "    v[\"245\"] = 0.019293*np.tanh((data[\"loo_ps_ind_04_cat\"] * (np.tanh(data[\"ps_car_12\"]) + (-(data[\"loo_ps_car_06_cat\"])))))\n",
    "    v[\"246\"] = 0.020000*np.tanh((data[\"loo_ps_ind_08_bin\"] * ((data[\"loo_ps_ind_08_bin\"] * data[\"loo_ps_ind_08_bin\"]) * (data[\"ps_ind_01\"] - data[\"loo_ps_car_05_cat\"]))))\n",
    "    v[\"247\"] = 0.020000*np.tanh((np.tanh((data[\"ps_ind_15\"] * (data[\"loo_ps_ind_07_bin\"] + data[\"ps_ind_15\"]))) * data[\"loo_ps_ind_07_bin\"]))\n",
    "    v[\"248\"] = 0.019254*np.tanh(((((data[\"loo_ps_ind_08_bin\"] + (data[\"ps_car_12\"] * data[\"ps_ind_14\"]))/2.0) + (data[\"loo_ps_ind_08_bin\"] * data[\"loo_ps_car_03_cat\"]))/2.0))\n",
    "    v[\"249\"] = 0.019992*np.tanh(((data[\"loo_ps_ind_13_bin\"] + (-((data[\"ps_ind_03\"] * (data[\"ps_car_14\"] + data[\"loo_ps_ind_02_cat\"])))))/2.0))\n",
    "    v[\"250\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_02_cat\"] * data[\"loo_ps_car_08_cat\"]) * (data[\"loo_ps_car_03_cat\"] - (data[\"loo_ps_ind_02_cat\"] * data[\"loo_ps_ind_02_cat\"]))))\n",
    "    v[\"251\"] = 0.020000*np.tanh(((np.tanh(data[\"ps_car_12\"]) * data[\"loo_ps_ind_02_cat\"]) - ((data[\"loo_ps_ind_02_cat\"] + np.tanh(data[\"loo_ps_ind_05_cat\"]))/2.0)))\n",
    "    v[\"252\"] = 0.020000*np.tanh(((data[\"ps_ind_15\"] * data[\"ps_ind_15\"]) * (data[\"loo_ps_ind_12_bin\"] * (data[\"ps_ind_15\"] * data[\"loo_ps_car_11_cat\"]))))\n",
    "    v[\"253\"] = 0.019801*np.tanh(((data[\"loo_ps_ind_05_cat\"] - 0.232323) * ((data[\"loo_ps_ind_04_cat\"] - data[\"ps_car_11\"]) * data[\"loo_ps_ind_17_bin\"])))\n",
    "    v[\"254\"] = 0.020000*np.tanh((data[\"loo_ps_ind_17_bin\"] * (data[\"ps_ind_14\"] * (-((data[\"loo_ps_car_03_cat\"] + data[\"loo_ps_ind_04_cat\"]))))))\n",
    "    v[\"255\"] = 0.019711*np.tanh((((data[\"ps_car_11\"] + data[\"ps_ind_01\"])/2.0) * (-((data[\"loo_ps_car_04_cat\"] * np.tanh(data[\"ps_ind_01\"]))))))\n",
    "    v[\"256\"] = 0.019996*np.tanh((data[\"loo_ps_ind_02_cat\"] * ((data[\"ps_car_15\"] * data[\"loo_ps_ind_17_bin\"]) * (data[\"missing\"] - 0.945455))))\n",
    "    v[\"257\"] = 0.020000*np.tanh((((-((data[\"missing\"] * data[\"loo_ps_car_07_cat\"]))) + (data[\"loo_ps_car_07_cat\"] * (-(data[\"loo_ps_ind_12_bin\"]))))/2.0))\n",
    "    v[\"258\"] = 0.019844*np.tanh(((data[\"loo_ps_ind_05_cat\"] + data[\"ps_car_14\"]) * (-((data[\"ps_ind_01\"] * data[\"loo_ps_ind_17_bin\"])))))\n",
    "    v[\"259\"] = 0.020000*np.tanh((data[\"loo_ps_ind_08_bin\"] * (((data[\"missing\"] + np.tanh(data[\"loo_ps_ind_02_cat\"]))/2.0) * data[\"ps_car_14\"])))\n",
    "    v[\"260\"] = 0.019945*np.tanh(((data[\"loo_ps_ind_04_cat\"] * (data[\"loo_ps_ind_04_cat\"] + (-(data[\"loo_ps_ind_09_bin\"])))) - data[\"loo_ps_car_10_cat\"]))\n",
    "    v[\"261\"] = 0.020000*np.tanh((((data[\"ps_ind_03\"] + data[\"loo_ps_ind_12_bin\"])/2.0) * (data[\"ps_ind_03\"] + np.tanh((-(data[\"ps_ind_03\"]))))))\n",
    "    v[\"262\"] = 0.019992*np.tanh((data[\"loo_ps_car_10_cat\"] * (((data[\"loo_ps_ind_04_cat\"] * data[\"loo_ps_ind_05_cat\"]) * data[\"ps_ind_01\"]) - data[\"ps_ind_01\"])))\n",
    "    v[\"263\"] = 0.020000*np.tanh((data[\"ps_reg_02\"] * ((data[\"ps_car_13\"] - data[\"loo_ps_car_07_cat\"]) * (data[\"ps_car_12\"] - 0.633333))))\n",
    "    v[\"264\"] = 0.019973*np.tanh((data[\"ps_ind_14\"] * (((8.428570 * (data[\"loo_ps_ind_07_bin\"] * data[\"ps_car_15\"])) + data[\"loo_ps_ind_13_bin\"])/2.0)))\n",
    "    v[\"265\"] = 0.020000*np.tanh(((data[\"loo_ps_car_03_cat\"] * (data[\"loo_ps_ind_05_cat\"] - data[\"loo_ps_car_10_cat\"])) * np.tanh(data[\"ps_reg_02\"])))\n",
    "    v[\"266\"] = 0.020000*np.tanh((((data[\"ps_car_13\"] + np.tanh(data[\"loo_ps_ind_17_bin\"]))/2.0) * (((-(data[\"loo_ps_car_10_cat\"])) + data[\"loo_ps_ind_04_cat\"])/2.0)))\n",
    "    v[\"267\"] = 0.020000*np.tanh(((data[\"ps_ind_03\"] * data[\"loo_ps_ind_17_bin\"]) * ((-1.0 + (data[\"loo_ps_car_03_cat\"] * data[\"ps_car_13\"]))/2.0)))\n",
    "    v[\"268\"] = 0.019977*np.tanh(((((data[\"loo_ps_ind_11_bin\"] + (data[\"ps_car_11\"] + 1.480000))/2.0) + data[\"ps_ind_15\"]) * data[\"loo_ps_ind_12_bin\"]))\n",
    "    v[\"269\"] = 0.020000*np.tanh((np.tanh(np.tanh(data[\"ps_reg_03\"])) * (data[\"ps_car_11\"] * (data[\"ps_ind_14\"] + data[\"ps_ind_15\"]))))\n",
    "    v[\"270\"] = 0.018535*np.tanh((((data[\"loo_ps_ind_05_cat\"] + (data[\"loo_ps_ind_18_bin\"] - (data[\"loo_ps_ind_05_cat\"] * data[\"loo_ps_ind_18_bin\"])))/2.0) * data[\"loo_ps_ind_09_bin\"]))\n",
    "    v[\"271\"] = 0.020000*np.tanh((data[\"ps_car_15\"] * (data[\"ps_car_12\"] * (np.tanh(data[\"ps_car_15\"]) - data[\"ps_car_11\"]))))\n",
    "    v[\"272\"] = 0.019957*np.tanh((data[\"ps_reg_02\"] * (data[\"ps_reg_03\"] * (-3.0 + data[\"ps_reg_02\"]))))\n",
    "    v[\"273\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_05_cat\"] - data[\"loo_ps_ind_12_bin\"]) * ((data[\"ps_car_15\"] + ((data[\"loo_ps_ind_02_cat\"] + data[\"loo_ps_ind_02_cat\"])/2.0))/2.0)))\n",
    "    v[\"274\"] = 0.020000*np.tanh((data[\"loo_ps_car_10_cat\"] * ((data[\"loo_ps_ind_17_bin\"] * data[\"loo_ps_ind_02_cat\"]) - data[\"loo_ps_ind_16_bin\"])))\n",
    "    v[\"275\"] = 0.020000*np.tanh((((data[\"ps_ind_03\"] + (-((data[\"loo_ps_ind_09_bin\"] * data[\"ps_ind_15\"]))))/2.0) * data[\"loo_ps_ind_05_cat\"]))\n",
    "    v[\"276\"] = 0.019512*np.tanh(np.tanh((data[\"ps_ind_03\"] * ((data[\"ps_reg_03\"] * data[\"ps_reg_03\"]) - 0.791667))))\n",
    "    v[\"277\"] = 0.018703*np.tanh((-(((0.633333 * data[\"loo_ps_ind_05_cat\"]) * (data[\"loo_ps_ind_16_bin\"] * data[\"loo_ps_car_08_cat\"])))))\n",
    "    v[\"278\"] = 0.019988*np.tanh(((data[\"loo_ps_ind_02_cat\"] * data[\"ps_ind_03\"]) * (data[\"ps_ind_03\"] * data[\"loo_ps_ind_06_bin\"])))\n",
    "    v[\"279\"] = 0.019723*np.tanh((((data[\"loo_ps_ind_09_bin\"] * data[\"loo_ps_car_04_cat\"]) + (data[\"ps_ind_03\"] * data[\"ps_car_13\"])) * data[\"ps_car_15\"]))\n",
    "    v[\"280\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_02_cat\"] + (data[\"loo_ps_ind_02_cat\"] + data[\"ps_ind_03\"])) * (data[\"loo_ps_ind_13_bin\"] - data[\"loo_ps_ind_02_cat\"])))\n",
    "    v[\"281\"] = 0.019992*np.tanh((data[\"loo_ps_ind_04_cat\"] * (data[\"loo_ps_ind_05_cat\"] * (data[\"ps_ind_01\"] - ((0.432099 + data[\"loo_ps_car_06_cat\"])/2.0)))))\n",
    "    v[\"282\"] = 0.020000*np.tanh((data[\"ps_reg_01\"] * (((data[\"loo_ps_ind_05_cat\"] * (-(data[\"ps_car_12\"]))) + data[\"loo_ps_ind_11_bin\"])/2.0)))\n",
    "    v[\"283\"] = 0.020000*np.tanh((((-(data[\"ps_ind_03\"])) * data[\"loo_ps_ind_05_cat\"]) * np.tanh(np.tanh(data[\"ps_ind_01\"]))))\n",
    "    v[\"284\"] = 0.018035*np.tanh((data[\"ps_ind_03\"] * np.tanh((data[\"loo_ps_car_05_cat\"] * (data[\"loo_ps_ind_16_bin\"] - data[\"ps_ind_01\"])))))\n",
    "    v[\"285\"] = 0.017937*np.tanh((data[\"loo_ps_ind_04_cat\"] * ((data[\"ps_car_11\"] + (data[\"loo_ps_ind_04_cat\"] - data[\"loo_ps_ind_16_bin\"])) + data[\"ps_ind_03\"])))\n",
    "    v[\"286\"] = 0.020000*np.tanh((data[\"ps_car_13\"] * (data[\"loo_ps_car_03_cat\"] * ((data[\"loo_ps_ind_13_bin\"] * data[\"ps_car_13\"]) * data[\"ps_car_13\"]))))\n",
    "    v[\"287\"] = 0.019140*np.tanh((data[\"loo_ps_car_03_cat\"] * ((data[\"loo_ps_car_02_cat\"] * (data[\"ps_reg_02\"] - data[\"ps_reg_01\"])) * data[\"loo_ps_ind_04_cat\"])))\n",
    "    v[\"288\"] = 0.019984*np.tanh((data[\"loo_ps_car_06_cat\"] * (data[\"loo_ps_ind_02_cat\"] * (data[\"loo_ps_ind_02_cat\"] * (-(data[\"loo_ps_ind_16_bin\"]))))))\n",
    "    v[\"289\"] = 0.017492*np.tanh((((data[\"ps_car_11\"] * data[\"loo_ps_car_06_cat\"]) + ((-(data[\"ps_car_11\"])) * data[\"loo_ps_ind_17_bin\"]))/2.0))\n",
    "    v[\"290\"] = 0.019707*np.tanh((data[\"loo_ps_ind_04_cat\"] * (((data[\"loo_ps_ind_11_bin\"] + (data[\"missing\"] * data[\"loo_ps_car_07_cat\"])) + data[\"missing\"])/2.0)))\n",
    "    v[\"291\"] = 0.019598*np.tanh(((data[\"ps_reg_01\"] * data[\"loo_ps_car_04_cat\"]) * (data[\"loo_ps_car_07_cat\"] + data[\"loo_ps_ind_12_bin\"])))\n",
    "    v[\"292\"] = 0.019855*np.tanh(((data[\"loo_ps_ind_02_cat\"] * data[\"loo_ps_ind_16_bin\"]) * (data[\"loo_ps_ind_07_bin\"] * (data[\"loo_ps_ind_18_bin\"] + 0.232323))))\n",
    "    v[\"293\"] = 0.020000*np.tanh(((data[\"loo_ps_car_04_cat\"] * data[\"ps_reg_01\"]) * np.tanh(((-(data[\"loo_ps_car_08_cat\"])) - data[\"loo_ps_car_09_cat\"]))))\n",
    "    v[\"294\"] = 0.019992*np.tanh((data[\"ps_reg_02\"] * (data[\"ps_car_13\"] * (data[\"ps_car_15\"] + (data[\"loo_ps_car_05_cat\"] * data[\"ps_reg_03\"])))))\n",
    "    v[\"295\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_12_bin\"] * (data[\"loo_ps_car_01_cat\"] - data[\"loo_ps_car_07_cat\"])) * data[\"ps_reg_02\"]))\n",
    "    v[\"296\"] = 0.020000*np.tanh((-((data[\"loo_ps_car_10_cat\"] * ((data[\"ps_car_15\"] + data[\"loo_ps_car_11_cat\"]) + data[\"ps_ind_14\"])))))\n",
    "    v[\"297\"] = 0.019977*np.tanh((((data[\"loo_ps_car_07_cat\"] + (0.435484 - data[\"loo_ps_ind_06_bin\"]))/2.0) * (data[\"loo_ps_ind_08_bin\"] * data[\"loo_ps_car_08_cat\"])))\n",
    "    v[\"298\"] = 0.019941*np.tanh((data[\"ps_car_14\"] * (data[\"loo_ps_ind_04_cat\"] + (np.tanh(data[\"loo_ps_ind_04_cat\"]) * (-(data[\"loo_ps_ind_07_bin\"]))))))\n",
    "    v[\"299\"] = 0.019117*np.tanh((data[\"loo_ps_ind_06_bin\"] * ((data[\"ps_ind_03\"] + data[\"loo_ps_ind_04_cat\"]) * data[\"loo_ps_ind_17_bin\"])))\n",
    "    v[\"300\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_16_bin\"] * (data[\"loo_ps_ind_04_cat\"] * (data[\"ps_reg_01\"] * data[\"loo_ps_car_07_cat\"]))) * data[\"loo_ps_ind_18_bin\"]))\n",
    "    v[\"301\"] = 0.019973*np.tanh((-((data[\"ps_car_11\"] * (((data[\"loo_ps_ind_04_cat\"] + data[\"loo_ps_car_02_cat\"])/2.0) * data[\"loo_ps_ind_05_cat\"])))))\n",
    "    v[\"302\"] = 0.020000*np.tanh((data[\"ps_car_12\"] * ((data[\"loo_ps_ind_12_bin\"] * data[\"ps_car_12\"]) * (data[\"ps_car_11\"] - data[\"loo_ps_car_08_cat\"]))))\n",
    "    v[\"303\"] = 0.020000*np.tanh((data[\"loo_ps_ind_17_bin\"] * (data[\"loo_ps_car_10_cat\"] * (data[\"loo_ps_ind_04_cat\"] - (data[\"ps_ind_03\"] * data[\"loo_ps_ind_17_bin\"])))))\n",
    "    v[\"304\"] = 0.017566*np.tanh(((data[\"ps_reg_03\"] - data[\"loo_ps_car_03_cat\"]) * (data[\"ps_reg_01\"] * data[\"loo_ps_ind_08_bin\"])))\n",
    "    v[\"305\"] = 0.019973*np.tanh((8.428570 * (0.666667 - (data[\"loo_ps_car_10_cat\"] * (8.428570 - 0.432099)))))\n",
    "    v[\"306\"] = 0.020000*np.tanh(np.tanh(np.tanh((-3.0 * (((data[\"ps_reg_01\"] - data[\"loo_ps_car_02_cat\"]) + 2.0)/2.0)))))\n",
    "    v[\"307\"] = 0.020000*np.tanh(((data[\"ps_ind_01\"] - data[\"ps_reg_01\"]) * (data[\"ps_reg_02\"] * data[\"loo_ps_ind_04_cat\"])))\n",
    "    v[\"308\"] = 0.020000*np.tanh((((data[\"ps_car_12\"] + data[\"ps_ind_14\"])/2.0) * (data[\"loo_ps_ind_02_cat\"] * (data[\"ps_car_12\"] * data[\"loo_ps_ind_17_bin\"]))))\n",
    "    v[\"309\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_02_cat\"] * data[\"loo_ps_car_04_cat\"]) * ((data[\"loo_ps_ind_02_cat\"] * data[\"loo_ps_ind_02_cat\"]) - data[\"loo_ps_ind_02_cat\"])))\n",
    "    v[\"310\"] = 0.020000*np.tanh((((data[\"ps_ind_14\"] * data[\"ps_car_12\"]) + (data[\"loo_ps_ind_04_cat\"] * (data[\"loo_ps_ind_04_cat\"] + data[\"ps_ind_14\"])))/2.0))\n",
    "    v[\"311\"] = 0.017878*np.tanh((data[\"ps_reg_03\"] * (-(((data[\"ps_car_12\"] + (data[\"loo_ps_car_09_cat\"] * data[\"loo_ps_ind_08_bin\"]))/2.0)))))\n",
    "    v[\"312\"] = 0.019973*np.tanh((data[\"loo_ps_car_01_cat\"] * (((data[\"loo_ps_car_01_cat\"] + data[\"ps_reg_01\"])/2.0) * data[\"ps_car_12\"])))\n",
    "    v[\"313\"] = 0.018691*np.tanh(((data[\"ps_car_14\"] * data[\"loo_ps_car_11_cat\"]) * (-((data[\"ps_ind_14\"] + data[\"loo_ps_ind_08_bin\"])))))\n",
    "    v[\"314\"] = 0.019566*np.tanh(((1.0 - data[\"loo_ps_car_11_cat\"]) * (((data[\"missing\"] * data[\"loo_ps_car_11_cat\"]) + data[\"ps_car_14\"])/2.0)))\n",
    "    v[\"315\"] = 0.015312*np.tanh(((data[\"missing\"] + (((data[\"missing\"] - data[\"loo_ps_ind_02_cat\"]) - data[\"loo_ps_ind_09_bin\"]) * data[\"ps_reg_01\"]))/2.0))\n",
    "    v[\"316\"] = 0.019980*np.tanh((data[\"loo_ps_car_03_cat\"] * ((data[\"loo_ps_car_11_cat\"] * data[\"loo_ps_ind_04_cat\"]) * data[\"loo_ps_ind_05_cat\"])))\n",
    "    v[\"317\"] = 0.016890*np.tanh((data[\"loo_ps_car_07_cat\"] * ((data[\"loo_ps_car_11_cat\"] - data[\"ps_car_13\"]) - data[\"loo_ps_ind_06_bin\"])))\n",
    "    v[\"318\"] = 0.020000*np.tanh((data[\"ps_car_12\"] * ((data[\"ps_reg_02\"] * data[\"loo_ps_car_04_cat\"]) * ((data[\"ps_reg_02\"] + data[\"ps_ind_03\"])/2.0))))\n",
    "    v[\"319\"] = 0.016683*np.tanh(np.tanh((data[\"loo_ps_ind_16_bin\"] * (data[\"loo_ps_ind_12_bin\"] - (data[\"loo_ps_ind_17_bin\"] * data[\"ps_ind_01\"])))))\n",
    "    v[\"320\"] = 0.018222*np.tanh(((data[\"loo_ps_ind_13_bin\"] * data[\"ps_car_12\"]) - np.tanh((data[\"loo_ps_ind_02_cat\"] + data[\"ps_car_14\"]))))\n",
    "    v[\"321\"] = 0.020000*np.tanh(((data[\"ps_ind_14\"] * data[\"ps_car_11\"]) * (data[\"ps_reg_02\"] - ((data[\"ps_car_11\"] + data[\"ps_car_15\"])/2.0))))\n",
    "    v[\"322\"] = 0.019703*np.tanh((((data[\"ps_ind_01\"] + (-(data[\"loo_ps_car_08_cat\"])))/2.0) * (data[\"loo_ps_ind_17_bin\"] * data[\"ps_ind_01\"])))\n",
    "    v[\"323\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_05_cat\"] * (data[\"ps_reg_01\"] - 0.753247)) * (data[\"loo_ps_car_02_cat\"] * data[\"loo_ps_car_02_cat\"])))\n",
    "    v[\"324\"] = 0.020000*np.tanh((data[\"ps_reg_01\"] * ((data[\"loo_ps_car_11_cat\"] + ((data[\"ps_reg_01\"] + (-(data[\"loo_ps_car_04_cat\"])))/2.0))/2.0)))\n",
    "    v[\"325\"] = 0.019898*np.tanh((-(((((data[\"loo_ps_ind_17_bin\"] + (-(data[\"ps_car_12\"])))/2.0) + np.tanh(data[\"ps_car_12\"]))/2.0))))\n",
    "    v[\"326\"] = 0.019980*np.tanh(((data[\"loo_ps_ind_12_bin\"] + (data[\"loo_ps_car_04_cat\"] * (data[\"loo_ps_car_09_cat\"] + 2.352940))) * data[\"loo_ps_ind_13_bin\"]))\n",
    "    v[\"327\"] = 0.019996*np.tanh(((((data[\"loo_ps_ind_08_bin\"] * data[\"loo_ps_car_09_cat\"]) + (data[\"ps_reg_03\"] * data[\"loo_ps_ind_08_bin\"]))/2.0) * data[\"ps_car_15\"]))\n",
    "    v[\"328\"] = 0.020000*np.tanh((data[\"ps_reg_03\"] * (((np.tanh(data[\"ps_car_11\"]) + data[\"loo_ps_car_09_cat\"])/2.0) * np.tanh(data[\"loo_ps_ind_07_bin\"]))))\n",
    "    v[\"329\"] = 0.019996*np.tanh((((((data[\"loo_ps_ind_02_cat\"] + data[\"loo_ps_car_10_cat\"])/2.0) + data[\"ps_car_14\"])/2.0) * (data[\"loo_ps_car_08_cat\"] * data[\"ps_reg_02\"])))\n",
    "    v[\"330\"] = 0.020000*np.tanh(((data[\"loo_ps_car_10_cat\"] * data[\"ps_reg_02\"]) * (data[\"loo_ps_ind_18_bin\"] - (data[\"ps_ind_14\"] * data[\"loo_ps_ind_02_cat\"]))))\n",
    "    v[\"331\"] = 0.020000*np.tanh((((data[\"ps_ind_14\"] + np.tanh(data[\"ps_ind_01\"]))/2.0) * (data[\"loo_ps_ind_17_bin\"] * data[\"loo_ps_car_06_cat\"])))\n",
    "    v[\"332\"] = 0.020000*np.tanh((((data[\"ps_ind_15\"] + data[\"loo_ps_ind_05_cat\"])/2.0) * np.tanh((data[\"loo_ps_ind_17_bin\"] * (-(data[\"loo_ps_car_06_cat\"]))))))\n",
    "    v[\"333\"] = 0.020000*np.tanh((data[\"loo_ps_ind_17_bin\"] * (data[\"ps_car_15\"] * np.tanh((data[\"ps_ind_03\"] + data[\"loo_ps_car_11_cat\"])))))\n",
    "    v[\"334\"] = 0.020000*np.tanh((data[\"ps_car_11\"] * (((data[\"loo_ps_ind_11_bin\"] + data[\"loo_ps_ind_10_bin\"])/2.0) - (data[\"loo_ps_ind_05_cat\"] * data[\"loo_ps_ind_04_cat\"]))))\n",
    "    v[\"335\"] = 0.019996*np.tanh((data[\"ps_car_11\"] * ((data[\"loo_ps_car_10_cat\"] + ((data[\"ps_reg_02\"] * data[\"ps_car_11\"]) * data[\"loo_ps_ind_18_bin\"]))/2.0)))\n",
    "    v[\"336\"] = 0.020000*np.tanh(((data[\"ps_ind_03\"] * data[\"loo_ps_ind_02_cat\"]) * (data[\"ps_ind_03\"] - data[\"ps_ind_15\"])))\n",
    "    v[\"337\"] = 0.019996*np.tanh((((data[\"loo_ps_car_07_cat\"] * (data[\"loo_ps_ind_13_bin\"] - data[\"loo_ps_ind_11_bin\"])) * data[\"loo_ps_car_07_cat\"]) * data[\"loo_ps_car_07_cat\"]))\n",
    "    v[\"338\"] = 0.019219*np.tanh(((data[\"loo_ps_ind_02_cat\"] * ((data[\"loo_ps_ind_05_cat\"] * data[\"loo_ps_ind_18_bin\"]) - data[\"loo_ps_ind_02_cat\"])) - data[\"loo_ps_ind_02_cat\"]))\n",
    "    v[\"339\"] = 0.020000*np.tanh((data[\"loo_ps_car_07_cat\"] * (np.tanh(0.232323) - (np.tanh(data[\"loo_ps_car_01_cat\"]) + data[\"loo_ps_ind_12_bin\"]))))\n",
    "    v[\"340\"] = 0.019047*np.tanh(((data[\"ps_ind_01\"] * (data[\"ps_reg_01\"] * data[\"loo_ps_car_06_cat\"])) - (data[\"ps_ind_14\"] * data[\"ps_reg_01\"])))\n",
    "    v[\"341\"] = 0.019996*np.tanh((data[\"loo_ps_car_10_cat\"] * ((np.tanh(np.tanh(data[\"ps_car_12\"])) - data[\"ps_car_13\"]) - data[\"loo_ps_ind_12_bin\"])))\n",
    "    v[\"342\"] = 0.019996*np.tanh((data[\"ps_car_14\"] * (data[\"loo_ps_car_05_cat\"] * (((data[\"loo_ps_car_05_cat\"] + data[\"ps_car_15\"]) + data[\"ps_reg_01\"])/2.0))))\n",
    "    v[\"343\"] = 0.020000*np.tanh((data[\"loo_ps_ind_02_cat\"] * (np.tanh(((-(data[\"loo_ps_car_07_cat\"])) + data[\"ps_reg_02\"])) + data[\"loo_ps_ind_10_bin\"])))\n",
    "    v[\"344\"] = 0.019902*np.tanh((data[\"ps_car_14\"] * ((np.tanh(data[\"loo_ps_ind_05_cat\"]) * data[\"ps_ind_15\"]) - np.tanh(data[\"ps_reg_03\"]))))\n",
    "    v[\"345\"] = 0.019937*np.tanh(((data[\"ps_car_11\"] * (data[\"ps_car_12\"] * data[\"loo_ps_ind_09_bin\"])) * (data[\"loo_ps_ind_11_bin\"] - data[\"loo_ps_ind_18_bin\"])))\n",
    "    v[\"346\"] = 0.019984*np.tanh(((data[\"loo_ps_car_06_cat\"] * (0.232323 - (data[\"loo_ps_ind_05_cat\"] * data[\"loo_ps_ind_05_cat\"]))) * data[\"loo_ps_ind_04_cat\"]))\n",
    "    v[\"347\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_11_bin\"] * data[\"ps_ind_03\"]) * ((data[\"loo_ps_ind_05_cat\"] * data[\"ps_ind_03\"]) * data[\"ps_ind_03\"])))\n",
    "    v[\"348\"] = 0.019934*np.tanh((data[\"loo_ps_ind_16_bin\"] * (data[\"loo_ps_ind_12_bin\"] * (data[\"ps_car_13\"] * (data[\"loo_ps_car_10_cat\"] + data[\"loo_ps_car_03_cat\"])))))\n",
    "    v[\"349\"] = 0.020000*np.tanh(((((data[\"ps_car_15\"] + data[\"ps_ind_14\"])/2.0) * data[\"loo_ps_ind_06_bin\"]) * data[\"ps_reg_02\"]))\n",
    "    v[\"350\"] = 0.019769*np.tanh(((((data[\"ps_ind_03\"] - data[\"ps_reg_02\"]) * 0.117647) - data[\"loo_ps_car_10_cat\"]) * data[\"ps_ind_03\"]))\n",
    "    v[\"351\"] = 0.019992*np.tanh((-(((0.232323 + ((data[\"loo_ps_car_03_cat\"] * data[\"ps_ind_03\"]) * data[\"loo_ps_car_08_cat\"]))/2.0))))\n",
    "    v[\"352\"] = 0.020000*np.tanh((data[\"loo_ps_ind_05_cat\"] * ((data[\"ps_ind_03\"] * (0.232323 - data[\"loo_ps_car_11_cat\"])) * data[\"ps_ind_15\"])))\n",
    "    v[\"353\"] = 0.019980*np.tanh((np.tanh(data[\"ps_ind_03\"]) * ((data[\"ps_car_11\"] + (data[\"ps_reg_03\"] + np.tanh(data[\"missing\"])))/2.0)))\n",
    "    v[\"354\"] = 0.019988*np.tanh((data[\"ps_car_14\"] * (((data[\"loo_ps_ind_12_bin\"] + data[\"ps_car_12\"])/2.0) * data[\"ps_reg_01\"])))\n",
    "    v[\"355\"] = 0.019957*np.tanh(np.tanh((data[\"loo_ps_car_07_cat\"] * (0.633333 - (data[\"ps_reg_02\"] * data[\"ps_reg_02\"])))))\n",
    "    v[\"356\"] = 0.019977*np.tanh((data[\"loo_ps_car_09_cat\"] * (data[\"loo_ps_car_09_cat\"] * (data[\"loo_ps_ind_16_bin\"] * (data[\"ps_reg_01\"] * data[\"ps_ind_15\"])))))\n",
    "    v[\"357\"] = 0.019887*np.tanh(((-((((data[\"ps_car_14\"] * data[\"loo_ps_ind_12_bin\"]) + data[\"ps_reg_03\"])/2.0))) * np.tanh(data[\"loo_ps_car_06_cat\"])))\n",
    "    v[\"358\"] = 0.019965*np.tanh((data[\"loo_ps_ind_05_cat\"] * (data[\"ps_reg_02\"] * ((np.tanh((-(data[\"ps_ind_15\"]))) + data[\"loo_ps_car_09_cat\"])/2.0))))\n",
    "    v[\"359\"] = 0.020000*np.tanh((data[\"loo_ps_ind_12_bin\"] * ((data[\"loo_ps_ind_11_bin\"] + (data[\"loo_ps_car_11_cat\"] + data[\"ps_ind_15\"])) - data[\"loo_ps_ind_02_cat\"])))\n",
    "    v[\"360\"] = 0.020000*np.tanh((((data[\"ps_reg_01\"] + data[\"ps_car_13\"])/2.0) * (data[\"ps_ind_01\"] * data[\"loo_ps_ind_05_cat\"])))\n",
    "    v[\"361\"] = 0.020000*np.tanh((data[\"loo_ps_ind_08_bin\"] * (-((data[\"loo_ps_ind_05_cat\"] * (data[\"ps_car_11\"] - (-(data[\"ps_ind_03\"]))))))))\n",
    "    v[\"362\"] = 0.018640*np.tanh(((((-(((data[\"ps_car_15\"] + data[\"ps_car_11\"])/2.0))) + data[\"loo_ps_car_05_cat\"])/2.0) * data[\"loo_ps_ind_06_bin\"]))\n",
    "    v[\"363\"] = 0.019480*np.tanh((((np.tanh(data[\"ps_reg_02\"]) * ((data[\"loo_ps_car_07_cat\"] + data[\"loo_ps_ind_11_bin\"])/2.0)) + np.tanh(data[\"loo_ps_car_07_cat\"]))/2.0))\n",
    "    v[\"364\"] = 0.020000*np.tanh((data[\"ps_ind_14\"] * (-((0.753247 - ((data[\"ps_ind_03\"] + data[\"ps_ind_03\"])/2.0))))))\n",
    "    v[\"365\"] = 0.020000*np.tanh((((data[\"ps_reg_02\"] * (-(data[\"loo_ps_ind_05_cat\"]))) * data[\"ps_car_15\"]) * data[\"loo_ps_ind_05_cat\"]))\n",
    "    v[\"366\"] = 0.019992*np.tanh((data[\"ps_ind_15\"] * (data[\"loo_ps_ind_02_cat\"] * ((data[\"loo_ps_ind_02_cat\"] * data[\"ps_reg_01\"]) - data[\"ps_ind_03\"]))))\n",
    "    v[\"367\"] = 0.020000*np.tanh((data[\"ps_car_15\"] * ((0.232323 + ((-(data[\"ps_ind_15\"])) * data[\"ps_car_15\"]))/2.0)))\n",
    "    v[\"368\"] = 0.019992*np.tanh((((data[\"loo_ps_car_02_cat\"] + data[\"loo_ps_car_02_cat\"]) - data[\"ps_car_11\"]) * (data[\"loo_ps_ind_02_cat\"] * data[\"loo_ps_ind_04_cat\"])))\n",
    "    v[\"369\"] = 0.020000*np.tanh((data[\"loo_ps_ind_02_cat\"] * (data[\"ps_ind_15\"] * ((data[\"ps_ind_15\"] + (data[\"ps_reg_01\"] * data[\"ps_car_13\"]))/2.0))))\n",
    "    v[\"370\"] = 0.019840*np.tanh((data[\"ps_car_12\"] * ((data[\"ps_car_11\"] + data[\"loo_ps_ind_12_bin\"]) * (-(np.tanh(data[\"ps_ind_01\"]))))))\n",
    "    v[\"371\"] = 0.020000*np.tanh((data[\"loo_ps_ind_06_bin\"] * (data[\"loo_ps_ind_12_bin\"] * (data[\"ps_car_12\"] + (data[\"ps_ind_03\"] * data[\"loo_ps_ind_04_cat\"])))))\n",
    "    v[\"372\"] = 0.017296*np.tanh((data[\"ps_car_11\"] * ((data[\"ps_reg_03\"] + np.tanh((data[\"loo_ps_car_04_cat\"] - data[\"ps_car_11\"])))/2.0)))\n",
    "    v[\"373\"] = 0.019992*np.tanh((((data[\"loo_ps_ind_04_cat\"] * data[\"ps_car_11\"]) + np.tanh((-((data[\"ps_car_11\"] * data[\"loo_ps_ind_05_cat\"])))))/2.0))\n",
    "    v[\"374\"] = 0.017175*np.tanh((data[\"loo_ps_car_09_cat\"] * np.tanh(((data[\"loo_ps_ind_16_bin\"] + data[\"ps_reg_02\"]) + data[\"loo_ps_ind_16_bin\"]))))\n",
    "    v[\"375\"] = 0.020000*np.tanh((np.tanh((0.618557 - data[\"loo_ps_ind_06_bin\"])) * (data[\"loo_ps_car_08_cat\"] * data[\"loo_ps_ind_02_cat\"])))\n",
    "    v[\"376\"] = 0.019992*np.tanh((np.tanh(data[\"loo_ps_ind_05_cat\"]) * (((-(data[\"loo_ps_car_02_cat\"])) + (data[\"loo_ps_car_02_cat\"] * data[\"ps_reg_03\"]))/2.0)))\n",
    "    v[\"377\"] = 0.019965*np.tanh(((-(data[\"loo_ps_car_04_cat\"])) * (((data[\"ps_ind_03\"] * data[\"ps_ind_03\"]) + (-(data[\"ps_car_15\"])))/2.0)))\n",
    "    v[\"378\"] = 0.019777*np.tanh((data[\"loo_ps_ind_17_bin\"] * (data[\"loo_ps_ind_17_bin\"] * (((data[\"loo_ps_ind_08_bin\"] + data[\"loo_ps_ind_13_bin\"])/2.0) * data[\"loo_ps_car_04_cat\"]))))\n",
    "    v[\"379\"] = 0.019996*np.tanh((data[\"loo_ps_car_02_cat\"] * (((data[\"loo_ps_car_01_cat\"] + data[\"ps_car_11\"])/2.0) * ((data[\"loo_ps_car_01_cat\"] + data[\"ps_ind_15\"])/2.0))))\n",
    "    v[\"380\"] = 0.019988*np.tanh((data[\"loo_ps_ind_02_cat\"] * (data[\"ps_car_15\"] * (data[\"ps_car_11\"] + (data[\"ps_ind_15\"] * data[\"ps_reg_01\"])))))\n",
    "    v[\"381\"] = 0.020000*np.tanh(((0.0 + (data[\"loo_ps_ind_04_cat\"] * (data[\"ps_reg_03\"] * (data[\"loo_ps_car_04_cat\"] * data[\"loo_ps_car_08_cat\"]))))/2.0))\n",
    "    v[\"382\"] = 0.019953*np.tanh(((data[\"loo_ps_car_01_cat\"] * data[\"loo_ps_car_01_cat\"]) * ((data[\"ps_reg_01\"] + (-(data[\"loo_ps_car_10_cat\"])))/2.0)))\n",
    "    v[\"383\"] = 0.020000*np.tanh((-((data[\"ps_reg_03\"] * (data[\"ps_ind_14\"] * (data[\"loo_ps_car_04_cat\"] * data[\"ps_reg_03\"]))))))\n",
    "    v[\"384\"] = 0.019078*np.tanh(np.tanh(((data[\"loo_ps_ind_06_bin\"] * data[\"loo_ps_ind_05_cat\"]) * ((-(0.432099)) - data[\"ps_reg_01\"]))))\n",
    "    v[\"385\"] = 0.019934*np.tanh((data[\"loo_ps_car_03_cat\"] * ((-(data[\"ps_car_13\"])) * (data[\"loo_ps_car_10_cat\"] * data[\"ps_car_13\"]))))\n",
    "    v[\"386\"] = 0.019945*np.tanh(np.tanh(((data[\"ps_ind_03\"] * ((-(data[\"loo_ps_ind_04_cat\"])) - data[\"missing\"])) * data[\"loo_ps_ind_07_bin\"])))\n",
    "    v[\"387\"] = 0.019680*np.tanh((data[\"loo_ps_car_01_cat\"] * (((data[\"loo_ps_car_01_cat\"] + (-(data[\"loo_ps_car_09_cat\"])))/2.0) * np.tanh(data[\"loo_ps_ind_16_bin\"]))))\n",
    "    v[\"388\"] = 0.020000*np.tanh((data[\"loo_ps_ind_12_bin\"] * ((-(data[\"ps_ind_01\"])) * (data[\"loo_ps_ind_08_bin\"] * data[\"loo_ps_ind_17_bin\"]))))\n",
    "    v[\"389\"] = 0.020000*np.tanh((((data[\"ps_ind_03\"] * 0.232323) + np.tanh((data[\"ps_reg_03\"] * np.tanh(data[\"loo_ps_car_04_cat\"]))))/2.0))\n",
    "    v[\"390\"] = 0.019988*np.tanh((data[\"loo_ps_car_08_cat\"] * ((data[\"loo_ps_car_01_cat\"] + (data[\"loo_ps_car_09_cat\"] * (data[\"loo_ps_ind_04_cat\"] * data[\"loo_ps_car_06_cat\"])))/2.0)))\n",
    "    v[\"391\"] = 0.019988*np.tanh(((data[\"loo_ps_ind_11_bin\"] * data[\"ps_reg_03\"]) - ((data[\"loo_ps_ind_11_bin\"] + ((data[\"loo_ps_ind_16_bin\"] + data[\"loo_ps_ind_10_bin\"])/2.0))/2.0)))\n",
    "    v[\"392\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_11_bin\"] - data[\"loo_ps_car_10_cat\"]) * (data[\"loo_ps_car_08_cat\"] + data[\"ps_car_13\"])))\n",
    "    v[\"393\"] = 0.019992*np.tanh(((data[\"loo_ps_ind_05_cat\"] * ((data[\"ps_ind_14\"] + (data[\"ps_car_14\"] * data[\"ps_reg_03\"]))/2.0)) * data[\"loo_ps_car_01_cat\"]))\n",
    "    v[\"394\"] = 0.019238*np.tanh(((np.tanh((-(data[\"missing\"]))) * data[\"loo_ps_ind_07_bin\"]) * (-(data[\"ps_reg_01\"]))))\n",
    "    v[\"395\"] = 0.019906*np.tanh((-((np.tanh((data[\"ps_ind_14\"] * data[\"loo_ps_ind_17_bin\"])) * (data[\"loo_ps_ind_07_bin\"] + data[\"loo_ps_ind_07_bin\"])))))\n",
    "    v[\"396\"] = 0.019789*np.tanh(np.tanh((-((data[\"loo_ps_car_03_cat\"] * (data[\"ps_ind_01\"] * (2.0 - data[\"ps_ind_01\"])))))))\n",
    "    v[\"397\"] = 0.019949*np.tanh(((data[\"ps_car_13\"] * (0.148148 * (-(np.tanh(data[\"ps_ind_15\"]))))) * data[\"ps_car_13\"]))\n",
    "    v[\"398\"] = 0.019137*np.tanh((data[\"loo_ps_ind_02_cat\"] * (((-(data[\"ps_ind_03\"])) * (-(data[\"ps_ind_03\"]))) - 1.0)))\n",
    "    v[\"399\"] = 0.019895*np.tanh(np.tanh(np.tanh(((data[\"loo_ps_car_05_cat\"] * data[\"ps_ind_01\"]) + ((data[\"ps_ind_03\"] + data[\"loo_ps_ind_18_bin\"])/2.0)))))\n",
    "    v[\"400\"] = 0.015581*np.tanh((-((0.232323 * (data[\"loo_ps_ind_07_bin\"] * (data[\"loo_ps_ind_16_bin\"] + data[\"loo_ps_car_02_cat\"]))))))\n",
    "    return Outputs(v.sum(axis=1))\n",
    "\n",
    "\n",
    "def GPII(data):\n",
    "    v = pd.DataFrame()\n",
    "    v[\"0\"] = -3.274750\n",
    "    v[\"1\"] = 0.020000*np.tanh((3.642860 * ((data[\"loo_ps_car_01_cat\"] + data[\"loo_ps_ind_16_bin\"]) + (data[\"ps_reg_03\"] + data[\"loo_ps_ind_06_bin\"]))))\n",
    "    v[\"2\"] = 0.020000*np.tanh((19.500000 * (((data[\"ps_car_15\"] + data[\"loo_ps_ind_06_bin\"]) + data[\"loo_ps_car_06_cat\"]) + data[\"loo_ps_car_07_cat\"])))\n",
    "    v[\"3\"] = 0.019996*np.tanh((19.500000 * ((data[\"ps_car_13\"] + (data[\"loo_ps_car_11_cat\"] + data[\"loo_ps_ind_05_cat\"])) + data[\"ps_reg_02\"])))\n",
    "    v[\"4\"] = 0.020000*np.tanh((((data[\"ps_reg_03\"] + (data[\"loo_ps_ind_05_cat\"] + data[\"loo_ps_car_07_cat\"])) + data[\"ps_car_12\"]) * 19.500000))\n",
    "    v[\"5\"] = 0.020000*np.tanh((data[\"loo_ps_ind_06_bin\"] + (data[\"loo_ps_car_04_cat\"] - (data[\"ps_ind_15\"] - (data[\"loo_ps_ind_17_bin\"] + data[\"loo_ps_car_01_cat\"])))))\n",
    "    v[\"6\"] = 0.020000*np.tanh(((11.51410007476806641) * (data[\"loo_ps_car_11_cat\"] + (((data[\"loo_ps_car_09_cat\"] + data[\"ps_reg_03\"])/2.0) + data[\"loo_ps_ind_06_bin\"]))))\n",
    "    v[\"7\"] = 0.020000*np.tanh((19.500000 * ((data[\"ps_car_13\"] + ((data[\"loo_ps_ind_05_cat\"] + (data[\"loo_ps_ind_17_bin\"] + data[\"loo_ps_car_01_cat\"]))/2.0))/2.0)))\n",
    "    v[\"8\"] = 0.020000*np.tanh((19.500000 * (((data[\"ps_reg_02\"] + data[\"loo_ps_ind_09_bin\"]) + 0.760563) + data[\"loo_ps_car_05_cat\"])))\n",
    "    v[\"9\"] = 0.020000*np.tanh((19.500000 * ((data[\"loo_ps_car_11_cat\"] + (((data[\"loo_ps_ind_17_bin\"] + data[\"loo_ps_ind_06_bin\"]) + data[\"loo_ps_car_03_cat\"])/2.0))/2.0)))\n",
    "    v[\"10\"] = 0.020000*np.tanh((6.846150 * (data[\"loo_ps_ind_06_bin\"] + (data[\"loo_ps_car_11_cat\"] + (data[\"loo_ps_ind_17_bin\"] + data[\"loo_ps_car_09_cat\"])))))\n",
    "    v[\"11\"] = 0.020000*np.tanh(((9.75283908843994141) * ((data[\"ps_reg_03\"] + (data[\"loo_ps_car_11_cat\"] - data[\"ps_ind_15\"])) + data[\"loo_ps_ind_04_cat\"])))\n",
    "    v[\"12\"] = 0.020000*np.tanh(((data[\"ps_reg_02\"] + data[\"loo_ps_car_03_cat\"]) + ((data[\"ps_car_13\"] - data[\"ps_ind_15\"]) + data[\"loo_ps_ind_05_cat\"])))\n",
    "    v[\"13\"] = 0.020000*np.tanh(((8.49180412292480469) * ((data[\"loo_ps_ind_09_bin\"] + data[\"loo_ps_car_07_cat\"]) + (data[\"loo_ps_car_09_cat\"] + data[\"loo_ps_ind_06_bin\"]))))\n",
    "    v[\"14\"] = 0.020000*np.tanh(((6.0) * ((((data[\"loo_ps_ind_16_bin\"] + data[\"loo_ps_ind_05_cat\"]) + data[\"ps_reg_01\"])/2.0) + data[\"ps_car_13\"])))\n",
    "    v[\"15\"] = 0.020000*np.tanh((data[\"loo_ps_car_01_cat\"] + (((data[\"ps_reg_01\"] + data[\"ps_car_12\"]) + data[\"loo_ps_car_03_cat\"]) - data[\"ps_ind_15\"])))\n",
    "    v[\"16\"] = 0.020000*np.tanh(((data[\"loo_ps_car_08_cat\"] + (data[\"loo_ps_car_04_cat\"] + (data[\"loo_ps_ind_05_cat\"] + data[\"loo_ps_ind_17_bin\"]))) * 3.642860))\n",
    "    v[\"17\"] = 0.020000*np.tanh((19.500000 * ((0.760563 + (data[\"ps_reg_02\"] + data[\"ps_car_13\"])) + data[\"ps_reg_03\"])))\n",
    "    v[\"18\"] = 0.020000*np.tanh((data[\"loo_ps_ind_07_bin\"] + ((9.29609489440917969) * (((data[\"loo_ps_car_03_cat\"] + data[\"ps_reg_03\"]) + data[\"ps_car_15\"])/2.0))))\n",
    "    v[\"19\"] = 0.020000*np.tanh((6.846150 * ((data[\"loo_ps_ind_05_cat\"] + data[\"ps_car_13\"]) + (data[\"loo_ps_ind_17_bin\"] + data[\"loo_ps_car_07_cat\"]))))\n",
    "    v[\"20\"] = 0.020000*np.tanh((data[\"loo_ps_car_04_cat\"] + (data[\"ps_car_15\"] + (data[\"ps_reg_03\"] + (data[\"loo_ps_car_03_cat\"] - data[\"ps_ind_15\"])))))\n",
    "    v[\"21\"] = 0.020000*np.tanh((6.846150 * (data[\"loo_ps_ind_05_cat\"] + ((data[\"ps_car_13\"] + (data[\"ps_ind_03\"] + data[\"loo_ps_ind_17_bin\"]))/2.0))))\n",
    "    v[\"22\"] = 0.020000*np.tanh((19.500000 * ((data[\"loo_ps_ind_16_bin\"] - data[\"ps_ind_15\"]) + (data[\"ps_reg_03\"] + 0.600000))))\n",
    "    v[\"23\"] = 0.020000*np.tanh((3.0 * (data[\"loo_ps_car_03_cat\"] + (data[\"loo_ps_car_04_cat\"] + (data[\"loo_ps_ind_05_cat\"] + data[\"loo_ps_car_01_cat\"])))))\n",
    "    v[\"24\"] = 0.020000*np.tanh((6.846150 * (((data[\"loo_ps_car_01_cat\"] + data[\"ps_ind_03\"]) + (data[\"loo_ps_ind_05_cat\"] + data[\"loo_ps_ind_17_bin\"]))/2.0)))\n",
    "    v[\"25\"] = 0.020000*np.tanh((data[\"loo_ps_ind_05_cat\"] + (((data[\"loo_ps_ind_17_bin\"] + data[\"ps_car_13\"]) + data[\"ps_reg_01\"]) + data[\"loo_ps_ind_09_bin\"])))\n",
    "    v[\"26\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_09_bin\"] + (data[\"loo_ps_ind_17_bin\"] + (data[\"loo_ps_ind_06_bin\"] + data[\"loo_ps_ind_05_cat\"]))) * 19.500000))\n",
    "    v[\"27\"] = 0.020000*np.tanh(((data[\"ps_reg_03\"] + (data[\"loo_ps_ind_06_bin\"] + (data[\"loo_ps_car_01_cat\"] + 1.871790))) * (13.13490962982177734)))\n",
    "    v[\"28\"] = 0.020000*np.tanh((6.846150 * (data[\"loo_ps_ind_05_cat\"] + ((data[\"loo_ps_ind_05_cat\"] + (data[\"ps_car_13\"] + data[\"loo_ps_ind_16_bin\"]))/2.0))))\n",
    "    v[\"29\"] = 0.020000*np.tanh(((data[\"ps_reg_02\"] + (data[\"loo_ps_ind_17_bin\"] + (data[\"loo_ps_car_11_cat\"] + data[\"ps_car_15\"]))) - data[\"ps_ind_15\"]))\n",
    "    v[\"30\"] = 0.020000*np.tanh(((3.0 * (data[\"loo_ps_ind_05_cat\"] + (data[\"loo_ps_car_09_cat\"] + data[\"ps_ind_03\"]))) + data[\"ps_car_13\"]))\n",
    "    v[\"31\"] = 0.020000*np.tanh(((8.0) * ((data[\"loo_ps_ind_09_bin\"] + data[\"loo_ps_ind_05_cat\"]) + (data[\"ps_ind_03\"] + data[\"loo_ps_car_07_cat\"]))))\n",
    "    v[\"32\"] = 0.020000*np.tanh((data[\"ps_reg_02\"] + ((data[\"ps_car_13\"] + data[\"loo_ps_car_01_cat\"]) + ((1.11309552192687988) + data[\"loo_ps_car_07_cat\"]))))\n",
    "    v[\"33\"] = 0.020000*np.tanh((6.846150 * (((data[\"loo_ps_ind_05_cat\"] - data[\"ps_ind_15\"]) + ((data[\"loo_ps_ind_16_bin\"] + data[\"loo_ps_car_09_cat\"])/2.0))/2.0)))\n",
    "    v[\"34\"] = 0.020000*np.tanh((19.500000 * ((data[\"loo_ps_car_07_cat\"] + (((data[\"ps_ind_03\"] + data[\"loo_ps_ind_05_cat\"]) + data[\"loo_ps_ind_06_bin\"])/2.0))/2.0)))\n",
    "    v[\"35\"] = 0.020000*np.tanh(((((data[\"loo_ps_ind_05_cat\"] + data[\"loo_ps_car_07_cat\"]) + (data[\"loo_ps_ind_07_bin\"] + data[\"loo_ps_car_11_cat\"]))/2.0) * 19.500000))\n",
    "    v[\"36\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_06_bin\"] + (data[\"loo_ps_car_09_cat\"] + data[\"loo_ps_ind_05_cat\"])) + data[\"loo_ps_ind_16_bin\"]) * 19.500000))\n",
    "    v[\"37\"] = 0.020000*np.tanh((((6.0) * (data[\"loo_ps_car_05_cat\"] + (data[\"loo_ps_car_11_cat\"] + data[\"loo_ps_ind_05_cat\"]))) + data[\"ps_reg_02\"]))\n",
    "    v[\"38\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_05_cat\"] + (data[\"loo_ps_car_01_cat\"] - data[\"ps_ind_15\"])) + ((data[\"loo_ps_ind_17_bin\"] + data[\"loo_ps_ind_09_bin\"])/2.0)))\n",
    "    v[\"39\"] = 0.020000*np.tanh(((data[\"ps_reg_03\"] + (data[\"ps_reg_02\"] + (data[\"loo_ps_ind_06_bin\"] - -2.0))) + data[\"ps_ind_01\"]))\n",
    "    v[\"40\"] = 0.020000*np.tanh((data[\"ps_car_13\"] - (data[\"ps_ind_15\"] - ((5.0) * (data[\"loo_ps_car_09_cat\"] + data[\"loo_ps_ind_09_bin\"])))))\n",
    "    v[\"41\"] = 0.020000*np.tanh((((data[\"loo_ps_car_09_cat\"] + (data[\"ps_ind_03\"] * data[\"ps_ind_03\"])) + data[\"ps_ind_03\"]) * (8.21348762512207031)))\n",
    "    v[\"42\"] = 0.020000*np.tanh(((11.08931350708007812) * (((data[\"loo_ps_ind_05_cat\"] + data[\"ps_car_15\"]) + data[\"ps_ind_01\"]) + data[\"loo_ps_car_09_cat\"])))\n",
    "    v[\"43\"] = 0.020000*np.tanh((19.500000 * (data[\"loo_ps_car_09_cat\"] + ((data[\"loo_ps_ind_04_cat\"] - data[\"ps_ind_15\"]) + data[\"loo_ps_car_05_cat\"]))))\n",
    "    v[\"44\"] = 0.020000*np.tanh((19.500000 * ((data[\"loo_ps_ind_17_bin\"] + data[\"ps_reg_03\"]) + (data[\"loo_ps_car_07_cat\"] * data[\"loo_ps_car_07_cat\"]))))\n",
    "    v[\"45\"] = 0.020000*np.tanh((data[\"ps_car_13\"] - (data[\"ps_ind_15\"] - ((data[\"loo_ps_ind_05_cat\"] * (10.0)) - data[\"ps_car_11\"]))))\n",
    "    v[\"46\"] = 0.020000*np.tanh(((2.0 * ((data[\"loo_ps_car_07_cat\"] + data[\"ps_ind_01\"]) + data[\"loo_ps_ind_09_bin\"])) + data[\"loo_ps_ind_17_bin\"]))\n",
    "    v[\"47\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_02_cat\"] + (data[\"loo_ps_ind_16_bin\"] + data[\"loo_ps_ind_02_cat\"])) - data[\"loo_ps_ind_18_bin\"]) * (10.0)))\n",
    "    v[\"48\"] = 0.020000*np.tanh((((data[\"ps_ind_03\"] + (data[\"ps_ind_03\"] * data[\"ps_ind_03\"])) * (14.62119007110595703)) * (14.62119007110595703)))\n",
    "    v[\"49\"] = 0.020000*np.tanh(((6.846150 * (data[\"loo_ps_car_01_cat\"] + data[\"loo_ps_car_09_cat\"])) + (data[\"ps_car_13\"] + 1.135800)))\n",
    "    v[\"50\"] = 0.020000*np.tanh(((7.46593427658081055) * ((7.46593427658081055) * ((data[\"ps_ind_03\"] * data[\"ps_ind_03\"]) + data[\"ps_ind_03\"]))))\n",
    "    v[\"51\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_07_bin\"] + (0.965909 - data[\"ps_ind_15\"])) * (3.642860 - data[\"loo_ps_ind_06_bin\"])))\n",
    "    v[\"52\"] = 0.020000*np.tanh((data[\"loo_ps_ind_07_bin\"] + ((7.95933532714843750) * (data[\"loo_ps_car_07_cat\"] - (data[\"ps_ind_03\"] * data[\"loo_ps_ind_02_cat\"])))))\n",
    "    v[\"53\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_05_cat\"] + (data[\"loo_ps_ind_17_bin\"] + (data[\"loo_ps_ind_06_bin\"] + -2.0))) * 6.846150))\n",
    "    v[\"54\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_09_bin\"] + (data[\"loo_ps_car_07_cat\"] + ((data[\"ps_reg_03\"] + data[\"ps_car_13\"])/2.0))) * (8.96369743347167969)))\n",
    "    v[\"55\"] = 0.020000*np.tanh((data[\"loo_ps_ind_04_cat\"] + (data[\"ps_ind_03\"] - (data[\"ps_ind_03\"] * ((7.0) * data[\"loo_ps_ind_02_cat\"])))))\n",
    "    v[\"56\"] = 0.020000*np.tanh(((4.0) * (data[\"ps_reg_02\"] + (data[\"ps_reg_03\"] + ((data[\"loo_ps_ind_02_cat\"] + data[\"ps_car_15\"])/2.0)))))\n",
    "    v[\"57\"] = 0.020000*np.tanh(((data[\"loo_ps_car_09_cat\"] + (data[\"loo_ps_car_09_cat\"] + (data[\"loo_ps_ind_05_cat\"] * data[\"loo_ps_ind_06_bin\"]))) * 19.500000))\n",
    "    v[\"58\"] = 0.020000*np.tanh((3.642860 * (data[\"loo_ps_ind_05_cat\"] + ((data[\"loo_ps_car_05_cat\"] * data[\"ps_ind_03\"]) - data[\"ps_car_11\"]))))\n",
    "    v[\"59\"] = 0.020000*np.tanh((data[\"loo_ps_ind_02_cat\"] + (data[\"loo_ps_car_07_cat\"] + ((data[\"ps_ind_15\"] * data[\"loo_ps_ind_18_bin\"]) * 6.846150))))\n",
    "    v[\"60\"] = 0.020000*np.tanh((((6.846150 * data[\"loo_ps_ind_02_cat\"]) + (data[\"ps_ind_01\"] + data[\"loo_ps_ind_07_bin\"])) + data[\"loo_ps_car_01_cat\"]))\n",
    "    v[\"61\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_17_bin\"] + (data[\"loo_ps_ind_05_cat\"] * data[\"ps_car_13\"])) + (data[\"loo_ps_ind_17_bin\"] - data[\"ps_ind_03\"])))\n",
    "    v[\"62\"] = 0.020000*np.tanh((((data[\"loo_ps_car_03_cat\"] + data[\"ps_car_13\"]) + data[\"loo_ps_car_04_cat\"]) * (data[\"loo_ps_ind_05_cat\"] + data[\"loo_ps_ind_16_bin\"])))\n",
    "    v[\"63\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_17_bin\"] * data[\"loo_ps_ind_09_bin\"]) + (data[\"loo_ps_ind_16_bin\"] * (data[\"ps_ind_01\"] + data[\"loo_ps_car_01_cat\"]))))\n",
    "    v[\"64\"] = 0.020000*np.tanh((data[\"loo_ps_car_03_cat\"] * (data[\"missing\"] + (data[\"loo_ps_ind_17_bin\"] + (data[\"ps_ind_01\"] + data[\"loo_ps_car_11_cat\"])))))\n",
    "    v[\"65\"] = 0.020000*np.tanh((((data[\"ps_reg_02\"] + data[\"loo_ps_ind_06_bin\"]) + data[\"loo_ps_car_11_cat\"]) * (data[\"loo_ps_ind_05_cat\"] - data[\"ps_car_11\"])))\n",
    "    v[\"66\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_05_cat\"] - data[\"ps_reg_01\"]) * (data[\"ps_car_12\"] + (data[\"loo_ps_car_11_cat\"] + data[\"loo_ps_ind_17_bin\"]))))\n",
    "    v[\"67\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_17_bin\"] * data[\"loo_ps_ind_06_bin\"]) + (data[\"loo_ps_ind_04_cat\"] + ((data[\"loo_ps_ind_08_bin\"] + data[\"ps_car_13\"])/2.0))))\n",
    "    v[\"68\"] = 0.020000*np.tanh(((data[\"ps_car_13\"] * (data[\"loo_ps_ind_05_cat\"] - data[\"ps_car_11\"])) + (data[\"loo_ps_ind_16_bin\"] * data[\"loo_ps_ind_05_cat\"])))\n",
    "    v[\"69\"] = 0.020000*np.tanh(((data[\"ps_ind_01\"] * (data[\"loo_ps_car_05_cat\"] - data[\"ps_ind_15\"])) + ((data[\"loo_ps_car_07_cat\"] + data[\"ps_car_13\"])/2.0)))\n",
    "    v[\"70\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_05_cat\"] * 19.500000) * (data[\"loo_ps_ind_17_bin\"] + data[\"ps_reg_02\"])))\n",
    "    v[\"71\"] = 0.020000*np.tanh((-1.0 + (data[\"loo_ps_ind_05_cat\"] + (data[\"ps_ind_03\"] * (data[\"ps_ind_03\"] - data[\"loo_ps_ind_02_cat\"])))))\n",
    "    v[\"72\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_06_bin\"] + data[\"ps_car_13\"]) * (data[\"ps_ind_03\"] + data[\"loo_ps_ind_05_cat\"])) - data[\"ps_ind_03\"]))\n",
    "    v[\"73\"] = 0.020000*np.tanh((data[\"loo_ps_ind_04_cat\"] + (data[\"loo_ps_ind_16_bin\"] * (data[\"loo_ps_car_09_cat\"] + (data[\"ps_reg_02\"] * data[\"ps_reg_02\"])))))\n",
    "    v[\"74\"] = 0.020000*np.tanh((((data[\"loo_ps_car_03_cat\"] * 3.0) * 3.0) * (data[\"ps_ind_15\"] + data[\"loo_ps_ind_17_bin\"])))\n",
    "    v[\"75\"] = 0.020000*np.tanh((((data[\"ps_ind_01\"] + data[\"loo_ps_ind_17_bin\"])/2.0) * ((data[\"loo_ps_car_07_cat\"] - data[\"ps_car_11\"]) - data[\"ps_ind_15\"])))\n",
    "    v[\"76\"] = 0.020000*np.tanh((((data[\"loo_ps_car_09_cat\"] - (data[\"loo_ps_car_04_cat\"] * data[\"ps_car_11\"])) + data[\"ps_reg_02\"]) - data[\"loo_ps_car_04_cat\"]))\n",
    "    v[\"77\"] = 0.019992*np.tanh(((((data[\"ps_ind_03\"] - data[\"ps_ind_15\"]) * data[\"ps_car_12\"]) + data[\"loo_ps_car_07_cat\"]) + data[\"loo_ps_ind_04_cat\"]))\n",
    "    v[\"78\"] = 0.020000*np.tanh((data[\"loo_ps_ind_05_cat\"] * ((data[\"loo_ps_car_09_cat\"] + data[\"ps_ind_01\"]) + (data[\"loo_ps_car_03_cat\"] + data[\"ps_ind_01\"]))))\n",
    "    v[\"79\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_05_cat\"] + data[\"loo_ps_car_09_cat\"]) * ((data[\"loo_ps_ind_07_bin\"] + data[\"loo_ps_ind_16_bin\"]) + data[\"loo_ps_car_04_cat\"])))\n",
    "    v[\"80\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_17_bin\"] + data[\"loo_ps_car_07_cat\"]) * ((data[\"loo_ps_car_09_cat\"] + data[\"loo_ps_ind_09_bin\"]) + data[\"ps_reg_02\"])))\n",
    "    v[\"81\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_04_cat\"] + (data[\"loo_ps_car_03_cat\"] * data[\"loo_ps_ind_09_bin\"])) + (data[\"ps_ind_01\"] * data[\"loo_ps_car_04_cat\"])))\n",
    "    v[\"82\"] = 0.020000*np.tanh(((data[\"loo_ps_car_01_cat\"] * data[\"loo_ps_car_05_cat\"]) - (data[\"ps_ind_15\"] * (data[\"ps_car_13\"] - data[\"loo_ps_ind_06_bin\"]))))\n",
    "    v[\"83\"] = 0.019996*np.tanh(((data[\"ps_ind_03\"] * ((data[\"loo_ps_ind_09_bin\"] - data[\"ps_reg_01\"]) - data[\"missing\"])) - data[\"ps_car_11\"]))\n",
    "    v[\"84\"] = 0.020000*np.tanh((data[\"loo_ps_car_02_cat\"] + (((data[\"ps_car_13\"] + data[\"loo_ps_car_09_cat\"])/2.0) + (data[\"loo_ps_car_02_cat\"] - data[\"ps_ind_03\"]))))\n",
    "    v[\"85\"] = 0.020000*np.tanh((data[\"ps_ind_01\"] + (data[\"ps_reg_01\"] * ((data[\"missing\"] - data[\"ps_ind_01\"]) - data[\"loo_ps_car_01_cat\"]))))\n",
    "    v[\"86\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_17_bin\"] - ((data[\"ps_reg_03\"] + data[\"loo_ps_ind_09_bin\"])/2.0)) * (data[\"loo_ps_car_01_cat\"] - data[\"ps_ind_15\"])))\n",
    "    v[\"87\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_07_bin\"] + data[\"loo_ps_ind_04_cat\"]) * (data[\"ps_ind_03\"] + ((data[\"loo_ps_car_05_cat\"] + data[\"loo_ps_car_09_cat\"])/2.0))))\n",
    "    v[\"88\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_04_cat\"] - data[\"loo_ps_car_04_cat\"]) + ((data[\"loo_ps_car_07_cat\"] + data[\"loo_ps_ind_07_bin\"]) * data[\"loo_ps_ind_17_bin\"])))\n",
    "    v[\"89\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_05_cat\"] * data[\"loo_ps_ind_17_bin\"]) + ((data[\"loo_ps_ind_05_cat\"] - data[\"loo_ps_ind_02_cat\"]) * data[\"ps_ind_03\"])))\n",
    "    v[\"90\"] = 0.020000*np.tanh((data[\"ps_ind_03\"] - (((data[\"ps_ind_03\"] * data[\"loo_ps_ind_02_cat\"]) + data[\"loo_ps_ind_02_cat\"]) * 6.846150)))\n",
    "    v[\"91\"] = 0.019980*np.tanh((np.tanh((-(data[\"loo_ps_car_11_cat\"]))) + (data[\"loo_ps_car_07_cat\"] - (data[\"ps_ind_15\"] * data[\"loo_ps_car_11_cat\"]))))\n",
    "    v[\"92\"] = 0.020000*np.tanh((data[\"loo_ps_ind_02_cat\"] + ((data[\"loo_ps_ind_05_cat\"] * (data[\"ps_reg_02\"] + data[\"loo_ps_ind_17_bin\"])) - data[\"loo_ps_ind_05_cat\"])))\n",
    "    v[\"93\"] = 0.019996*np.tanh(((data[\"loo_ps_ind_02_cat\"] + data[\"loo_ps_ind_02_cat\"]) * ((data[\"loo_ps_car_08_cat\"] - data[\"ps_ind_03\"]) + data[\"loo_ps_car_08_cat\"])))\n",
    "    v[\"94\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_05_cat\"] * (data[\"loo_ps_ind_07_bin\"] + data[\"ps_reg_02\"])) + (data[\"loo_ps_ind_02_cat\"] - data[\"ps_ind_03\"]))/2.0))\n",
    "    v[\"95\"] = 0.020000*np.tanh((((data[\"loo_ps_car_09_cat\"] + data[\"ps_reg_01\"])/2.0) - (data[\"loo_ps_ind_06_bin\"] * (data[\"ps_car_15\"] + data[\"ps_reg_01\"]))))\n",
    "    v[\"96\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_02_cat\"] + (((data[\"loo_ps_car_09_cat\"] + data[\"loo_ps_ind_18_bin\"])/2.0) * data[\"loo_ps_ind_17_bin\"])) * data[\"loo_ps_car_09_cat\"]))\n",
    "    v[\"97\"] = 0.020000*np.tanh((data[\"loo_ps_ind_05_cat\"] * ((data[\"loo_ps_ind_07_bin\"] + data[\"ps_ind_15\"]) + (data[\"ps_ind_01\"] + data[\"loo_ps_car_09_cat\"]))))\n",
    "    v[\"98\"] = 0.020000*np.tanh((data[\"ps_reg_02\"] + (((data[\"loo_ps_ind_02_cat\"] - data[\"ps_ind_03\"]) * data[\"loo_ps_ind_02_cat\"]) + -1.0)))\n",
    "    v[\"99\"] = 0.020000*np.tanh((((data[\"ps_ind_03\"] - data[\"ps_car_15\"]) - data[\"ps_ind_15\"]) * ((data[\"ps_car_15\"] + data[\"ps_ind_03\"])/2.0)))\n",
    "    v[\"100\"] = 0.020000*np.tanh(((((data[\"ps_reg_03\"] + data[\"loo_ps_car_09_cat\"])/2.0) + data[\"loo_ps_ind_05_cat\"]) * (-2.0 + data[\"loo_ps_ind_05_cat\"])))\n",
    "    v[\"101\"] = 0.020000*np.tanh((((data[\"ps_car_15\"] + data[\"loo_ps_car_09_cat\"])/2.0) - (data[\"loo_ps_car_03_cat\"] * (data[\"ps_car_15\"] - data[\"loo_ps_ind_09_bin\"]))))\n",
    "    v[\"102\"] = 0.020000*np.tanh((data[\"ps_ind_01\"] + (data[\"loo_ps_ind_04_cat\"] - ((data[\"ps_car_11\"] + data[\"ps_ind_01\"]) * data[\"ps_ind_01\"]))))\n",
    "    v[\"103\"] = 0.019988*np.tanh((((data[\"ps_reg_03\"] * (data[\"loo_ps_ind_05_cat\"] - data[\"ps_ind_01\"])) + ((data[\"ps_car_13\"] + data[\"loo_ps_ind_04_cat\"])/2.0))/2.0))\n",
    "    v[\"104\"] = 0.020000*np.tanh((data[\"loo_ps_car_08_cat\"] + (data[\"loo_ps_car_03_cat\"] * ((data[\"loo_ps_ind_04_cat\"] + data[\"ps_reg_03\"]) + data[\"ps_reg_03\"]))))\n",
    "    v[\"105\"] = 0.020000*np.tanh(((((data[\"loo_ps_ind_05_cat\"] * data[\"loo_ps_ind_17_bin\"]) - data[\"loo_ps_car_07_cat\"]) + data[\"loo_ps_ind_02_cat\"]) - data[\"loo_ps_ind_05_cat\"]))\n",
    "    v[\"106\"] = 0.019996*np.tanh(((data[\"ps_ind_01\"] - (data[\"ps_car_15\"] * data[\"loo_ps_ind_17_bin\"])) + ((data[\"ps_ind_01\"] + data[\"loo_ps_car_01_cat\"])/2.0)))\n",
    "    v[\"107\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_05_cat\"] + (data[\"ps_ind_01\"] + data[\"loo_ps_car_09_cat\"])) * (data[\"loo_ps_ind_17_bin\"] - data[\"ps_reg_01\"])))\n",
    "    v[\"108\"] = 0.020000*np.tanh((data[\"loo_ps_ind_04_cat\"] * (data[\"ps_car_11\"] + ((data[\"loo_ps_car_09_cat\"] + data[\"ps_ind_03\"]) - data[\"loo_ps_ind_06_bin\"]))))\n",
    "    v[\"109\"] = 0.020000*np.tanh(((data[\"missing\"] + ((data[\"loo_ps_ind_05_cat\"] + data[\"ps_reg_02\"]) * (data[\"loo_ps_car_11_cat\"] * data[\"loo_ps_car_05_cat\"])))/2.0))\n",
    "    v[\"110\"] = 0.019996*np.tanh((data[\"ps_reg_03\"] * (((data[\"ps_car_11\"] + data[\"loo_ps_car_09_cat\"])/2.0) - ((data[\"loo_ps_ind_02_cat\"] + data[\"ps_reg_01\"])/2.0))))\n",
    "    v[\"111\"] = 0.019988*np.tanh(((-1.0 + (data[\"loo_ps_ind_02_cat\"] * data[\"loo_ps_ind_02_cat\"])) * (data[\"loo_ps_ind_02_cat\"] + data[\"loo_ps_ind_02_cat\"])))\n",
    "    v[\"112\"] = 0.020000*np.tanh((data[\"loo_ps_ind_05_cat\"] * (data[\"loo_ps_ind_05_cat\"] - (1.526320 - np.tanh((-(data[\"loo_ps_ind_05_cat\"])))))))\n",
    "    v[\"113\"] = 0.020000*np.tanh((((((data[\"loo_ps_ind_16_bin\"] + data[\"loo_ps_car_01_cat\"])/2.0) + data[\"ps_ind_03\"])/2.0) * (data[\"missing\"] - data[\"ps_car_11\"])))\n",
    "    v[\"114\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_05_cat\"] - data[\"ps_reg_01\"]) * (data[\"loo_ps_ind_08_bin\"] + (data[\"ps_ind_01\"] + data[\"loo_ps_car_04_cat\"]))))\n",
    "    v[\"115\"] = 0.020000*np.tanh((-((data[\"ps_reg_02\"] * (data[\"loo_ps_ind_04_cat\"] + (data[\"ps_reg_02\"] * data[\"loo_ps_car_07_cat\"]))))))\n",
    "    v[\"116\"] = 0.020000*np.tanh(((data[\"ps_ind_03\"] + (data[\"ps_ind_03\"] + 3.0)) * (data[\"ps_ind_03\"] + -2.0)))\n",
    "    v[\"117\"] = 0.020000*np.tanh((data[\"loo_ps_car_09_cat\"] - (data[\"loo_ps_car_04_cat\"] * ((data[\"ps_car_11\"] + data[\"ps_ind_15\"]) + 1.871790))))\n",
    "    v[\"118\"] = 0.020000*np.tanh((data[\"ps_reg_03\"] * (data[\"ps_reg_03\"] - ((0.513158 - data[\"loo_ps_ind_07_bin\"]) * data[\"loo_ps_ind_16_bin\"]))))\n",
    "    v[\"119\"] = 0.020000*np.tanh(((((data[\"ps_reg_03\"] + data[\"loo_ps_car_09_cat\"]) * (data[\"loo_ps_ind_05_cat\"] - data[\"ps_reg_01\"])) + data[\"ps_reg_01\"])/2.0))\n",
    "    v[\"120\"] = 0.020000*np.tanh((((((data[\"missing\"] + data[\"loo_ps_car_04_cat\"])/2.0) + data[\"loo_ps_car_03_cat\"])/2.0) * (data[\"loo_ps_ind_02_cat\"] + data[\"loo_ps_car_11_cat\"])))\n",
    "    v[\"121\"] = 0.019988*np.tanh(((data[\"ps_ind_03\"] * (data[\"ps_ind_03\"] - data[\"ps_ind_01\"])) + (data[\"ps_ind_03\"] - data[\"ps_ind_01\"])))\n",
    "    v[\"122\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_02_cat\"] * (data[\"loo_ps_ind_04_cat\"] * (data[\"loo_ps_ind_02_cat\"] - 2.800000))) - data[\"loo_ps_car_10_cat\"]))\n",
    "    v[\"123\"] = 0.020000*np.tanh((data[\"loo_ps_car_05_cat\"] * (data[\"ps_ind_01\"] + ((data[\"loo_ps_ind_07_bin\"] + ((data[\"loo_ps_ind_04_cat\"] + data[\"ps_ind_03\"])/2.0))/2.0))))\n",
    "    v[\"124\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_05_cat\"] * (data[\"ps_reg_02\"] * data[\"ps_reg_01\"])) - (0.452381 + data[\"loo_ps_ind_05_cat\"])))\n",
    "    v[\"125\"] = 0.020000*np.tanh((data[\"loo_ps_car_01_cat\"] * ((data[\"loo_ps_car_01_cat\"] + ((-3.0 * data[\"ps_car_13\"]) - data[\"loo_ps_ind_06_bin\"]))/2.0)))\n",
    "    v[\"126\"] = 0.020000*np.tanh((data[\"loo_ps_ind_05_cat\"] * ((data[\"loo_ps_ind_02_cat\"] + (data[\"ps_reg_03\"] + (data[\"loo_ps_ind_09_bin\"] - 0.965909)))/2.0)))\n",
    "    v[\"127\"] = 0.019988*np.tanh(((((data[\"loo_ps_ind_02_cat\"] - data[\"loo_ps_car_07_cat\"]) + (data[\"loo_ps_car_04_cat\"] * data[\"ps_car_12\"]))/2.0) * 0.485294))\n",
    "    v[\"128\"] = 0.020000*np.tanh((((data[\"loo_ps_car_09_cat\"] * data[\"loo_ps_car_09_cat\"]) - data[\"ps_reg_02\"]) * ((data[\"ps_reg_03\"] + data[\"loo_ps_ind_04_cat\"])/2.0)))\n",
    "    v[\"129\"] = 0.020000*np.tanh((((data[\"ps_reg_03\"] + data[\"ps_reg_03\"]) * np.tanh(data[\"ps_ind_03\"])) - data[\"ps_ind_03\"]))\n",
    "    v[\"130\"] = 0.020000*np.tanh(((data[\"ps_reg_03\"] * data[\"ps_reg_03\"]) * ((data[\"loo_ps_ind_17_bin\"] + data[\"ps_car_13\"])/2.0)))\n",
    "    v[\"131\"] = 0.020000*np.tanh((data[\"ps_reg_01\"] * (0.273684 - ((data[\"loo_ps_car_09_cat\"] + (data[\"ps_reg_03\"] - data[\"ps_reg_01\"]))/2.0))))\n",
    "    v[\"132\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_05_cat\"] + data[\"loo_ps_car_05_cat\"])/2.0) * ((data[\"ps_reg_03\"] * data[\"ps_reg_03\"]) - 0.760563)))\n",
    "    v[\"133\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_02_cat\"] * (-(data[\"ps_ind_03\"]))) * (-(data[\"ps_ind_03\"]))) - data[\"loo_ps_ind_02_cat\"]))\n",
    "    v[\"134\"] = 0.020000*np.tanh((((data[\"loo_ps_car_09_cat\"] + -3.0)/2.0) * ((((data[\"ps_car_11\"] + 1.135800)/2.0) + data[\"loo_ps_ind_02_cat\"])/2.0)))\n",
    "    v[\"135\"] = 0.020000*np.tanh((data[\"loo_ps_car_07_cat\"] * (((2.0 + (data[\"loo_ps_ind_04_cat\"] - data[\"loo_ps_car_07_cat\"]))/2.0) - data[\"ps_car_13\"])))\n",
    "    v[\"136\"] = 0.020000*np.tanh((data[\"loo_ps_ind_05_cat\"] * ((((data[\"loo_ps_ind_04_cat\"] + data[\"ps_reg_03\"])/2.0) + np.tanh(data[\"ps_ind_03\"]))/2.0)))\n",
    "    v[\"137\"] = 0.020000*np.tanh((((data[\"ps_reg_01\"] * (data[\"ps_reg_01\"] - data[\"loo_ps_ind_18_bin\"])) + (data[\"ps_car_11\"] * data[\"loo_ps_car_06_cat\"]))/2.0))\n",
    "    v[\"138\"] = 0.019996*np.tanh((data[\"loo_ps_ind_02_cat\"] * (-3.0 + (data[\"ps_ind_03\"] * (data[\"ps_ind_03\"] + data[\"ps_ind_03\"])))))\n",
    "    v[\"139\"] = 0.020000*np.tanh((data[\"loo_ps_ind_05_cat\"] * ((data[\"loo_ps_car_09_cat\"] * data[\"loo_ps_car_09_cat\"]) + (data[\"ps_car_13\"] * data[\"loo_ps_car_07_cat\"]))))\n",
    "    v[\"140\"] = 0.020000*np.tanh(((-((data[\"ps_ind_03\"] * data[\"loo_ps_ind_02_cat\"]))) - np.tanh((data[\"loo_ps_ind_05_cat\"] * data[\"loo_ps_ind_05_cat\"]))))\n",
    "    v[\"141\"] = 0.020000*np.tanh((data[\"ps_car_13\"] - (data[\"loo_ps_car_04_cat\"] - (data[\"loo_ps_car_07_cat\"] + ((data[\"loo_ps_ind_18_bin\"] + data[\"loo_ps_car_07_cat\"])/2.0)))))\n",
    "    v[\"142\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_02_cat\"] - data[\"loo_ps_car_07_cat\"]) + (data[\"loo_ps_ind_17_bin\"] * (data[\"ps_ind_03\"] - data[\"ps_car_15\"])))/2.0))\n",
    "    v[\"143\"] = 0.020000*np.tanh(((((data[\"loo_ps_ind_02_cat\"] + data[\"ps_car_13\"])/2.0) - 1.135800) * (data[\"loo_ps_ind_02_cat\"] + data[\"ps_car_13\"])))\n",
    "    v[\"144\"] = 0.020000*np.tanh(((data[\"loo_ps_car_09_cat\"] - data[\"ps_car_14\"]) * (data[\"loo_ps_car_02_cat\"] + (data[\"loo_ps_car_05_cat\"] * data[\"loo_ps_car_07_cat\"]))))\n",
    "    v[\"145\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_04_cat\"] - data[\"ps_ind_01\"]) * (data[\"loo_ps_ind_04_cat\"] + (data[\"loo_ps_ind_04_cat\"] - data[\"loo_ps_car_07_cat\"]))))\n",
    "    v[\"146\"] = 0.020000*np.tanh((data[\"loo_ps_ind_05_cat\"] * (data[\"loo_ps_ind_05_cat\"] * ((data[\"loo_ps_ind_05_cat\"] + (-2.0 - 0.452381))/2.0))))\n",
    "    v[\"147\"] = 0.020000*np.tanh((-((((data[\"loo_ps_ind_04_cat\"] + data[\"loo_ps_ind_04_cat\"]) + data[\"ps_car_15\"]) * data[\"ps_reg_02\"]))))\n",
    "    v[\"148\"] = 0.020000*np.tanh((data[\"loo_ps_ind_02_cat\"] * ((data[\"loo_ps_ind_02_cat\"] * (data[\"loo_ps_ind_02_cat\"] + data[\"loo_ps_car_08_cat\"])) + data[\"loo_ps_car_08_cat\"])))\n",
    "    v[\"149\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_04_cat\"] * (data[\"loo_ps_car_03_cat\"] * (data[\"loo_ps_ind_04_cat\"] + data[\"loo_ps_car_04_cat\"]))) - data[\"loo_ps_car_10_cat\"]))\n",
    "    v[\"150\"] = 0.020000*np.tanh(((data[\"missing\"] * ((data[\"ps_ind_01\"] + ((data[\"loo_ps_ind_02_cat\"] + data[\"ps_ind_01\"])/2.0))/2.0)) - data[\"loo_ps_car_10_cat\"]))\n",
    "    v[\"151\"] = 0.020000*np.tanh((((data[\"ps_ind_01\"] * (data[\"ps_ind_01\"] * data[\"loo_ps_car_03_cat\"])) + ((data[\"ps_ind_03\"] + data[\"loo_ps_ind_04_cat\"])/2.0))/2.0))\n",
    "    v[\"152\"] = 0.019965*np.tanh((data[\"ps_reg_01\"] - ((data[\"ps_reg_01\"] + data[\"loo_ps_ind_02_cat\"]) * data[\"ps_ind_03\"])))\n",
    "    v[\"153\"] = 0.020000*np.tanh(((data[\"ps_ind_03\"] * data[\"loo_ps_ind_05_cat\"]) * (-((data[\"ps_ind_01\"] - data[\"ps_reg_01\"])))))\n",
    "    v[\"154\"] = 0.019988*np.tanh((((((data[\"loo_ps_ind_04_cat\"] + -1.0)/2.0) + data[\"ps_ind_01\"])/2.0) - (data[\"ps_car_11\"] * data[\"ps_ind_01\"])))\n",
    "    v[\"155\"] = 0.020000*np.tanh((((data[\"loo_ps_car_07_cat\"] + ((data[\"loo_ps_car_09_cat\"] + data[\"ps_car_12\"])/2.0))/2.0) * (data[\"loo_ps_ind_06_bin\"] * data[\"loo_ps_ind_16_bin\"])))\n",
    "    v[\"156\"] = 0.020000*np.tanh(((data[\"loo_ps_car_01_cat\"] - data[\"loo_ps_car_06_cat\"]) * (data[\"missing\"] + data[\"loo_ps_ind_08_bin\"])))\n",
    "    v[\"157\"] = 0.020000*np.tanh(((data[\"loo_ps_car_07_cat\"] + (data[\"ps_car_12\"] * ((data[\"loo_ps_car_01_cat\"] - data[\"loo_ps_car_07_cat\"]) - data[\"loo_ps_car_07_cat\"])))/2.0))\n",
    "    v[\"158\"] = 0.020000*np.tanh((((data[\"loo_ps_car_01_cat\"] * (data[\"loo_ps_car_01_cat\"] * 0.020833)) + (data[\"ps_car_15\"] * data[\"missing\"]))/2.0))\n",
    "    v[\"159\"] = 0.020000*np.tanh(((0.093750 - data[\"ps_reg_01\"]) * (data[\"loo_ps_car_09_cat\"] * (data[\"ps_car_12\"] + data[\"loo_ps_car_09_cat\"]))))\n",
    "    v[\"160\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_09_bin\"] + (data[\"loo_ps_car_09_cat\"] * (data[\"loo_ps_car_05_cat\"] * data[\"loo_ps_car_04_cat\"])))/2.0) * data[\"loo_ps_car_09_cat\"]))\n",
    "    v[\"161\"] = 0.019977*np.tanh((((-((data[\"loo_ps_car_01_cat\"] * data[\"ps_reg_03\"]))) - data[\"ps_car_12\"]) - data[\"ps_ind_14\"]))\n",
    "    v[\"162\"] = 0.020000*np.tanh(((((data[\"loo_ps_car_01_cat\"] * data[\"loo_ps_car_01_cat\"]) * (data[\"loo_ps_car_01_cat\"] - data[\"loo_ps_car_07_cat\"])) + 0.760563)/2.0))\n",
    "    v[\"163\"] = 0.019988*np.tanh((((data[\"loo_ps_ind_02_cat\"] + ((data[\"ps_car_12\"] - 0.513158) - data[\"loo_ps_ind_06_bin\"]))/2.0) - data[\"loo_ps_car_10_cat\"]))\n",
    "    v[\"164\"] = 0.020000*np.tanh((data[\"ps_car_15\"] + (data[\"loo_ps_ind_02_cat\"] * ((data[\"loo_ps_car_07_cat\"] * data[\"loo_ps_car_07_cat\"]) * data[\"loo_ps_car_01_cat\"]))))\n",
    "    v[\"165\"] = 0.019988*np.tanh((((data[\"loo_ps_ind_04_cat\"] + (data[\"loo_ps_car_07_cat\"] - data[\"ps_car_15\"]))/2.0) + (data[\"loo_ps_ind_09_bin\"] * data[\"loo_ps_car_07_cat\"])))\n",
    "    v[\"166\"] = 0.020000*np.tanh((((data[\"loo_ps_car_10_cat\"] + data[\"loo_ps_car_01_cat\"]) * data[\"loo_ps_ind_17_bin\"]) * (data[\"loo_ps_car_09_cat\"] + data[\"loo_ps_ind_04_cat\"])))\n",
    "    v[\"167\"] = 0.018984*np.tanh((((10.63927078247070312) * (-(data[\"loo_ps_ind_05_cat\"]))) * ((data[\"ps_reg_01\"] + np.tanh(data[\"loo_ps_ind_16_bin\"]))/2.0)))\n",
    "    v[\"168\"] = 0.020000*np.tanh((((data[\"loo_ps_car_07_cat\"] + data[\"ps_ind_03\"])/2.0) * (((data[\"loo_ps_ind_17_bin\"] * data[\"loo_ps_ind_04_cat\"]) + data[\"ps_ind_03\"])/2.0)))\n",
    "    v[\"169\"] = 0.020000*np.tanh(((((-1.0 + (data[\"loo_ps_ind_05_cat\"] - 0.347826))/2.0) + (data[\"ps_ind_15\"] * data[\"ps_reg_01\"]))/2.0))\n",
    "    v[\"170\"] = 0.020000*np.tanh((data[\"loo_ps_ind_16_bin\"] * ((0.100000 * data[\"loo_ps_car_01_cat\"]) - ((data[\"loo_ps_car_10_cat\"] + 0.166667)/2.0))))\n",
    "    v[\"171\"] = 0.020000*np.tanh(((data[\"loo_ps_car_05_cat\"] * data[\"loo_ps_ind_17_bin\"]) * ((data[\"loo_ps_ind_04_cat\"] * data[\"loo_ps_ind_04_cat\"]) - data[\"ps_car_11\"])))\n",
    "    v[\"172\"] = 0.019992*np.tanh((data[\"loo_ps_ind_07_bin\"] * (data[\"ps_reg_03\"] + (-(((data[\"loo_ps_car_01_cat\"] + np.tanh(data[\"loo_ps_car_02_cat\"]))/2.0))))))\n",
    "    v[\"173\"] = 0.020000*np.tanh((((((data[\"loo_ps_ind_04_cat\"] + data[\"loo_ps_ind_05_cat\"])/2.0) + data[\"loo_ps_ind_08_bin\"])/2.0) * (data[\"loo_ps_car_09_cat\"] + data[\"ps_ind_03\"])))\n",
    "    v[\"174\"] = 0.019988*np.tanh(((((data[\"loo_ps_ind_04_cat\"] + data[\"ps_ind_14\"])/2.0) - ((data[\"loo_ps_car_03_cat\"] + 1.526320)/2.0)) * data[\"loo_ps_ind_04_cat\"]))\n",
    "    v[\"175\"] = 0.020000*np.tanh((data[\"loo_ps_ind_17_bin\"] * ((((data[\"loo_ps_ind_02_cat\"] + (-(data[\"loo_ps_ind_12_bin\"])))/2.0) + data[\"loo_ps_car_05_cat\"])/2.0)))\n",
    "    v[\"176\"] = 0.019902*np.tanh(((data[\"ps_reg_03\"] + (data[\"ps_reg_03\"] + np.tanh(data[\"loo_ps_ind_05_cat\"]))) * (-(data[\"loo_ps_car_11_cat\"]))))\n",
    "    v[\"177\"] = 0.019996*np.tanh((((data[\"ps_reg_02\"] + data[\"loo_ps_ind_02_cat\"])/2.0) * (data[\"ps_car_12\"] + (data[\"loo_ps_ind_05_cat\"] * data[\"loo_ps_ind_16_bin\"]))))\n",
    "    v[\"178\"] = 0.020000*np.tanh((data[\"ps_ind_15\"] * (data[\"ps_ind_03\"] * (-(((data[\"ps_reg_01\"] + data[\"ps_ind_01\"])/2.0))))))\n",
    "    v[\"179\"] = 0.020000*np.tanh(((data[\"loo_ps_car_01_cat\"] * data[\"loo_ps_car_11_cat\"]) * (data[\"ps_ind_03\"] + ((data[\"ps_reg_01\"] + data[\"loo_ps_car_01_cat\"])/2.0))))\n",
    "    v[\"180\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_04_cat\"] + (-(data[\"loo_ps_ind_16_bin\"])))/2.0) - (data[\"ps_reg_03\"] * data[\"ps_reg_01\"])))\n",
    "    v[\"181\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_04_cat\"] + (data[\"loo_ps_car_04_cat\"] * (0.583333 - (data[\"ps_ind_03\"] * data[\"ps_ind_03\"]))))/2.0))\n",
    "    v[\"182\"] = 0.019992*np.tanh(((data[\"ps_reg_03\"] * data[\"ps_reg_03\"]) + np.tanh((data[\"ps_ind_03\"] * data[\"loo_ps_ind_04_cat\"]))))\n",
    "    v[\"183\"] = 0.019961*np.tanh(((data[\"ps_ind_15\"] * (np.tanh((-(data[\"loo_ps_car_11_cat\"]))) - data[\"loo_ps_car_09_cat\"])) * data[\"loo_ps_car_11_cat\"]))\n",
    "    v[\"184\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_16_bin\"] + data[\"loo_ps_ind_07_bin\"])/2.0) * ((data[\"missing\"] + (-(data[\"ps_reg_01\"])))/2.0)))\n",
    "    v[\"185\"] = 0.019949*np.tanh((data[\"loo_ps_car_04_cat\"] * ((data[\"ps_reg_03\"] + (data[\"loo_ps_ind_02_cat\"] - data[\"loo_ps_car_04_cat\"]))/2.0)))\n",
    "    v[\"186\"] = 0.020000*np.tanh((((data[\"ps_car_12\"] + data[\"loo_ps_car_03_cat\"])/2.0) * (((data[\"ps_car_12\"] + data[\"loo_ps_ind_05_cat\"])/2.0) * data[\"loo_ps_car_04_cat\"])))\n",
    "    v[\"187\"] = 0.020000*np.tanh((np.tanh(data[\"loo_ps_ind_17_bin\"]) * (data[\"loo_ps_ind_05_cat\"] * ((data[\"loo_ps_ind_04_cat\"] + (-(data[\"ps_ind_15\"])))/2.0))))\n",
    "    v[\"188\"] = 0.020000*np.tanh((((data[\"ps_ind_03\"] + data[\"loo_ps_ind_12_bin\"])/2.0) * (data[\"ps_ind_03\"] - np.tanh(data[\"ps_ind_03\"]))))\n",
    "    v[\"189\"] = 0.020000*np.tanh(((((data[\"loo_ps_car_11_cat\"] + data[\"loo_ps_ind_04_cat\"])/2.0) * data[\"loo_ps_ind_17_bin\"]) * (data[\"loo_ps_ind_02_cat\"] - data[\"loo_ps_car_07_cat\"])))\n",
    "    v[\"190\"] = 0.020000*np.tanh(((data[\"ps_ind_01\"] * data[\"ps_ind_01\"]) * (((data[\"loo_ps_car_01_cat\"] + data[\"ps_ind_03\"])/2.0) * data[\"loo_ps_ind_17_bin\"])))\n",
    "    v[\"191\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_02_cat\"] + (-(data[\"ps_car_15\"])))/2.0) * data[\"ps_car_15\"]))\n",
    "    v[\"192\"] = 0.020000*np.tanh(((0.166667 + (((data[\"ps_car_12\"] + data[\"loo_ps_ind_17_bin\"])/2.0) * (data[\"loo_ps_ind_04_cat\"] * data[\"loo_ps_ind_04_cat\"])))/2.0))\n",
    "    v[\"193\"] = 0.019980*np.tanh((data[\"loo_ps_car_02_cat\"] * (((data[\"loo_ps_ind_13_bin\"] + data[\"loo_ps_car_02_cat\"])/2.0) - (data[\"ps_reg_02\"] + data[\"loo_ps_car_06_cat\"]))))\n",
    "    v[\"194\"] = 0.019895*np.tanh(((data[\"ps_reg_03\"] * (-((data[\"ps_ind_03\"] * data[\"ps_ind_15\"])))) * data[\"loo_ps_car_01_cat\"]))\n",
    "    v[\"195\"] = 0.020000*np.tanh((-(((((data[\"loo_ps_ind_04_cat\"] + data[\"ps_ind_01\"])/2.0) * data[\"ps_ind_01\"]) * data[\"ps_ind_03\"]))))\n",
    "    v[\"196\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_05_cat\"] * (-(data[\"ps_car_11\"]))) * (data[\"loo_ps_car_02_cat\"] + data[\"loo_ps_car_01_cat\"])))\n",
    "    v[\"197\"] = 0.020000*np.tanh((np.tanh(data[\"loo_ps_car_01_cat\"]) * (data[\"ps_ind_14\"] + (-((data[\"loo_ps_ind_18_bin\"] * data[\"loo_ps_car_09_cat\"]))))))\n",
    "    v[\"198\"] = 0.018046*np.tanh((19.500000 * (0.583333 - (6.846150 * data[\"loo_ps_car_10_cat\"]))))\n",
    "    v[\"199\"] = 0.019988*np.tanh((-2.0 + (((data[\"loo_ps_car_10_cat\"] + 0.965909) + data[\"ps_car_11\"]) * data[\"ps_car_11\"])))\n",
    "    v[\"200\"] = 0.020000*np.tanh(((data[\"ps_ind_03\"] + ((data[\"ps_ind_03\"] * data[\"ps_ind_01\"]) * (data[\"ps_car_13\"] - data[\"ps_ind_01\"])))/2.0))\n",
    "    v[\"201\"] = 0.019984*np.tanh((data[\"ps_reg_02\"] * ((((-(data[\"loo_ps_car_01_cat\"])) + data[\"loo_ps_ind_05_cat\"])/2.0) * data[\"loo_ps_ind_17_bin\"])))\n",
    "    v[\"202\"] = 0.020000*np.tanh((data[\"loo_ps_ind_05_cat\"] * ((((0.965909 - data[\"loo_ps_car_01_cat\"]) + data[\"loo_ps_ind_02_cat\"])/2.0) * data[\"ps_ind_01\"])))\n",
    "    v[\"203\"] = 0.020000*np.tanh((data[\"ps_reg_03\"] * ((data[\"ps_ind_15\"] * (data[\"ps_ind_15\"] + data[\"loo_ps_ind_09_bin\"])) + data[\"ps_ind_15\"])))\n",
    "    v[\"204\"] = 0.020000*np.tanh((((data[\"loo_ps_car_10_cat\"] + data[\"loo_ps_car_03_cat\"])/2.0) * (-(((data[\"loo_ps_ind_18_bin\"] + data[\"ps_car_15\"])/2.0)))))\n",
    "    v[\"205\"] = 0.020000*np.tanh((((-(np.tanh(data[\"loo_ps_ind_02_cat\"]))) + (((data[\"ps_ind_03\"] + data[\"loo_ps_ind_02_cat\"])/2.0) * data[\"loo_ps_ind_16_bin\"]))/2.0))\n",
    "    v[\"206\"] = 0.020000*np.tanh(np.tanh((19.500000 * np.tanh((data[\"ps_ind_14\"] + (0.965909 - data[\"ps_car_15\"]))))))\n",
    "    v[\"207\"] = 0.019945*np.tanh(((19.500000 - (data[\"loo_ps_ind_02_cat\"] * 19.500000)) * (data[\"ps_reg_02\"] - 2.800000)))\n",
    "    v[\"208\"] = 0.019969*np.tanh((((data[\"ps_reg_02\"] * (data[\"loo_ps_car_01_cat\"] * data[\"loo_ps_ind_12_bin\"])) + (data[\"loo_ps_car_11_cat\"] * data[\"loo_ps_car_08_cat\"]))/2.0))\n",
    "    v[\"209\"] = 0.019996*np.tanh((((data[\"ps_ind_03\"] + data[\"loo_ps_ind_12_bin\"])/2.0) * ((data[\"ps_ind_03\"] + (data[\"missing\"] - data[\"loo_ps_ind_02_cat\"]))/2.0)))\n",
    "    v[\"210\"] = 0.020000*np.tanh((data[\"loo_ps_ind_17_bin\"] * (data[\"loo_ps_ind_04_cat\"] * (data[\"ps_reg_03\"] * (-(data[\"loo_ps_car_07_cat\"]))))))\n",
    "    v[\"211\"] = 0.020000*np.tanh((data[\"loo_ps_ind_05_cat\"] * (data[\"ps_reg_03\"] + ((data[\"loo_ps_ind_02_cat\"] * data[\"loo_ps_ind_09_bin\"]) - 0.600000))))\n",
    "    v[\"212\"] = 0.017421*np.tanh(np.tanh(((-((data[\"ps_car_11\"] + data[\"loo_ps_ind_08_bin\"]))) * data[\"loo_ps_ind_05_cat\"])))\n",
    "    v[\"213\"] = 0.019305*np.tanh((((data[\"loo_ps_ind_02_cat\"] * data[\"loo_ps_car_04_cat\"]) - ((data[\"missing\"] + data[\"loo_ps_car_04_cat\"])/2.0)) - data[\"loo_ps_ind_02_cat\"]))\n",
    "    v[\"214\"] = 0.019992*np.tanh((data[\"ps_car_12\"] * (((-(data[\"ps_car_11\"])) + (data[\"ps_reg_01\"] + data[\"loo_ps_ind_04_cat\"]))/2.0)))\n",
    "    v[\"215\"] = 0.019879*np.tanh((data[\"loo_ps_ind_05_cat\"] * (data[\"ps_car_13\"] * ((data[\"ps_car_14\"] * data[\"ps_ind_15\"]) + data[\"loo_ps_ind_05_cat\"]))))\n",
    "    v[\"216\"] = 0.019984*np.tanh(((data[\"loo_ps_car_01_cat\"] * data[\"loo_ps_ind_17_bin\"]) * (data[\"loo_ps_ind_02_cat\"] - data[\"loo_ps_ind_17_bin\"])))\n",
    "    v[\"217\"] = 0.020000*np.tanh((((data[\"ps_reg_03\"] * data[\"loo_ps_car_08_cat\"]) - np.tanh(np.tanh(data[\"loo_ps_car_11_cat\"]))) * data[\"loo_ps_ind_05_cat\"]))\n",
    "    v[\"218\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_05_cat\"] + (0.273684 - data[\"loo_ps_ind_12_bin\"])) * (data[\"ps_reg_02\"] * data[\"loo_ps_car_07_cat\"])))\n",
    "    v[\"219\"] = 0.020000*np.tanh(((((data[\"loo_ps_ind_16_bin\"] + (data[\"loo_ps_ind_06_bin\"] * 0.166667))/2.0) * data[\"loo_ps_ind_06_bin\"]) * data[\"loo_ps_ind_05_cat\"]))\n",
    "    v[\"220\"] = 0.020000*np.tanh(((data[\"ps_ind_15\"] * data[\"ps_car_15\"]) * (-(data[\"loo_ps_ind_17_bin\"]))))\n",
    "    v[\"221\"] = 0.020000*np.tanh(((((data[\"loo_ps_car_02_cat\"] * data[\"ps_ind_03\"]) + (data[\"loo_ps_car_02_cat\"] * data[\"ps_reg_01\"]))/2.0) * data[\"ps_ind_01\"]))\n",
    "    v[\"222\"] = 0.020000*np.tanh((data[\"loo_ps_ind_02_cat\"] * (data[\"loo_ps_ind_18_bin\"] * (data[\"loo_ps_ind_07_bin\"] - (data[\"loo_ps_ind_04_cat\"] * data[\"loo_ps_ind_16_bin\"])))))\n",
    "    v[\"223\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_12_bin\"] * data[\"ps_car_11\"]) + (data[\"loo_ps_ind_04_cat\"] * (data[\"ps_reg_01\"] * data[\"loo_ps_car_08_cat\"]))))\n",
    "    v[\"224\"] = 0.019988*np.tanh((data[\"ps_car_14\"] * ((data[\"ps_car_14\"] + ((data[\"loo_ps_ind_05_cat\"] * data[\"loo_ps_ind_05_cat\"]) * data[\"loo_ps_car_01_cat\"]))/2.0)))\n",
    "    v[\"225\"] = 0.019090*np.tanh((data[\"ps_ind_15\"] * (data[\"loo_ps_ind_07_bin\"] - (-((data[\"loo_ps_car_06_cat\"] * data[\"ps_ind_15\"]))))))\n",
    "    v[\"226\"] = 0.015734*np.tanh((data[\"ps_ind_15\"] - (6.846150 * ((data[\"loo_ps_car_11_cat\"] + data[\"loo_ps_car_06_cat\"]) + data[\"loo_ps_car_06_cat\"]))))\n",
    "    v[\"227\"] = 0.020000*np.tanh(((data[\"ps_car_12\"] - data[\"loo_ps_car_06_cat\"]) * (data[\"loo_ps_ind_02_cat\"] * (-(data[\"loo_ps_car_08_cat\"])))))\n",
    "    v[\"228\"] = 0.019996*np.tanh(((data[\"loo_ps_ind_09_bin\"] * data[\"ps_car_12\"]) - np.tanh(((data[\"ps_reg_02\"] + data[\"ps_car_12\"])/2.0))))\n",
    "    v[\"229\"] = 0.019219*np.tanh((data[\"ps_ind_01\"] * ((data[\"loo_ps_ind_17_bin\"] * data[\"loo_ps_car_06_cat\"]) - np.tanh(data[\"loo_ps_ind_17_bin\"]))))\n",
    "    v[\"230\"] = 0.019996*np.tanh((data[\"loo_ps_ind_07_bin\"] * (data[\"ps_car_13\"] * (data[\"loo_ps_car_11_cat\"] - np.tanh(2.0)))))\n",
    "    v[\"231\"] = 0.020000*np.tanh((data[\"loo_ps_car_11_cat\"] * ((data[\"ps_ind_14\"] * data[\"ps_ind_15\"]) * data[\"ps_car_12\"])))\n",
    "    v[\"232\"] = 0.019816*np.tanh(((np.tanh(data[\"loo_ps_ind_17_bin\"]) * data[\"missing\"]) * (np.tanh(data[\"ps_car_15\"]) - data[\"loo_ps_car_02_cat\"])))\n",
    "    v[\"233\"] = 0.020000*np.tanh((((data[\"loo_ps_car_01_cat\"] - data[\"ps_reg_01\"]) * data[\"loo_ps_car_10_cat\"]) * (data[\"ps_ind_03\"] + data[\"loo_ps_ind_17_bin\"])))\n",
    "    v[\"234\"] = 0.017378*np.tanh(((data[\"ps_ind_01\"] * data[\"loo_ps_car_04_cat\"]) * (data[\"loo_ps_car_01_cat\"] + (data[\"ps_car_12\"] * data[\"loo_ps_car_04_cat\"]))))\n",
    "    v[\"235\"] = 0.020000*np.tanh((data[\"ps_reg_03\"] * ((((data[\"ps_reg_03\"] + data[\"loo_ps_ind_05_cat\"])/2.0) - data[\"loo_ps_ind_02_cat\"]) - data[\"ps_reg_01\"])))\n",
    "    v[\"236\"] = 0.020000*np.tanh((data[\"ps_ind_01\"] * (((data[\"loo_ps_car_09_cat\"] + data[\"loo_ps_ind_04_cat\"])/2.0) * ((data[\"loo_ps_ind_05_cat\"] + data[\"loo_ps_ind_05_cat\"])/2.0))))\n",
    "    v[\"237\"] = 0.019996*np.tanh((data[\"ps_ind_01\"] * ((data[\"loo_ps_ind_02_cat\"] + (data[\"ps_reg_01\"] + (-(data[\"loo_ps_car_11_cat\"]))))/2.0)))\n",
    "    v[\"238\"] = 0.019941*np.tanh((-((data[\"loo_ps_car_08_cat\"] * (data[\"loo_ps_car_02_cat\"] - ((data[\"loo_ps_car_04_cat\"] + (-(data[\"loo_ps_ind_18_bin\"])))/2.0))))))\n",
    "    v[\"239\"] = 0.020000*np.tanh((data[\"loo_ps_ind_02_cat\"] * (((data[\"loo_ps_ind_17_bin\"] * (-(np.tanh(data[\"loo_ps_car_08_cat\"])))) + data[\"ps_reg_02\"])/2.0)))\n",
    "    v[\"240\"] = 0.020000*np.tanh(((np.tanh((-(data[\"loo_ps_ind_08_bin\"]))) + (data[\"ps_reg_03\"] * (data[\"loo_ps_ind_08_bin\"] * data[\"ps_reg_01\"])))/2.0))\n",
    "    v[\"241\"] = 0.019969*np.tanh((((data[\"loo_ps_car_02_cat\"] + data[\"ps_car_15\"])/2.0) * ((-(data[\"loo_ps_ind_17_bin\"])) - data[\"loo_ps_car_10_cat\"])))\n",
    "    v[\"242\"] = 0.019371*np.tanh(((data[\"loo_ps_car_03_cat\"] * (data[\"ps_ind_14\"] - data[\"loo_ps_ind_05_cat\"])) * (data[\"ps_car_11\"] + data[\"ps_car_11\"])))\n",
    "    v[\"243\"] = 0.020000*np.tanh((((data[\"loo_ps_car_10_cat\"] * (data[\"loo_ps_ind_17_bin\"] * data[\"loo_ps_ind_04_cat\"])) + (-(np.tanh(data[\"loo_ps_ind_04_cat\"]))))/2.0))\n",
    "    v[\"244\"] = 0.020000*np.tanh((np.tanh((19.500000 * ((0.452381 + data[\"loo_ps_ind_18_bin\"])/2.0))) * data[\"loo_ps_ind_05_cat\"]))\n",
    "    v[\"245\"] = 0.019996*np.tanh((((data[\"loo_ps_car_01_cat\"] * data[\"loo_ps_ind_02_cat\"]) * (data[\"loo_ps_car_08_cat\"] * data[\"ps_reg_01\"])) * (4.34056949615478516)))\n",
    "    v[\"246\"] = 0.019988*np.tanh(((data[\"loo_ps_car_01_cat\"] + data[\"loo_ps_ind_16_bin\"]) * (data[\"loo_ps_ind_02_cat\"] - data[\"loo_ps_ind_05_cat\"])))\n",
    "    v[\"247\"] = 0.020000*np.tanh((data[\"ps_car_14\"] * (((data[\"loo_ps_car_07_cat\"] * data[\"ps_ind_15\"]) + ((data[\"ps_car_13\"] + data[\"loo_ps_ind_13_bin\"])/2.0))/2.0)))\n",
    "    v[\"248\"] = 0.019969*np.tanh((data[\"ps_reg_02\"] * ((data[\"ps_ind_15\"] + data[\"ps_ind_14\"]) * (data[\"loo_ps_ind_08_bin\"] * data[\"loo_ps_car_08_cat\"]))))\n",
    "    v[\"249\"] = 0.019984*np.tanh((data[\"loo_ps_ind_02_cat\"] * (data[\"missing\"] - ((data[\"loo_ps_ind_02_cat\"] * data[\"loo_ps_ind_02_cat\"]) * data[\"loo_ps_car_08_cat\"]))))\n",
    "    v[\"250\"] = 0.020000*np.tanh((((((data[\"loo_ps_car_03_cat\"] + data[\"ps_car_15\"])/2.0) + data[\"loo_ps_ind_06_bin\"])/2.0) * (data[\"ps_reg_02\"] * data[\"ps_car_15\"])))\n",
    "    v[\"251\"] = 0.020000*np.tanh(((data[\"ps_car_11\"] * ((data[\"loo_ps_car_06_cat\"] + (data[\"ps_reg_02\"] * data[\"loo_ps_ind_12_bin\"]))/2.0)) - data[\"loo_ps_car_10_cat\"]))\n",
    "    v[\"252\"] = 0.019453*np.tanh((data[\"ps_ind_03\"] * ((0.273684 * data[\"loo_ps_ind_05_cat\"]) + (0.020833 - data[\"ps_car_14\"]))))\n",
    "    v[\"253\"] = 0.020000*np.tanh((data[\"ps_car_13\"] * ((data[\"ps_car_13\"] * (data[\"loo_ps_ind_12_bin\"] * data[\"ps_ind_15\"])) + data[\"ps_ind_14\"])))\n",
    "    v[\"254\"] = 0.020000*np.tanh((-((((data[\"loo_ps_car_10_cat\"] * (data[\"ps_car_13\"] + data[\"ps_car_13\"])) + np.tanh(data[\"loo_ps_ind_05_cat\"]))/2.0))))\n",
    "    v[\"255\"] = 0.019961*np.tanh(((((data[\"ps_ind_03\"] + data[\"loo_ps_ind_07_bin\"])/2.0) * data[\"ps_ind_14\"]) - (data[\"ps_reg_02\"] * data[\"loo_ps_car_10_cat\"])))\n",
    "    v[\"256\"] = 0.020000*np.tanh((data[\"loo_ps_ind_02_cat\"] * ((data[\"loo_ps_car_11_cat\"] * (data[\"loo_ps_ind_04_cat\"] - 0.583333)) - data[\"loo_ps_ind_08_bin\"])))\n",
    "    v[\"257\"] = 0.019664*np.tanh((data[\"loo_ps_car_07_cat\"] * (data[\"loo_ps_ind_09_bin\"] - data[\"loo_ps_car_01_cat\"])))\n",
    "    v[\"258\"] = 0.020000*np.tanh(((-(data[\"loo_ps_ind_17_bin\"])) * np.tanh((data[\"loo_ps_car_11_cat\"] * (data[\"loo_ps_car_08_cat\"] + data[\"ps_ind_15\"])))))\n",
    "    v[\"259\"] = 0.019644*np.tanh(((data[\"ps_ind_01\"] * (-(data[\"ps_ind_03\"]))) * (data[\"loo_ps_ind_04_cat\"] + data[\"loo_ps_ind_04_cat\"])))\n",
    "    v[\"260\"] = 0.020000*np.tanh((data[\"ps_reg_03\"] * (-((data[\"ps_car_15\"] * (data[\"loo_ps_car_07_cat\"] * data[\"loo_ps_ind_17_bin\"]))))))\n",
    "    v[\"261\"] = 0.020000*np.tanh((data[\"ps_car_12\"] * ((data[\"ps_car_12\"] * (data[\"ps_ind_15\"] * data[\"loo_ps_ind_04_cat\"])) + data[\"ps_ind_15\"])))\n",
    "    v[\"262\"] = 0.018953*np.tanh(((data[\"ps_ind_15\"] + (data[\"ps_ind_15\"] * ((data[\"loo_ps_ind_08_bin\"] - data[\"loo_ps_car_04_cat\"]) - data[\"loo_ps_car_03_cat\"])))/2.0))\n",
    "    v[\"263\"] = 0.020000*np.tanh((0.166667 * (((data[\"ps_car_13\"] + data[\"loo_ps_ind_04_cat\"])/2.0) - (data[\"ps_car_13\"] * data[\"loo_ps_car_03_cat\"]))))\n",
    "    v[\"264\"] = 0.020000*np.tanh((data[\"loo_ps_ind_02_cat\"] * ((data[\"loo_ps_ind_09_bin\"] + ((data[\"loo_ps_ind_02_cat\"] * data[\"loo_ps_ind_02_cat\"]) + data[\"loo_ps_ind_10_bin\"]))/2.0)))\n",
    "    v[\"265\"] = 0.019992*np.tanh((data[\"ps_ind_14\"] * ((data[\"loo_ps_car_03_cat\"] * (data[\"loo_ps_ind_07_bin\"] + data[\"ps_ind_15\"])) * data[\"loo_ps_car_11_cat\"])))\n",
    "    v[\"266\"] = 0.019988*np.tanh((np.tanh(np.tanh(data[\"loo_ps_car_07_cat\"])) + (np.tanh(data[\"ps_ind_01\"]) * (-(data[\"ps_ind_14\"])))))\n",
    "    v[\"267\"] = 0.020000*np.tanh((np.tanh(np.tanh(data[\"ps_ind_01\"])) * ((data[\"ps_car_14\"] + (data[\"loo_ps_ind_04_cat\"] - data[\"loo_ps_car_01_cat\"]))/2.0)))\n",
    "    v[\"268\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_02_cat\"] * (data[\"ps_ind_03\"] * data[\"ps_ind_03\"])) - data[\"loo_ps_ind_02_cat\"]) - data[\"loo_ps_ind_02_cat\"]))\n",
    "    v[\"269\"] = 0.018969*np.tanh((data[\"loo_ps_ind_05_cat\"] * (data[\"loo_ps_car_07_cat\"] * (data[\"ps_reg_02\"] + data[\"ps_car_12\"]))))\n",
    "    v[\"270\"] = 0.019996*np.tanh((data[\"ps_car_13\"] * (data[\"loo_ps_ind_12_bin\"] * (1.135800 + (data[\"ps_ind_15\"] + data[\"loo_ps_ind_11_bin\"])))))\n",
    "    v[\"271\"] = 0.019996*np.tanh((-((data[\"loo_ps_ind_05_cat\"] * ((data[\"loo_ps_car_07_cat\"] * (-(data[\"loo_ps_car_09_cat\"]))) + data[\"loo_ps_car_07_cat\"])))))\n",
    "    v[\"272\"] = 0.020000*np.tanh((data[\"ps_car_11\"] * ((-(data[\"ps_reg_03\"])) * (data[\"loo_ps_ind_05_cat\"] * np.tanh(-1.0)))))\n",
    "    v[\"273\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_09_bin\"] + data[\"loo_ps_ind_17_bin\"])/2.0) * ((data[\"loo_ps_ind_18_bin\"] + (data[\"ps_reg_02\"] - data[\"ps_ind_14\"]))/2.0)))\n",
    "    v[\"274\"] = 0.020000*np.tanh((data[\"ps_ind_01\"] * (((data[\"ps_ind_01\"] * data[\"loo_ps_car_03_cat\"]) + data[\"loo_ps_ind_02_cat\"])/2.0)))\n",
    "    v[\"275\"] = 0.020000*np.tanh((data[\"loo_ps_ind_02_cat\"] * (data[\"ps_ind_01\"] * (data[\"loo_ps_ind_06_bin\"] * (-(data[\"ps_ind_03\"]))))))\n",
    "    v[\"276\"] = 0.019949*np.tanh(((np.tanh((((data[\"loo_ps_ind_12_bin\"] + data[\"ps_reg_03\"])/2.0) * 19.500000)) + (-(data[\"ps_reg_03\"])))/2.0))\n",
    "    v[\"277\"] = 0.016070*np.tanh(((data[\"ps_car_15\"] + data[\"loo_ps_car_03_cat\"]) * (-((data[\"ps_reg_03\"] + data[\"loo_ps_ind_05_cat\"])))))\n",
    "    v[\"278\"] = 0.019930*np.tanh(((data[\"loo_ps_ind_02_cat\"] + ((data[\"loo_ps_car_05_cat\"] * data[\"loo_ps_ind_05_cat\"]) - data[\"loo_ps_ind_05_cat\"]))/2.0))\n",
    "    v[\"279\"] = 0.017035*np.tanh((((data[\"loo_ps_car_09_cat\"] * data[\"ps_reg_03\"]) + data[\"loo_ps_ind_02_cat\"]) * data[\"loo_ps_ind_05_cat\"]))\n",
    "    v[\"280\"] = 0.019965*np.tanh(((data[\"ps_reg_01\"] + data[\"loo_ps_ind_07_bin\"]) * ((data[\"loo_ps_ind_05_cat\"] + ((data[\"loo_ps_car_11_cat\"] + data[\"loo_ps_car_08_cat\"])/2.0))/2.0)))\n",
    "    v[\"281\"] = 0.020000*np.tanh((-(((np.tanh(((data[\"loo_ps_car_01_cat\"] + data[\"loo_ps_car_05_cat\"])/2.0)) + (data[\"loo_ps_car_10_cat\"] * data[\"ps_car_15\"]))/2.0))))\n",
    "    v[\"282\"] = 0.019992*np.tanh(((data[\"ps_ind_03\"] - data[\"loo_ps_ind_18_bin\"]) * (((data[\"ps_ind_03\"] + data[\"ps_car_12\"])/2.0) * data[\"loo_ps_car_02_cat\"])))\n",
    "    v[\"283\"] = 0.019945*np.tanh((data[\"loo_ps_ind_04_cat\"] * (-((data[\"ps_reg_02\"] * (data[\"loo_ps_car_07_cat\"] * data[\"loo_ps_ind_17_bin\"]))))))\n",
    "    v[\"284\"] = 0.020000*np.tanh(((-((3.642860 + (-(data[\"loo_ps_car_09_cat\"]))))) * (data[\"ps_ind_01\"] * data[\"loo_ps_car_09_cat\"])))\n",
    "    v[\"285\"] = 0.018918*np.tanh((data[\"ps_ind_01\"] * (data[\"ps_ind_01\"] - (data[\"ps_ind_01\"] * data[\"ps_ind_01\"]))))\n",
    "    v[\"286\"] = 0.018738*np.tanh((((data[\"ps_ind_03\"] + data[\"ps_ind_15\"])/2.0) - (data[\"ps_ind_15\"] * (data[\"ps_ind_15\"] * data[\"ps_ind_03\"]))))\n",
    "    v[\"287\"] = 0.019957*np.tanh(((data[\"loo_ps_car_08_cat\"] * data[\"loo_ps_ind_08_bin\"]) * ((data[\"loo_ps_car_07_cat\"] + data[\"missing\"])/2.0)))\n",
    "    v[\"288\"] = 0.019598*np.tanh(((data[\"loo_ps_ind_09_bin\"] * ((data[\"ps_ind_01\"] + (-(data[\"loo_ps_car_05_cat\"])))/2.0)) + data[\"loo_ps_ind_13_bin\"]))\n",
    "    v[\"289\"] = 0.020000*np.tanh((((data[\"loo_ps_car_01_cat\"] * data[\"ps_ind_15\"]) + data[\"ps_car_11\"]) * data[\"loo_ps_ind_12_bin\"]))\n",
    "    v[\"290\"] = 0.020000*np.tanh((((data[\"loo_ps_ind_02_cat\"] - (data[\"ps_car_11\"] * data[\"loo_ps_car_09_cat\"])) * data[\"loo_ps_ind_17_bin\"]) * data[\"loo_ps_car_10_cat\"]))\n",
    "    v[\"291\"] = 0.019301*np.tanh((data[\"loo_ps_car_04_cat\"] * ((np.tanh(data[\"loo_ps_car_04_cat\"]) - data[\"ps_ind_03\"]) * data[\"ps_ind_03\"])))\n",
    "    v[\"292\"] = 0.020000*np.tanh(((data[\"ps_reg_03\"] - data[\"ps_car_11\"]) * ((np.tanh(data[\"loo_ps_car_04_cat\"]) + (-(data[\"ps_car_14\"])))/2.0)))\n",
    "    v[\"293\"] = 0.019086*np.tanh((((data[\"ps_ind_03\"] * data[\"loo_ps_ind_12_bin\"]) + ((data[\"loo_ps_ind_12_bin\"] - data[\"loo_ps_car_06_cat\"]) * data[\"ps_reg_03\"]))/2.0))\n",
    "    v[\"294\"] = 0.020000*np.tanh((data[\"loo_ps_ind_12_bin\"] - (data[\"loo_ps_ind_18_bin\"] * (data[\"loo_ps_ind_04_cat\"] * (-(data[\"ps_reg_03\"]))))))\n",
    "    v[\"295\"] = 0.019988*np.tanh(((((data[\"ps_reg_03\"] * data[\"ps_car_12\"]) + data[\"loo_ps_ind_02_cat\"])/2.0) * np.tanh(data[\"loo_ps_car_04_cat\"])))\n",
    "    v[\"296\"] = 0.019898*np.tanh((data[\"loo_ps_car_07_cat\"] * (-((((data[\"ps_car_11\"] * (-(data[\"loo_ps_car_08_cat\"]))) + data[\"loo_ps_car_09_cat\"])/2.0)))))\n",
    "    v[\"297\"] = 0.019973*np.tanh(((data[\"loo_ps_ind_02_cat\"] * (data[\"loo_ps_ind_16_bin\"] + (-(data[\"loo_ps_car_05_cat\"])))) * (-(data[\"loo_ps_car_08_cat\"]))))\n",
    "    v[\"298\"] = 0.019980*np.tanh((((data[\"loo_ps_ind_18_bin\"] * (data[\"loo_ps_ind_04_cat\"] * data[\"loo_ps_ind_16_bin\"])) - data[\"ps_car_14\"]) * data[\"ps_ind_14\"]))\n",
    "    v[\"299\"] = 0.016964*np.tanh((((-(0.347826)) + np.tanh((data[\"loo_ps_car_06_cat\"] - data[\"ps_reg_01\"])))/2.0))\n",
    "    v[\"300\"] = 0.020000*np.tanh(((data[\"ps_ind_15\"] * data[\"ps_car_15\"]) * ((data[\"loo_ps_ind_12_bin\"] + (-(data[\"ps_car_15\"])))/2.0)))\n",
    "    v[\"301\"] = 0.019957*np.tanh(((data[\"ps_car_14\"] * data[\"loo_ps_ind_04_cat\"]) * (data[\"ps_ind_01\"] + (data[\"ps_car_14\"] * data[\"loo_ps_car_08_cat\"]))))\n",
    "    v[\"302\"] = 0.020000*np.tanh((data[\"ps_ind_14\"] * (data[\"ps_car_11\"] * (data[\"ps_car_12\"] + (data[\"ps_ind_03\"] * data[\"ps_car_12\"])))))\n",
    "    v[\"303\"] = 0.020000*np.tanh((data[\"ps_reg_01\"] * (data[\"loo_ps_car_01_cat\"] * ((data[\"loo_ps_car_01_cat\"] + (data[\"ps_ind_03\"] * data[\"ps_reg_02\"]))/2.0))))\n",
    "    v[\"304\"] = 0.019594*np.tanh(((data[\"loo_ps_ind_04_cat\"] * data[\"loo_ps_ind_02_cat\"]) * (data[\"loo_ps_car_06_cat\"] * (0.347826 + 2.800000))))\n",
    "    v[\"305\"] = 0.019992*np.tanh((data[\"ps_reg_01\"] * ((data[\"loo_ps_car_02_cat\"] - data[\"loo_ps_car_04_cat\"]) * data[\"loo_ps_ind_05_cat\"])))\n",
    "    v[\"306\"] = 0.020000*np.tanh(np.tanh(((((data[\"loo_ps_ind_09_bin\"] * data[\"loo_ps_ind_05_cat\"]) + data[\"ps_ind_03\"])/2.0) * (-(data[\"ps_reg_01\"])))))\n",
    "    v[\"307\"] = 0.018308*np.tanh((-((19.500000 * np.tanh((-1.0 - (data[\"loo_ps_ind_11_bin\"] * 19.500000)))))))\n",
    "    v[\"308\"] = 0.019754*np.tanh(((1.0 + data[\"ps_reg_02\"]) * ((data[\"ps_reg_02\"] - 3.0) * 3.0)))\n",
    "    v[\"309\"] = 0.019265*np.tanh((data[\"loo_ps_ind_04_cat\"] * ((data[\"ps_ind_01\"] * (data[\"ps_reg_01\"] * data[\"ps_ind_01\"])) * data[\"ps_ind_01\"])))\n",
    "    v[\"310\"] = 0.019879*np.tanh((((data[\"ps_reg_03\"] + data[\"ps_ind_03\"])/2.0) * np.tanh((data[\"ps_reg_03\"] * data[\"ps_ind_03\"]))))\n",
    "    v[\"311\"] = 0.020000*np.tanh(((data[\"ps_reg_02\"] * (data[\"loo_ps_ind_11_bin\"] - (data[\"ps_car_14\"] * data[\"loo_ps_car_04_cat\"]))) * data[\"ps_reg_01\"]))\n",
    "    v[\"312\"] = 0.019965*np.tanh((data[\"ps_reg_03\"] * ((data[\"ps_ind_15\"] + ((data[\"ps_ind_15\"] * data[\"loo_ps_ind_09_bin\"]) - data[\"loo_ps_ind_08_bin\"]))/2.0)))\n",
    "    v[\"313\"] = 0.020000*np.tanh((data[\"loo_ps_ind_06_bin\"] * ((data[\"loo_ps_ind_02_cat\"] + (data[\"ps_car_11\"] * data[\"loo_ps_car_06_cat\"]))/2.0)))\n",
    "    v[\"314\"] = 0.020000*np.tanh((data[\"loo_ps_ind_05_cat\"] * (data[\"loo_ps_ind_11_bin\"] - (data[\"loo_ps_ind_04_cat\"] * data[\"ps_car_11\"]))))\n",
    "    v[\"315\"] = 0.019461*np.tanh((data[\"loo_ps_car_03_cat\"] * (data[\"loo_ps_ind_05_cat\"] * (data[\"loo_ps_car_02_cat\"] + data[\"loo_ps_ind_04_cat\"]))))\n",
    "    v[\"316\"] = 0.014366*np.tanh(np.tanh(np.tanh((data[\"ps_reg_01\"] - ((data[\"ps_ind_03\"] + ((data[\"ps_ind_14\"] + data[\"loo_ps_car_10_cat\"])/2.0))/2.0)))))\n",
    "    v[\"317\"] = 0.019996*np.tanh((data[\"ps_car_12\"] * ((data[\"loo_ps_ind_12_bin\"] + (data[\"ps_car_11\"] * (data[\"ps_ind_15\"] + data[\"ps_car_11\"])))/2.0)))\n",
    "    v[\"318\"] = 0.020000*np.tanh(np.tanh((data[\"ps_car_14\"] * ((-(np.tanh(data[\"ps_car_14\"]))) + (-(data[\"ps_reg_03\"]))))))\n",
    "    v[\"319\"] = 0.015050*np.tanh((-((np.tanh(data[\"loo_ps_car_04_cat\"]) * (data[\"ps_car_15\"] * (data[\"loo_ps_ind_18_bin\"] - data[\"loo_ps_ind_06_bin\"]))))))\n",
    "    v[\"320\"] = 0.020000*np.tanh((data[\"ps_car_13\"] * (((data[\"loo_ps_car_04_cat\"] * (data[\"ps_car_14\"] - data[\"ps_ind_03\"])) + data[\"ps_ind_03\"])/2.0)))\n",
    "    v[\"321\"] = 0.020000*np.tanh((-((data[\"ps_car_14\"] + ((0.347826 - data[\"ps_car_14\"]) * data[\"ps_car_15\"])))))\n",
    "    v[\"322\"] = 0.019977*np.tanh(((0.166667 + (data[\"ps_ind_14\"] * ((data[\"ps_reg_03\"] - data[\"loo_ps_ind_08_bin\"]) - data[\"loo_ps_ind_17_bin\"])))/2.0))\n",
    "    v[\"323\"] = 0.020000*np.tanh((data[\"missing\"] * (-((data[\"loo_ps_car_09_cat\"] * ((data[\"ps_car_12\"] + data[\"loo_ps_ind_18_bin\"])/2.0))))))\n",
    "    v[\"324\"] = 0.018195*np.tanh((((data[\"loo_ps_ind_09_bin\"] + (-(np.tanh(data[\"loo_ps_ind_05_cat\"]))))/2.0) * (data[\"loo_ps_ind_18_bin\"] + data[\"loo_ps_car_07_cat\"])))\n",
    "    v[\"325\"] = 0.019359*np.tanh((-((19.500000 * ((0.485294 + np.tanh((data[\"loo_ps_ind_11_bin\"] * 19.500000)))/2.0)))))\n",
    "    v[\"326\"] = 0.019992*np.tanh((-3.0 - ((-((data[\"ps_ind_03\"] * data[\"ps_ind_03\"]))) + data[\"ps_ind_03\"])))\n",
    "    v[\"327\"] = 0.020000*np.tanh((np.tanh((data[\"ps_reg_01\"] * (data[\"ps_car_14\"] * (-(data[\"loo_ps_ind_02_cat\"]))))) - data[\"loo_ps_ind_02_cat\"]))\n",
    "    v[\"328\"] = 0.019992*np.tanh((data[\"loo_ps_ind_04_cat\"] * ((data[\"ps_ind_03\"] + data[\"loo_ps_ind_04_cat\"]) * (-(data[\"loo_ps_car_08_cat\"])))))\n",
    "    v[\"329\"] = 0.020000*np.tanh((data[\"ps_car_11\"] * ((data[\"loo_ps_ind_02_cat\"] + ((data[\"loo_ps_ind_07_bin\"] + (data[\"loo_ps_car_07_cat\"] * data[\"missing\"]))/2.0))/2.0)))\n",
    "    v[\"330\"] = 0.019996*np.tanh((((data[\"loo_ps_car_02_cat\"] - (data[\"loo_ps_ind_06_bin\"] - data[\"loo_ps_car_02_cat\"])) * data[\"loo_ps_car_09_cat\"]) * data[\"loo_ps_ind_02_cat\"]))\n",
    "    v[\"331\"] = 0.018343*np.tanh((((data[\"loo_ps_car_07_cat\"] + (data[\"ps_reg_03\"] + np.tanh(data[\"loo_ps_car_07_cat\"])))/2.0) * (-(data[\"missing\"]))))\n",
    "    v[\"332\"] = 0.019750*np.tanh((-((data[\"loo_ps_ind_02_cat\"] * (data[\"loo_ps_ind_18_bin\"] * (data[\"ps_car_14\"] * data[\"loo_ps_car_04_cat\"]))))))\n",
    "    v[\"333\"] = 0.019949*np.tanh(((data[\"loo_ps_ind_05_cat\"] * (-(data[\"loo_ps_car_06_cat\"]))) * (data[\"loo_ps_ind_05_cat\"] * data[\"loo_ps_ind_04_cat\"])))\n",
    "    v[\"334\"] = 0.020000*np.tanh((data[\"loo_ps_car_06_cat\"] * ((2.800000 + data[\"ps_car_14\"]) * (data[\"loo_ps_ind_13_bin\"] * data[\"loo_ps_car_04_cat\"]))))\n",
    "    v[\"335\"] = 0.020000*np.tanh(np.tanh((data[\"ps_ind_03\"] * np.tanh(np.tanh((data[\"ps_reg_02\"] * (-(data[\"ps_ind_15\"]))))))))\n",
    "    v[\"336\"] = 0.020000*np.tanh((data[\"loo_ps_car_10_cat\"] * ((data[\"loo_ps_ind_11_bin\"] + data[\"loo_ps_ind_18_bin\"]) * (data[\"ps_reg_02\"] + data[\"ps_reg_02\"]))))\n",
    "    v[\"337\"] = 0.020000*np.tanh(np.tanh(np.tanh((data[\"ps_ind_03\"] * ((data[\"ps_ind_03\"] + data[\"ps_car_11\"]) + data[\"ps_car_11\"])))))\n",
    "    v[\"338\"] = 0.019984*np.tanh(((data[\"loo_ps_ind_05_cat\"] * (data[\"loo_ps_ind_11_bin\"] - (data[\"ps_car_11\"] * data[\"loo_ps_ind_06_bin\"]))) * data[\"loo_ps_car_01_cat\"]))\n",
    "    v[\"339\"] = 0.020000*np.tanh((data[\"ps_car_15\"] * (data[\"loo_ps_ind_12_bin\"] * (data[\"loo_ps_car_08_cat\"] + data[\"loo_ps_ind_07_bin\"]))))\n",
    "    v[\"340\"] = 0.019953*np.tanh((data[\"ps_ind_15\"] * (data[\"loo_ps_ind_02_cat\"] * (0.600000 - (data[\"loo_ps_ind_10_bin\"] - data[\"ps_reg_03\"])))))\n",
    "    v[\"341\"] = 0.017914*np.tanh(((data[\"loo_ps_car_03_cat\"] - (data[\"ps_car_13\"] + data[\"loo_ps_ind_18_bin\"])) * (data[\"loo_ps_car_03_cat\"] * 0.273684)))\n",
    "    v[\"342\"] = 0.020000*np.tanh((data[\"loo_ps_car_10_cat\"] * (-3.0 + (data[\"ps_car_14\"] * (data[\"ps_car_15\"] - data[\"loo_ps_car_04_cat\"])))))\n",
    "    v[\"343\"] = 0.020000*np.tanh((data[\"loo_ps_car_09_cat\"] * (((data[\"ps_car_11\"] * data[\"loo_ps_car_09_cat\"]) + (data[\"loo_ps_car_02_cat\"] - data[\"loo_ps_ind_04_cat\"]))/2.0)))\n",
    "    v[\"344\"] = 0.019973*np.tanh(((data[\"ps_car_13\"] * (data[\"ps_ind_14\"] - data[\"ps_reg_02\"])) * data[\"ps_ind_15\"]))\n",
    "    v[\"345\"] = 0.020000*np.tanh(((data[\"loo_ps_car_09_cat\"] * ((0.965909 - data[\"ps_reg_03\"]) - data[\"ps_reg_03\"])) * data[\"loo_ps_ind_08_bin\"]))\n",
    "    v[\"346\"] = 0.019973*np.tanh(((data[\"ps_ind_01\"] * (np.tanh(data[\"loo_ps_car_02_cat\"]) + data[\"loo_ps_ind_11_bin\"])) * (-(data[\"ps_car_15\"]))))\n",
    "    v[\"347\"] = 0.020000*np.tanh((data[\"loo_ps_ind_09_bin\"] * (((-(data[\"loo_ps_car_08_cat\"])) * data[\"loo_ps_car_03_cat\"]) * data[\"ps_ind_03\"])))\n",
    "    v[\"348\"] = 0.018535*np.tanh((data[\"loo_ps_ind_04_cat\"] * (data[\"loo_ps_car_04_cat\"] * (data[\"ps_ind_15\"] - (-(data[\"loo_ps_car_01_cat\"]))))))\n",
    "    v[\"349\"] = 0.020000*np.tanh((data[\"loo_ps_car_07_cat\"] * ((((data[\"loo_ps_ind_10_bin\"] + data[\"loo_ps_car_08_cat\"])/2.0) + (-(data[\"loo_ps_ind_12_bin\"])))/2.0)))\n",
    "    v[\"350\"] = 0.019996*np.tanh(((data[\"loo_ps_car_10_cat\"] * (data[\"loo_ps_ind_13_bin\"] - data[\"ps_reg_02\"])) * (data[\"loo_ps_ind_17_bin\"] + data[\"ps_ind_03\"])))\n",
    "    v[\"351\"] = 0.020000*np.tanh((data[\"loo_ps_ind_06_bin\"] * (data[\"ps_reg_01\"] * ((data[\"missing\"] + (data[\"loo_ps_car_07_cat\"] - data[\"loo_ps_ind_05_cat\"]))/2.0))))\n",
    "    v[\"352\"] = 0.020000*np.tanh((data[\"ps_car_12\"] * (data[\"ps_car_12\"] * ((-(np.tanh(data[\"loo_ps_car_07_cat\"]))) * data[\"ps_reg_02\"]))))\n",
    "    v[\"353\"] = 0.020000*np.tanh((((-((data[\"ps_ind_01\"] * (data[\"ps_ind_03\"] * data[\"loo_ps_ind_02_cat\"])))) + np.tanh(data[\"loo_ps_car_08_cat\"]))/2.0))\n",
    "    v[\"354\"] = 0.016128*np.tanh((data[\"ps_ind_15\"] * (data[\"loo_ps_car_11_cat\"] * (((data[\"ps_ind_15\"] * data[\"loo_ps_car_11_cat\"]) + 1.871790)/2.0))))\n",
    "    v[\"355\"] = 0.019961*np.tanh((data[\"loo_ps_ind_06_bin\"] * (data[\"loo_ps_ind_12_bin\"] * (data[\"loo_ps_ind_11_bin\"] + ((data[\"ps_ind_15\"] + data[\"loo_ps_car_11_cat\"])/2.0)))))\n",
    "    v[\"356\"] = 0.019836*np.tanh(((np.tanh(data[\"ps_ind_15\"]) + (data[\"loo_ps_ind_02_cat\"] * (data[\"ps_ind_15\"] * (-(data[\"loo_ps_ind_02_cat\"])))))/2.0))\n",
    "    v[\"357\"] = 0.019840*np.tanh(((data[\"ps_car_15\"] * (data[\"loo_ps_ind_17_bin\"] - 0.093750)) * data[\"ps_car_15\"]))\n",
    "    v[\"358\"] = 0.020000*np.tanh((-((data[\"loo_ps_car_09_cat\"] * ((data[\"loo_ps_car_01_cat\"] + (data[\"ps_reg_02\"] * data[\"loo_ps_car_09_cat\"]))/2.0)))))\n",
    "    v[\"359\"] = 0.020000*np.tanh((-(((data[\"loo_ps_ind_17_bin\"] + data[\"loo_ps_ind_17_bin\"]) * ((np.tanh(data[\"ps_ind_01\"]) + 0.452381)/2.0)))))\n",
    "    v[\"360\"] = 0.020000*np.tanh((data[\"loo_ps_ind_08_bin\"] * (data[\"ps_car_14\"] * (data[\"loo_ps_ind_02_cat\"] - np.tanh(data[\"loo_ps_car_04_cat\"])))))\n",
    "    v[\"361\"] = 0.019996*np.tanh((((data[\"loo_ps_ind_11_bin\"] + (data[\"loo_ps_ind_08_bin\"] * (data[\"ps_ind_01\"] * data[\"ps_car_11\"])))/2.0) * data[\"ps_car_11\"]))\n",
    "    v[\"362\"] = 0.020000*np.tanh(((8.47791767120361328) * (data[\"loo_ps_ind_10_bin\"] * (data[\"ps_car_11\"] + (data[\"ps_car_14\"] * data[\"loo_ps_car_08_cat\"])))))\n",
    "    v[\"363\"] = 0.019152*np.tanh((((data[\"loo_ps_car_08_cat\"] + (data[\"loo_ps_car_08_cat\"] * (-(data[\"ps_ind_03\"]))))/2.0) * data[\"ps_ind_03\"]))\n",
    "    v[\"364\"] = 0.020000*np.tanh((data[\"loo_ps_ind_16_bin\"] * (data[\"ps_ind_14\"] * ((data[\"ps_car_12\"] + (data[\"ps_reg_03\"] * data[\"loo_ps_car_01_cat\"]))/2.0))))\n",
    "    v[\"365\"] = 0.019996*np.tanh((((data[\"ps_car_15\"] * (data[\"ps_ind_01\"] * data[\"ps_reg_02\"])) + (data[\"loo_ps_ind_02_cat\"] * data[\"ps_reg_02\"]))/2.0))\n",
    "    v[\"366\"] = 0.020000*np.tanh((data[\"loo_ps_ind_12_bin\"] * ((data[\"loo_ps_ind_11_bin\"] - data[\"loo_ps_car_10_cat\"]) - (data[\"loo_ps_ind_17_bin\"] * data[\"loo_ps_ind_07_bin\"]))))\n",
    "    v[\"367\"] = 0.019996*np.tanh((-(((data[\"loo_ps_ind_17_bin\"] * data[\"loo_ps_car_02_cat\"]) * (0.347826 - data[\"ps_car_15\"])))))\n",
    "    v[\"368\"] = 0.020000*np.tanh((data[\"loo_ps_ind_02_cat\"] * ((data[\"ps_reg_03\"] * (data[\"loo_ps_car_04_cat\"] * data[\"loo_ps_car_01_cat\"])) * data[\"loo_ps_car_08_cat\"])))\n",
    "    v[\"369\"] = 0.020000*np.tanh((((data[\"ps_reg_02\"] + data[\"ps_ind_15\"]) * data[\"loo_ps_ind_12_bin\"]) * (data[\"ps_ind_03\"] + data[\"ps_ind_03\"])))\n",
    "    v[\"370\"] = 0.020000*np.tanh((data[\"loo_ps_ind_16_bin\"] * (data[\"ps_car_12\"] * (data[\"loo_ps_ind_02_cat\"] * (0.485294 - data[\"loo_ps_car_08_cat\"])))))\n",
    "    v[\"371\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_12_bin\"] * (-(data[\"ps_reg_01\"]))) - (data[\"loo_ps_ind_04_cat\"] * np.tanh(data[\"ps_ind_15\"]))))\n",
    "    v[\"372\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_05_cat\"] * (((data[\"loo_ps_car_02_cat\"] * data[\"loo_ps_ind_04_cat\"]) + data[\"loo_ps_ind_10_bin\"])/2.0)) * data[\"loo_ps_car_03_cat\"]))\n",
    "    v[\"373\"] = 0.020000*np.tanh(((data[\"ps_ind_14\"] * data[\"loo_ps_car_11_cat\"]) * np.tanh((data[\"ps_ind_03\"] + data[\"ps_ind_15\"]))))\n",
    "    v[\"374\"] = 0.019984*np.tanh((data[\"ps_car_12\"] * ((data[\"loo_ps_ind_12_bin\"] * (1.526320 - data[\"ps_car_13\"])) + data[\"loo_ps_ind_12_bin\"])))\n",
    "    v[\"375\"] = 0.019684*np.tanh((data[\"loo_ps_ind_08_bin\"] * ((((data[\"loo_ps_ind_16_bin\"] + np.tanh(data[\"ps_reg_02\"]))/2.0) + 0.100000)/2.0)))\n",
    "    v[\"376\"] = 0.018172*np.tanh((((data[\"ps_car_11\"] + 1.135800)/2.0) * (data[\"ps_reg_03\"] * (data[\"ps_ind_03\"] + data[\"loo_ps_ind_12_bin\"]))))\n",
    "    v[\"377\"] = 0.020000*np.tanh(((data[\"ps_car_11\"] * ((data[\"loo_ps_ind_10_bin\"] + data[\"ps_car_11\"]) + 1.526320)) * data[\"loo_ps_car_10_cat\"]))\n",
    "    v[\"378\"] = 0.020000*np.tanh((data[\"loo_ps_ind_12_bin\"] * ((data[\"ps_ind_03\"] + ((data[\"ps_ind_15\"] + (-(data[\"ps_car_14\"])))/2.0))/2.0)))\n",
    "    v[\"379\"] = 0.020000*np.tanh((data[\"ps_car_11\"] * (((data[\"loo_ps_car_09_cat\"] + (data[\"ps_ind_01\"] * data[\"loo_ps_ind_11_bin\"]))/2.0) * data[\"ps_ind_01\"])))\n",
    "    v[\"380\"] = 0.019898*np.tanh((data[\"loo_ps_ind_12_bin\"] * (data[\"ps_ind_03\"] - (data[\"ps_car_11\"] + ((-2.0 + data[\"loo_ps_car_08_cat\"])/2.0)))))\n",
    "    v[\"381\"] = 0.020000*np.tanh((((data[\"ps_car_11\"] * data[\"loo_ps_ind_18_bin\"]) * data[\"ps_car_11\"]) * data[\"ps_ind_14\"]))\n",
    "    v[\"382\"] = 0.020000*np.tanh((data[\"loo_ps_ind_04_cat\"] * (data[\"ps_ind_03\"] * ((data[\"ps_ind_03\"] * data[\"ps_car_12\"]) - data[\"ps_ind_03\"]))))\n",
    "    v[\"383\"] = 0.019980*np.tanh((data[\"loo_ps_ind_02_cat\"] * (((data[\"ps_car_11\"] + data[\"ps_car_15\"])/2.0) + (data[\"ps_car_15\"] * data[\"ps_car_11\"]))))\n",
    "    v[\"384\"] = 0.019836*np.tanh(((data[\"loo_ps_car_06_cat\"] * data[\"loo_ps_ind_04_cat\"]) * ((data[\"loo_ps_ind_04_cat\"] * data[\"ps_ind_14\"]) + data[\"loo_ps_car_08_cat\"])))\n",
    "    v[\"385\"] = 0.019965*np.tanh(((data[\"ps_car_13\"] + data[\"ps_ind_15\"]) * (data[\"ps_ind_03\"] * (data[\"ps_reg_02\"] + data[\"ps_car_15\"]))))\n",
    "    v[\"386\"] = 0.019508*np.tanh((data[\"ps_ind_15\"] * (data[\"ps_reg_01\"] * ((data[\"loo_ps_car_06_cat\"] * data[\"loo_ps_car_04_cat\"]) + data[\"loo_ps_ind_13_bin\"]))))\n",
    "    v[\"387\"] = 0.015862*np.tanh((((data[\"ps_reg_02\"] + data[\"loo_ps_car_08_cat\"])/2.0) * (data[\"ps_car_13\"] * (data[\"ps_car_12\"] - 2.0))))\n",
    "    v[\"388\"] = 0.020000*np.tanh((data[\"ps_car_13\"] * (0.100000 - ((data[\"loo_ps_car_10_cat\"] * data[\"ps_ind_01\"]) * data[\"ps_ind_01\"]))))\n",
    "    v[\"389\"] = 0.019992*np.tanh((data[\"ps_car_13\"] * (data[\"loo_ps_ind_12_bin\"] * (data[\"ps_reg_01\"] + data[\"ps_ind_15\"]))))\n",
    "    v[\"390\"] = 0.015315*np.tanh(((np.tanh(np.tanh((data[\"loo_ps_ind_07_bin\"] + data[\"loo_ps_car_06_cat\"]))) + np.tanh(data[\"loo_ps_car_08_cat\"]))/2.0))\n",
    "    v[\"391\"] = 0.020000*np.tanh((data[\"ps_car_15\"] * (0.452381 - (data[\"loo_ps_car_08_cat\"] * ((data[\"loo_ps_ind_11_bin\"] + data[\"ps_car_15\"])/2.0)))))\n",
    "    v[\"392\"] = 0.020000*np.tanh(((data[\"loo_ps_ind_05_cat\"] + data[\"loo_ps_ind_06_bin\"]) * ((data[\"loo_ps_car_10_cat\"] - data[\"loo_ps_car_02_cat\"]) * data[\"loo_ps_car_10_cat\"])))\n",
    "    v[\"393\"] = 0.015452*np.tanh((data[\"loo_ps_ind_06_bin\"] * ((data[\"loo_ps_car_08_cat\"] + (data[\"loo_ps_ind_09_bin\"] * data[\"loo_ps_car_09_cat\"]))/2.0)))\n",
    "    v[\"394\"] = 0.019977*np.tanh((data[\"loo_ps_ind_17_bin\"] * ((data[\"loo_ps_ind_08_bin\"] * data[\"ps_car_15\"]) * (0.485294 - data[\"loo_ps_ind_02_cat\"]))))\n",
    "    v[\"395\"] = 0.019977*np.tanh((data[\"loo_ps_ind_04_cat\"] * ((data[\"ps_reg_02\"] + ((data[\"loo_ps_ind_04_cat\"] - data[\"ps_ind_01\"]) - data[\"loo_ps_car_09_cat\"]))/2.0)))\n",
    "    v[\"396\"] = 0.019980*np.tanh((data[\"ps_reg_01\"] * (data[\"loo_ps_car_10_cat\"] * (-((data[\"loo_ps_ind_12_bin\"] + data[\"ps_reg_02\"]))))))\n",
    "    v[\"397\"] = 0.020000*np.tanh(((data[\"ps_car_15\"] * ((data[\"loo_ps_ind_16_bin\"] + data[\"loo_ps_car_10_cat\"])/2.0)) * (data[\"ps_car_15\"] - data[\"loo_ps_ind_16_bin\"])))\n",
    "    v[\"398\"] = 0.020000*np.tanh((((-((data[\"loo_ps_ind_02_cat\"] * (data[\"ps_car_14\"] * data[\"loo_ps_ind_07_bin\"])))) + np.tanh(data[\"ps_car_15\"]))/2.0))\n",
    "    v[\"399\"] = 0.014948*np.tanh((data[\"ps_reg_02\"] * (data[\"loo_ps_car_08_cat\"] * (-(data[\"ps_ind_03\"])))))\n",
    "    v[\"400\"] = 0.016214*np.tanh((data[\"loo_ps_car_04_cat\"] * np.tanh((data[\"loo_ps_car_11_cat\"] - (data[\"loo_ps_ind_07_bin\"] + 1.526320)))))\n",
    "    return Outputs(v.sum(axis=1))\n",
    "\n",
    "\n",
    "def GPAri(data):\n",
    "    return (GPI(data)+GPII(data))/2.\n",
    "\n",
    "\n",
    "def ProjectOnMean(data1, data2, columnName):\n",
    "    grpOutcomes = data1.groupby(list([columnName]))['target'].mean().reset_index()\n",
    "    grpCount = data1.groupby(list([columnName]))['target'].count().reset_index()\n",
    "    grpOutcomes['cnt'] = grpCount.target\n",
    "    grpOutcomes.drop('cnt', inplace=True, axis=1)\n",
    "    outcomes = data2['target'].values\n",
    "    x = pd.merge(data2[[columnName, 'target']], grpOutcomes,\n",
    "                 suffixes=('x_', ''),\n",
    "                 how='left',\n",
    "                 on=list([columnName]),\n",
    "                 left_index=True)['target']\n",
    "\n",
    "    \n",
    "    return x.values\n",
    "\n",
    "\n",
    "def GetData(strdirectory):\n",
    "    # Project Categorical inputs to Target\n",
    "    highcardinality = ['ps_car_02_cat',\n",
    "                       'ps_car_09_cat',\n",
    "                       'ps_ind_04_cat',\n",
    "                       'ps_ind_05_cat',\n",
    "                       'ps_car_03_cat',\n",
    "                       'ps_ind_08_bin',\n",
    "                       'ps_car_05_cat',\n",
    "                       'ps_car_08_cat',\n",
    "                       'ps_ind_06_bin',\n",
    "                       'ps_ind_07_bin',\n",
    "                       'ps_ind_12_bin',\n",
    "                       'ps_ind_18_bin',\n",
    "                       'ps_ind_17_bin',\n",
    "                       'ps_car_07_cat',\n",
    "                       'ps_car_11_cat',\n",
    "                       'ps_ind_09_bin',\n",
    "                       'ps_car_10_cat',\n",
    "                       'ps_car_04_cat',\n",
    "                       'ps_car_01_cat',\n",
    "                       'ps_ind_02_cat',\n",
    "                       'ps_ind_10_bin',\n",
    "                       'ps_ind_11_bin',\n",
    "                       'ps_car_06_cat',\n",
    "                       'ps_ind_13_bin',\n",
    "                       'ps_ind_16_bin']\n",
    "\n",
    "    train = pd.read_csv(strdirectory+'train.csv')\n",
    "    test = pd.read_csv(strdirectory+'test.csv')\n",
    "\n",
    "    train['missing'] = (train==-1).sum(axis=1).astype(float)\n",
    "    test['missing'] = (test==-1).sum(axis=1).astype(float)\n",
    "\n",
    "    unwanted = train.columns[train.columns.str.startswith('ps_calc_')]\n",
    "    train.drop(unwanted,inplace=True,axis=1)\n",
    "    test.drop(unwanted,inplace=True,axis=1)\n",
    "\n",
    "    test['target'] = np.nan\n",
    "    feats = list(set(train.columns).difference(set(['id','target'])))\n",
    "    feats = list(['id'])+feats +list(['target'])\n",
    "    train = train[feats]\n",
    "    test = test[feats]\n",
    "    \n",
    "    blindloodata = None\n",
    "    folds = 5\n",
    "    kf = StratifiedKFold(n_splits=folds,shuffle=True,random_state=42)\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(range(train.shape[0]),train.target)):\n",
    "        print('Fold:',i)\n",
    "        blindtrain = train.loc[test_index].copy() \n",
    "        vistrain = train.loc[train_index].copy()\n",
    "\n",
    "        for c in highcardinality:\n",
    "            blindtrain.insert(1,'loo_'+c, ProjectOnMean(vistrain,\n",
    "                                                       blindtrain,c))\n",
    "        if(blindloodata is None):\n",
    "            blindloodata = blindtrain.copy()\n",
    "        else:\n",
    "            blindloodata = pd.concat([blindloodata,blindtrain])\n",
    "\n",
    "    for c in highcardinality:\n",
    "        test.insert(1,'loo_'+c, ProjectOnMean(train,\n",
    "                                             test,c))\n",
    "    test.drop(highcardinality,inplace=True,axis=1)\n",
    "\n",
    "    train = blindloodata\n",
    "    train.drop(highcardinality,inplace=True,axis=1)\n",
    "    train = train.fillna(train.mean())\n",
    "    test = test.fillna(train.mean())\n",
    "\n",
    "    print('Scale values')\n",
    "    ss = StandardScaler()\n",
    "    features = train.columns[1:-1]\n",
    "    ss.fit(pd.concat([train[features],test[features]]))\n",
    "    train[features] = ss.transform(train[features] )\n",
    "    test[features] = ss.transform(test[features] )\n",
    "    train[features] = np.round(train[features], 6)\n",
    "    test[features] = np.round(test[features], 6)\n",
    "    return train, test\n",
    "    \n",
    "\n",
    "def main():\n",
    "    print('Started')\n",
    "    strdirectory =\"C:\\\\Users\\\\hasee\\\\workspace\\\\Kaggle\\\\safe_driver\\\\\"\n",
    "    gptrain, gptest = GetData(strdirectory)\n",
    "    print('GPAri Gini Score:', GiniScore(gptrain.target,GPAri(gptrain)))\n",
    "    basic = pd.read_csv(strdirectory+'sample_submission.csv')\n",
    "    basic.target = GPAri(gptest).ravel()\n",
    "    basic.to_csv(strdirectory+'test_gpari.csv',index=None,float_format='%.6f')\n",
    "    \n",
    "    basic = pd.read_csv(strdirectory+'train.csv')\n",
    "    basic.target = GPAri(gptrain).ravel()\n",
    "    basic[['target']].to_csv(strdirectory+'train_gpari.csv',index=None,float_format='%.6f')\n",
    "    print('Finished')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\hasee\\AppData\\Local\\Temp\\tmpa2dqf_5m\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001F0A7C0BC18>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': 42, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\hasee\\\\AppData\\\\Local\\\\Temp\\\\tmpa2dqf_5m'}\n",
      "WARNING:tensorflow:From <ipython-input-34-1a46bf69181a>:52: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-34-1a46bf69181a>:52: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:From <ipython-input-34-1a46bf69181a>:52: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:642: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\hasee\\AppData\\Local\\Temp\\tmpa2dqf_5m\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.689418, step = 1\n",
      "INFO:tensorflow:global_step/sec: 130.103\n",
      "INFO:tensorflow:loss = 0.115856, step = 101 (0.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.061\n",
      "INFO:tensorflow:loss = 0.0317267, step = 201 (0.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.206\n",
      "INFO:tensorflow:loss = 0.181753, step = 301 (0.828 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.447\n",
      "INFO:tensorflow:loss = 0.167859, step = 401 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.36\n",
      "INFO:tensorflow:loss = 0.059496, step = 501 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.079\n",
      "INFO:tensorflow:loss = 0.366549, step = 601 (0.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.559\n",
      "INFO:tensorflow:loss = 0.105464, step = 701 (0.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.64\n",
      "INFO:tensorflow:loss = 0.15437, step = 801 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.507\n",
      "INFO:tensorflow:loss = 0.166529, step = 901 (0.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.359\n",
      "INFO:tensorflow:loss = 0.24242, step = 1001 (0.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.732\n",
      "INFO:tensorflow:loss = 0.0299361, step = 1101 (0.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.226\n",
      "INFO:tensorflow:loss = 0.147718, step = 1201 (0.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.7421\n",
      "INFO:tensorflow:loss = 0.213668, step = 1301 (1.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.513\n",
      "INFO:tensorflow:loss = 0.16303, step = 1401 (0.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.934\n",
      "INFO:tensorflow:loss = 0.106326, step = 1501 (0.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.2\n",
      "INFO:tensorflow:loss = 0.172949, step = 1601 (0.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.152\n",
      "INFO:tensorflow:loss = 0.102654, step = 1701 (0.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.178\n",
      "INFO:tensorflow:loss = 0.167731, step = 1801 (0.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.442\n",
      "INFO:tensorflow:loss = 0.103875, step = 1901 (0.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.43\n",
      "INFO:tensorflow:loss = 0.314506, step = 2001 (0.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.49\n",
      "INFO:tensorflow:loss = 0.164651, step = 2101 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.179\n",
      "INFO:tensorflow:loss = 0.181334, step = 2201 (0.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.748\n",
      "INFO:tensorflow:loss = 0.105738, step = 2301 (0.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.889\n",
      "INFO:tensorflow:loss = 0.106878, step = 2401 (0.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.969\n",
      "INFO:tensorflow:loss = 0.100068, step = 2501 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.613\n",
      "INFO:tensorflow:loss = 0.106511, step = 2601 (0.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.85\n",
      "INFO:tensorflow:loss = 0.172206, step = 2701 (0.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.47\n",
      "INFO:tensorflow:loss = 0.144468, step = 2801 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.978\n",
      "INFO:tensorflow:loss = 0.220692, step = 2901 (0.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.517\n",
      "INFO:tensorflow:loss = 0.111333, step = 3001 (0.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.173\n",
      "INFO:tensorflow:loss = 0.104084, step = 3101 (0.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.143\n",
      "INFO:tensorflow:loss = 0.10296, step = 3201 (0.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.638\n",
      "INFO:tensorflow:loss = 0.0351554, step = 3301 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.935\n",
      "INFO:tensorflow:loss = 0.241136, step = 3401 (0.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.404\n",
      "INFO:tensorflow:loss = 0.363814, step = 3501 (0.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.772\n",
      "INFO:tensorflow:loss = 0.119014, step = 3601 (0.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.419\n",
      "INFO:tensorflow:loss = 0.148919, step = 3701 (0.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.986\n",
      "INFO:tensorflow:loss = 0.156554, step = 3801 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.19\n",
      "INFO:tensorflow:loss = 0.156438, step = 3901 (0.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.298\n",
      "INFO:tensorflow:loss = 0.13792, step = 4001 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.559\n",
      "INFO:tensorflow:loss = 0.226101, step = 4101 (0.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.675\n",
      "INFO:tensorflow:loss = 0.107758, step = 4201 (0.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.077\n",
      "INFO:tensorflow:loss = 0.263222, step = 4301 (0.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.906\n",
      "INFO:tensorflow:loss = 0.163809, step = 4401 (0.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.248\n",
      "INFO:tensorflow:loss = 0.126745, step = 4501 (0.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.281\n",
      "INFO:tensorflow:loss = 0.195961, step = 4601 (0.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.062\n",
      "INFO:tensorflow:loss = 0.319966, step = 4701 (0.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.353\n",
      "INFO:tensorflow:loss = 0.242251, step = 4801 (0.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.108\n",
      "INFO:tensorflow:loss = 0.371144, step = 4901 (0.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0975341, step = 5001 (0.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.112\n",
      "INFO:tensorflow:loss = 0.351847, step = 5101 (0.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.151\n",
      "INFO:tensorflow:loss = 0.0426124, step = 5201 (0.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.239\n",
      "INFO:tensorflow:loss = 0.0251428, step = 5301 (0.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.011\n",
      "INFO:tensorflow:loss = 0.242848, step = 5401 (0.694 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.137\n",
      "INFO:tensorflow:loss = 0.300229, step = 5501 (0.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.573\n",
      "INFO:tensorflow:loss = 0.15713, step = 5601 (0.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.267\n",
      "INFO:tensorflow:loss = 0.0321693, step = 5701 (0.928 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.453\n",
      "INFO:tensorflow:loss = 0.229729, step = 5801 (0.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.652\n",
      "INFO:tensorflow:loss = 0.105433, step = 5901 (0.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.331\n",
      "INFO:tensorflow:loss = 0.302426, step = 6001 (0.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.292\n",
      "INFO:tensorflow:loss = 0.105433, step = 6101 (0.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.316\n",
      "INFO:tensorflow:loss = 0.0981701, step = 6201 (0.602 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.445\n",
      "INFO:tensorflow:loss = 0.216509, step = 6301 (0.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.529\n",
      "INFO:tensorflow:loss = 0.112193, step = 6401 (0.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.065\n",
      "INFO:tensorflow:loss = 0.341484, step = 6501 (0.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.069\n",
      "INFO:tensorflow:loss = 0.156897, step = 6601 (0.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.275\n",
      "INFO:tensorflow:loss = 0.174763, step = 6701 (0.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.036\n",
      "INFO:tensorflow:loss = 0.148713, step = 6801 (0.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.265\n",
      "INFO:tensorflow:loss = 0.161159, step = 6901 (0.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.478\n",
      "INFO:tensorflow:loss = 0.281878, step = 7001 (0.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.854\n",
      "INFO:tensorflow:loss = 0.330559, step = 7101 (0.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.122\n",
      "INFO:tensorflow:loss = 0.217974, step = 7201 (0.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.284\n",
      "INFO:tensorflow:loss = 0.0449407, step = 7301 (0.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.893\n",
      "INFO:tensorflow:loss = 0.111553, step = 7401 (0.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.355\n",
      "INFO:tensorflow:loss = 0.0396456, step = 7501 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.443\n",
      "INFO:tensorflow:loss = 0.158514, step = 7601 (0.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.201\n",
      "INFO:tensorflow:loss = 0.15942, step = 7701 (0.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.277\n",
      "INFO:tensorflow:loss = 0.116885, step = 7801 (0.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.532\n",
      "INFO:tensorflow:loss = 0.242194, step = 7901 (0.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.588\n",
      "INFO:tensorflow:loss = 0.203211, step = 8001 (0.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.999\n",
      "INFO:tensorflow:loss = 0.154945, step = 8101 (0.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.549\n",
      "INFO:tensorflow:loss = 0.0435216, step = 8201 (0.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.521\n",
      "INFO:tensorflow:loss = 0.170491, step = 8301 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.542\n",
      "INFO:tensorflow:loss = 0.0315382, step = 8401 (0.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.119\n",
      "INFO:tensorflow:loss = 0.169929, step = 8501 (0.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.222\n",
      "INFO:tensorflow:loss = 0.149547, step = 8601 (0.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.48\n",
      "INFO:tensorflow:loss = 0.253347, step = 8701 (0.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.561\n",
      "INFO:tensorflow:loss = 0.221686, step = 8801 (0.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.677\n",
      "INFO:tensorflow:loss = 0.16044, step = 8901 (0.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.727\n",
      "INFO:tensorflow:loss = 0.112438, step = 9001 (0.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.41\n",
      "INFO:tensorflow:loss = 0.113236, step = 9101 (0.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.921\n",
      "INFO:tensorflow:loss = 0.0980629, step = 9201 (0.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.921\n",
      "INFO:tensorflow:loss = 0.0965074, step = 9301 (0.856 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.053\n",
      "INFO:tensorflow:loss = 0.0969615, step = 9401 (0.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.441\n",
      "INFO:tensorflow:loss = 0.113892, step = 9501 (0.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.237\n",
      "INFO:tensorflow:loss = 0.21298, step = 9601 (0.822 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.794\n",
      "INFO:tensorflow:loss = 0.0922338, step = 9701 (0.880 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.658\n",
      "INFO:tensorflow:loss = 0.0979029, step = 9801 (0.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.915\n",
      "INFO:tensorflow:loss = 0.041178, step = 9901 (0.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.743\n",
      "INFO:tensorflow:loss = 0.0872318, step = 10001 (0.937 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.056\n",
      "INFO:tensorflow:loss = 0.0765798, step = 10101 (0.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.631\n",
      "INFO:tensorflow:loss = 0.0920651, step = 10201 (0.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.011\n",
      "INFO:tensorflow:loss = 0.329083, step = 10301 (0.977 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.094\n",
      "INFO:tensorflow:loss = 0.290714, step = 10401 (0.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.325\n",
      "INFO:tensorflow:loss = 0.112505, step = 10501 (0.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.795\n",
      "INFO:tensorflow:loss = 0.103397, step = 10601 (0.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.202\n",
      "INFO:tensorflow:loss = 0.190535, step = 10701 (0.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.291\n",
      "INFO:tensorflow:loss = 0.157923, step = 10801 (0.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.197\n",
      "INFO:tensorflow:loss = 0.309995, step = 10901 (0.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.763\n",
      "INFO:tensorflow:loss = 0.0810825, step = 11001 (0.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.44\n",
      "INFO:tensorflow:loss = 0.0299627, step = 11101 (0.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.21\n",
      "INFO:tensorflow:loss = 0.116908, step = 11201 (0.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.291\n",
      "INFO:tensorflow:loss = 0.0998998, step = 11301 (0.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.122\n",
      "INFO:tensorflow:loss = 0.112522, step = 11401 (0.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.33\n",
      "INFO:tensorflow:loss = 0.0964105, step = 11501 (0.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.258\n",
      "INFO:tensorflow:loss = 0.201746, step = 11601 (0.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.07\n",
      "INFO:tensorflow:loss = 0.0446045, step = 11701 (0.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.909\n",
      "INFO:tensorflow:loss = 0.213697, step = 11801 (0.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.843\n",
      "INFO:tensorflow:loss = 0.233834, step = 11901 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.674\n",
      "INFO:tensorflow:loss = 0.0441291, step = 12001 (0.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.67\n",
      "INFO:tensorflow:loss = 0.0805216, step = 12101 (0.700 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.768\n",
      "INFO:tensorflow:loss = 0.0423341, step = 12201 (0.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.845\n",
      "INFO:tensorflow:loss = 0.0420347, step = 12301 (0.720 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.314\n",
      "INFO:tensorflow:loss = 0.187844, step = 12401 (0.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.461\n",
      "INFO:tensorflow:loss = 0.111933, step = 12501 (0.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.969\n",
      "INFO:tensorflow:loss = 0.109463, step = 12601 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.3\n",
      "INFO:tensorflow:loss = 0.0925428, step = 12701 (0.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.437\n",
      "INFO:tensorflow:loss = 0.097131, step = 12801 (0.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.27\n",
      "INFO:tensorflow:loss = 0.257789, step = 12901 (0.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.209\n",
      "INFO:tensorflow:loss = 0.221776, step = 13001 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.064\n",
      "INFO:tensorflow:loss = 0.146605, step = 13101 (0.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.766\n",
      "INFO:tensorflow:loss = 0.155543, step = 13201 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.624\n",
      "INFO:tensorflow:loss = 0.0800064, step = 13301 (0.869 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 105.017\n",
      "INFO:tensorflow:loss = 0.35334, step = 13401 (0.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.439\n",
      "INFO:tensorflow:loss = 0.20578, step = 13501 (0.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 97.2507\n",
      "INFO:tensorflow:loss = 0.0378262, step = 13601 (1.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.49\n",
      "INFO:tensorflow:loss = 0.363141, step = 13701 (0.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 147\n",
      "INFO:tensorflow:loss = 0.137528, step = 13801 (0.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.262\n",
      "INFO:tensorflow:loss = 0.0297434, step = 13901 (0.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.498\n",
      "INFO:tensorflow:loss = 0.271441, step = 14001 (0.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.024\n",
      "INFO:tensorflow:loss = 0.0327338, step = 14101 (0.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.736\n",
      "INFO:tensorflow:loss = 0.215096, step = 14201 (0.706 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.157\n",
      "INFO:tensorflow:loss = 0.106695, step = 14301 (0.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.091\n",
      "INFO:tensorflow:loss = 0.272016, step = 14401 (0.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.292\n",
      "INFO:tensorflow:loss = 0.0839221, step = 14501 (0.809 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.088\n",
      "INFO:tensorflow:loss = 0.108435, step = 14601 (0.888 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.478\n",
      "INFO:tensorflow:loss = 0.314836, step = 14701 (0.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.421\n",
      "INFO:tensorflow:loss = 0.175592, step = 14801 (0.702 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.477\n",
      "INFO:tensorflow:loss = 0.16002, step = 14901 (0.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.463\n",
      "INFO:tensorflow:loss = 0.0450434, step = 15001 (0.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.8383\n",
      "INFO:tensorflow:loss = 0.0815894, step = 15101 (1.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.944\n",
      "INFO:tensorflow:loss = 0.10047, step = 15201 (0.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.57\n",
      "INFO:tensorflow:loss = 0.104029, step = 15301 (0.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.201\n",
      "INFO:tensorflow:loss = 0.154997, step = 15401 (0.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.184\n",
      "INFO:tensorflow:loss = 0.0441578, step = 15501 (0.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.84\n",
      "INFO:tensorflow:loss = 0.212294, step = 15601 (0.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 97.1842\n",
      "INFO:tensorflow:loss = 0.158608, step = 15701 (1.042 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.501\n",
      "INFO:tensorflow:loss = 0.171709, step = 15801 (0.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.137\n",
      "INFO:tensorflow:loss = 0.0957735, step = 15901 (0.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.367\n",
      "INFO:tensorflow:loss = 0.223671, step = 16001 (0.908 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.835\n",
      "INFO:tensorflow:loss = 0.109927, step = 16101 (0.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.675\n",
      "INFO:tensorflow:loss = 0.288036, step = 16201 (0.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.126\n",
      "INFO:tensorflow:loss = 0.280464, step = 16301 (0.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.981\n",
      "INFO:tensorflow:loss = 0.365916, step = 16401 (0.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.227\n",
      "INFO:tensorflow:loss = 0.437191, step = 16501 (0.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.802\n",
      "INFO:tensorflow:loss = 0.108284, step = 16601 (0.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.134\n",
      "INFO:tensorflow:loss = 0.235835, step = 16701 (0.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.216\n",
      "INFO:tensorflow:loss = 0.0942103, step = 16801 (0.941 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.36\n",
      "INFO:tensorflow:loss = 0.155318, step = 16901 (0.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.794\n",
      "INFO:tensorflow:loss = 0.33168, step = 17001 (0.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.832\n",
      "INFO:tensorflow:loss = 0.224226, step = 17101 (0.996 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.494\n",
      "INFO:tensorflow:loss = 0.17197, step = 17201 (0.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.123\n",
      "INFO:tensorflow:loss = 0.159965, step = 17301 (0.989 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.132\n",
      "INFO:tensorflow:loss = 0.160274, step = 17401 (0.956 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.661\n",
      "INFO:tensorflow:loss = 0.0906196, step = 17501 (0.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.968\n",
      "INFO:tensorflow:loss = 0.103787, step = 17601 (0.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.133\n",
      "INFO:tensorflow:loss = 0.17115, step = 17701 (0.757 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.343\n",
      "INFO:tensorflow:loss = 0.164922, step = 17801 (0.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.263\n",
      "INFO:tensorflow:loss = 0.173949, step = 17901 (0.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.886\n",
      "INFO:tensorflow:loss = 0.171834, step = 18001 (0.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.454\n",
      "INFO:tensorflow:loss = 0.0482873, step = 18101 (0.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.03\n",
      "INFO:tensorflow:loss = 0.100676, step = 18201 (0.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.037\n",
      "INFO:tensorflow:loss = 0.242969, step = 18301 (0.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.774\n",
      "INFO:tensorflow:loss = 0.388033, step = 18401 (0.996 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.9843\n",
      "INFO:tensorflow:loss = 0.152633, step = 18501 (1.038 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.413\n",
      "INFO:tensorflow:loss = 0.231059, step = 18601 (0.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.4203\n",
      "INFO:tensorflow:loss = 0.17157, step = 18701 (1.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.594\n",
      "INFO:tensorflow:loss = 0.241716, step = 18801 (0.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.342\n",
      "INFO:tensorflow:loss = 0.0957889, step = 18901 (0.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 97.8339\n",
      "INFO:tensorflow:loss = 0.104673, step = 19001 (1.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.021\n",
      "INFO:tensorflow:loss = 0.0387399, step = 19101 (0.837 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.513\n",
      "INFO:tensorflow:loss = 0.0848894, step = 19201 (0.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.897\n",
      "INFO:tensorflow:loss = 0.208881, step = 19301 (0.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.438\n",
      "INFO:tensorflow:loss = 0.269582, step = 19401 (0.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.984\n",
      "INFO:tensorflow:loss = 0.091468, step = 19501 (0.909 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.87\n",
      "INFO:tensorflow:loss = 0.169872, step = 19601 (0.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.357\n",
      "INFO:tensorflow:loss = 0.0900493, step = 19701 (0.763 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.07\n",
      "INFO:tensorflow:loss = 0.106842, step = 19801 (0.848 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.03\n",
      "INFO:tensorflow:loss = 0.230826, step = 19901 (0.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.965\n",
      "INFO:tensorflow:loss = 0.239185, step = 20001 (0.937 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.518\n",
      "INFO:tensorflow:loss = 0.314055, step = 20101 (0.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.514\n",
      "INFO:tensorflow:loss = 0.0366227, step = 20201 (0.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.552\n",
      "INFO:tensorflow:loss = 0.111026, step = 20301 (0.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.344\n",
      "INFO:tensorflow:loss = 0.102089, step = 20401 (0.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.963\n",
      "INFO:tensorflow:loss = 0.167526, step = 20501 (0.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.12\n",
      "INFO:tensorflow:loss = 0.241304, step = 20601 (0.892 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.977\n",
      "INFO:tensorflow:loss = 0.22954, step = 20701 (0.909 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.764\n",
      "INFO:tensorflow:loss = 0.395607, step = 20801 (0.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.559\n",
      "INFO:tensorflow:loss = 0.151852, step = 20901 (0.948 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.736\n",
      "INFO:tensorflow:loss = 0.0649489, step = 21001 (0.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.16\n",
      "INFO:tensorflow:loss = 0.0855157, step = 21101 (0.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.188\n",
      "INFO:tensorflow:loss = 0.135633, step = 21201 (0.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.899\n",
      "INFO:tensorflow:loss = 0.215553, step = 21301 (0.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.112\n",
      "INFO:tensorflow:loss = 0.231147, step = 21401 (0.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.349\n",
      "INFO:tensorflow:loss = 0.282888, step = 21501 (0.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.198\n",
      "INFO:tensorflow:loss = 0.174135, step = 21601 (0.632 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 163.089\n",
      "INFO:tensorflow:loss = 0.0829086, step = 21701 (0.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.624\n",
      "INFO:tensorflow:loss = 0.177346, step = 21801 (0.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.536\n",
      "INFO:tensorflow:loss = 0.109624, step = 21901 (0.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.198\n",
      "INFO:tensorflow:loss = 0.240466, step = 22001 (0.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.9\n",
      "INFO:tensorflow:loss = 0.276326, step = 22101 (0.627 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.661\n",
      "INFO:tensorflow:loss = 0.183123, step = 22201 (0.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.271\n",
      "INFO:tensorflow:loss = 0.037297, step = 22301 (0.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.234\n",
      "INFO:tensorflow:loss = 0.152579, step = 22401 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.657\n",
      "INFO:tensorflow:loss = 0.174461, step = 22501 (0.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.643\n",
      "INFO:tensorflow:loss = 0.150141, step = 22601 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.073\n",
      "INFO:tensorflow:loss = 0.239023, step = 22701 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.069\n",
      "INFO:tensorflow:loss = 0.216895, step = 22801 (0.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.025\n",
      "INFO:tensorflow:loss = 0.216037, step = 22901 (0.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.546\n",
      "INFO:tensorflow:loss = 0.351294, step = 23001 (0.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.057\n",
      "INFO:tensorflow:loss = 0.363943, step = 23101 (0.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.285\n",
      "INFO:tensorflow:loss = 0.086262, step = 23201 (0.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.207\n",
      "INFO:tensorflow:loss = 0.113895, step = 23301 (0.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.964\n",
      "INFO:tensorflow:loss = 0.173106, step = 23401 (0.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.192\n",
      "INFO:tensorflow:loss = 0.0871918, step = 23501 (0.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.71\n",
      "INFO:tensorflow:loss = 0.107216, step = 23601 (0.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.589\n",
      "INFO:tensorflow:loss = 0.102687, step = 23701 (0.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.689\n",
      "INFO:tensorflow:loss = 0.371999, step = 23801 (0.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.215\n",
      "INFO:tensorflow:loss = 0.152674, step = 23901 (0.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.675\n",
      "INFO:tensorflow:loss = 0.0999521, step = 24001 (0.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.651\n",
      "INFO:tensorflow:loss = 0.0423911, step = 24101 (0.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.91\n",
      "INFO:tensorflow:loss = 0.033053, step = 24201 (0.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.016\n",
      "INFO:tensorflow:loss = 0.101116, step = 24301 (0.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.235\n",
      "INFO:tensorflow:loss = 0.241435, step = 24401 (0.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.819\n",
      "INFO:tensorflow:loss = 0.23099, step = 24501 (0.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.024\n",
      "INFO:tensorflow:loss = 0.208673, step = 24601 (0.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.808\n",
      "INFO:tensorflow:loss = 0.393153, step = 24701 (0.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.706\n",
      "INFO:tensorflow:loss = 0.33478, step = 24801 (0.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.184\n",
      "INFO:tensorflow:loss = 0.0927116, step = 24901 (0.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.285\n",
      "INFO:tensorflow:loss = 0.313766, step = 25001 (0.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.198\n",
      "INFO:tensorflow:loss = 0.102181, step = 25101 (0.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.59\n",
      "INFO:tensorflow:loss = 0.0908987, step = 25201 (0.645 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.512\n",
      "INFO:tensorflow:loss = 0.228947, step = 25301 (0.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.784\n",
      "INFO:tensorflow:loss = 0.0916774, step = 25401 (0.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.875\n",
      "INFO:tensorflow:loss = 0.0244002, step = 25501 (0.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.221\n",
      "INFO:tensorflow:loss = 0.159047, step = 25601 (0.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.275\n",
      "INFO:tensorflow:loss = 0.0336633, step = 25701 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.11\n",
      "INFO:tensorflow:loss = 0.162111, step = 25801 (0.653 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.043\n",
      "INFO:tensorflow:loss = 0.0386384, step = 25901 (0.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.718\n",
      "INFO:tensorflow:loss = 0.349747, step = 26001 (0.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.7\n",
      "INFO:tensorflow:loss = 0.2909, step = 26101 (0.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.137\n",
      "INFO:tensorflow:loss = 0.152173, step = 26201 (0.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.016\n",
      "INFO:tensorflow:loss = 0.171167, step = 26301 (0.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.121\n",
      "INFO:tensorflow:loss = 0.0925698, step = 26401 (0.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.022\n",
      "INFO:tensorflow:loss = 0.145245, step = 26501 (0.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.442\n",
      "INFO:tensorflow:loss = 0.0302758, step = 26601 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.027\n",
      "INFO:tensorflow:loss = 0.0393741, step = 26701 (0.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.243\n",
      "INFO:tensorflow:loss = 0.110882, step = 26801 (0.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.021\n",
      "INFO:tensorflow:loss = 0.158496, step = 26901 (0.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.521\n",
      "INFO:tensorflow:loss = 0.10346, step = 27001 (0.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.738\n",
      "INFO:tensorflow:loss = 0.165354, step = 27101 (0.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.243\n",
      "INFO:tensorflow:loss = 0.445304, step = 27201 (0.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.682\n",
      "INFO:tensorflow:loss = 0.263375, step = 27301 (0.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.941\n",
      "INFO:tensorflow:loss = 0.157557, step = 27401 (0.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.416\n",
      "INFO:tensorflow:loss = 0.171212, step = 27501 (0.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.189\n",
      "INFO:tensorflow:loss = 0.217919, step = 27601 (0.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.317\n",
      "INFO:tensorflow:loss = 0.0915898, step = 27701 (0.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.09\n",
      "INFO:tensorflow:loss = 0.119041, step = 27801 (0.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.448\n",
      "INFO:tensorflow:loss = 0.0993836, step = 27901 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.06\n",
      "INFO:tensorflow:loss = 0.116354, step = 28001 (0.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.106\n",
      "INFO:tensorflow:loss = 0.0332336, step = 28101 (0.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.192\n",
      "INFO:tensorflow:loss = 0.106357, step = 28201 (0.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.211\n",
      "INFO:tensorflow:loss = 0.176636, step = 28301 (0.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.2\n",
      "INFO:tensorflow:loss = 0.1661, step = 28401 (0.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.708\n",
      "INFO:tensorflow:loss = 0.03684, step = 28501 (0.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.791\n",
      "INFO:tensorflow:loss = 0.0343845, step = 28601 (0.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.273\n",
      "INFO:tensorflow:loss = 0.257992, step = 28701 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.908\n",
      "INFO:tensorflow:loss = 0.145073, step = 28801 (0.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.08\n",
      "INFO:tensorflow:loss = 0.0969519, step = 28901 (0.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.114\n",
      "INFO:tensorflow:loss = 0.0363182, step = 29001 (0.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.254\n",
      "INFO:tensorflow:loss = 0.174017, step = 29101 (0.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.207\n",
      "INFO:tensorflow:loss = 0.158455, step = 29201 (0.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.03\n",
      "INFO:tensorflow:loss = 0.208563, step = 29301 (0.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.691\n",
      "INFO:tensorflow:loss = 0.0363986, step = 29401 (0.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.254\n",
      "INFO:tensorflow:loss = 0.111079, step = 29501 (0.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.846\n",
      "INFO:tensorflow:loss = 0.103502, step = 29601 (0.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.127\n",
      "INFO:tensorflow:loss = 0.247407, step = 29701 (0.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.342\n",
      "INFO:tensorflow:loss = 0.110249, step = 29801 (0.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.051\n",
      "INFO:tensorflow:loss = 0.210144, step = 29901 (0.624 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 165.423\n",
      "INFO:tensorflow:loss = 0.318418, step = 30001 (0.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.107\n",
      "INFO:tensorflow:loss = 0.0324479, step = 30101 (0.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.614\n",
      "INFO:tensorflow:loss = 0.239989, step = 30201 (0.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.421\n",
      "INFO:tensorflow:loss = 0.141202, step = 30301 (0.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.072\n",
      "INFO:tensorflow:loss = 0.112755, step = 30401 (0.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.262\n",
      "INFO:tensorflow:loss = 0.0803654, step = 30501 (0.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.256\n",
      "INFO:tensorflow:loss = 0.046491, step = 30601 (0.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.31\n",
      "INFO:tensorflow:loss = 0.104191, step = 30701 (0.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.943\n",
      "INFO:tensorflow:loss = 0.0319457, step = 30801 (0.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.016\n",
      "INFO:tensorflow:loss = 0.116544, step = 30901 (0.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.627\n",
      "INFO:tensorflow:loss = 0.037027, step = 31001 (0.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.963\n",
      "INFO:tensorflow:loss = 0.094428, step = 31101 (0.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.106\n",
      "INFO:tensorflow:loss = 0.0358669, step = 31201 (0.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.981\n",
      "INFO:tensorflow:loss = 0.133468, step = 31301 (0.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.56\n",
      "INFO:tensorflow:loss = 0.155349, step = 31401 (0.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.204\n",
      "INFO:tensorflow:loss = 0.149259, step = 31501 (0.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.049\n",
      "INFO:tensorflow:loss = 0.0813734, step = 31601 (0.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.289\n",
      "INFO:tensorflow:loss = 0.197189, step = 31701 (0.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.934\n",
      "INFO:tensorflow:loss = 0.032832, step = 31801 (0.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.27\n",
      "INFO:tensorflow:loss = 0.0798559, step = 31901 (0.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.144\n",
      "INFO:tensorflow:loss = 0.217966, step = 32001 (0.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.243\n",
      "INFO:tensorflow:loss = 0.0935574, step = 32101 (0.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.302\n",
      "INFO:tensorflow:loss = 0.235163, step = 32201 (0.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.405\n",
      "INFO:tensorflow:loss = 0.0920474, step = 32301 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.685\n",
      "INFO:tensorflow:loss = 0.0937014, step = 32401 (0.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.249\n",
      "INFO:tensorflow:loss = 0.0925373, step = 32501 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.111\n",
      "INFO:tensorflow:loss = 0.106683, step = 32601 (0.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.562\n",
      "INFO:tensorflow:loss = 0.112703, step = 32701 (0.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.207\n",
      "INFO:tensorflow:loss = 0.0887252, step = 32801 (0.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.112\n",
      "INFO:tensorflow:loss = 0.168481, step = 32901 (0.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.364\n",
      "INFO:tensorflow:loss = 0.241519, step = 33001 (0.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.357\n",
      "INFO:tensorflow:loss = 0.148589, step = 33101 (0.618 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.214\n",
      "INFO:tensorflow:loss = 0.106012, step = 33201 (0.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.331\n",
      "INFO:tensorflow:loss = 0.110508, step = 33301 (0.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.042\n",
      "INFO:tensorflow:loss = 0.0886728, step = 33401 (0.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.094\n",
      "INFO:tensorflow:loss = 0.157159, step = 33501 (0.639 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.183\n",
      "INFO:tensorflow:loss = 0.300522, step = 33601 (0.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.157\n",
      "INFO:tensorflow:loss = 0.425211, step = 33701 (0.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.829\n",
      "INFO:tensorflow:loss = 0.168226, step = 33801 (0.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.611\n",
      "INFO:tensorflow:loss = 0.312778, step = 33901 (0.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.165\n",
      "INFO:tensorflow:loss = 0.0304018, step = 34001 (0.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.397\n",
      "INFO:tensorflow:loss = 0.151674, step = 34101 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.424\n",
      "INFO:tensorflow:loss = 0.14594, step = 34201 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.086\n",
      "INFO:tensorflow:loss = 0.10464, step = 34301 (0.624 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.338\n",
      "INFO:tensorflow:loss = 0.213369, step = 34401 (0.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.103\n",
      "INFO:tensorflow:loss = 0.112579, step = 34501 (0.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.356\n",
      "INFO:tensorflow:loss = 0.0418043, step = 34601 (0.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.301\n",
      "INFO:tensorflow:loss = 0.0293131, step = 34701 (0.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.17\n",
      "INFO:tensorflow:loss = 0.109521, step = 34801 (0.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.556\n",
      "INFO:tensorflow:loss = 0.045338, step = 34901 (0.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.741\n",
      "INFO:tensorflow:loss = 0.173481, step = 35001 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.176\n",
      "INFO:tensorflow:loss = 0.105205, step = 35101 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.319\n",
      "INFO:tensorflow:loss = 0.119496, step = 35201 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.166\n",
      "INFO:tensorflow:loss = 0.11247, step = 35301 (0.628 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.226\n",
      "INFO:tensorflow:loss = 0.102185, step = 35401 (0.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.431\n",
      "INFO:tensorflow:loss = 0.160812, step = 35501 (0.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.163\n",
      "INFO:tensorflow:loss = 0.171989, step = 35601 (0.622 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.944\n",
      "INFO:tensorflow:loss = 0.209425, step = 35701 (0.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.105\n",
      "INFO:tensorflow:loss = 0.173291, step = 35801 (0.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.375\n",
      "INFO:tensorflow:loss = 0.218093, step = 35901 (0.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.005\n",
      "INFO:tensorflow:loss = 0.165073, step = 36001 (0.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.452\n",
      "INFO:tensorflow:loss = 0.0988449, step = 36101 (0.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.634\n",
      "INFO:tensorflow:loss = 0.263811, step = 36201 (0.740 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.025\n",
      "INFO:tensorflow:loss = 0.0367139, step = 36301 (0.814 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.309\n",
      "INFO:tensorflow:loss = 0.145147, step = 36401 (0.813 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.775\n",
      "INFO:tensorflow:loss = 0.202714, step = 36501 (0.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.627\n",
      "INFO:tensorflow:loss = 0.214293, step = 36601 (0.805 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.498\n",
      "INFO:tensorflow:loss = 0.101819, step = 36701 (0.656 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.992\n",
      "INFO:tensorflow:loss = 0.0339346, step = 36801 (0.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.969\n",
      "INFO:tensorflow:loss = 0.0864331, step = 36901 (0.648 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.454\n",
      "INFO:tensorflow:loss = 0.172822, step = 37001 (0.597 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.982\n",
      "INFO:tensorflow:loss = 0.091185, step = 37101 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.31\n",
      "INFO:tensorflow:loss = 0.102769, step = 37201 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.825\n",
      "INFO:tensorflow:loss = 0.198985, step = 37301 (0.591 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.163\n",
      "INFO:tensorflow:loss = 0.32836, step = 37401 (0.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.693\n",
      "INFO:tensorflow:loss = 0.17117, step = 37501 (0.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.751\n",
      "INFO:tensorflow:loss = 0.108658, step = 37601 (0.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.27\n",
      "INFO:tensorflow:loss = 0.137317, step = 37701 (0.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.28\n",
      "INFO:tensorflow:loss = 0.187472, step = 37801 (0.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.291\n",
      "INFO:tensorflow:loss = 0.316885, step = 37901 (0.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.354\n",
      "INFO:tensorflow:loss = 0.0256654, step = 38001 (0.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.34\n",
      "INFO:tensorflow:loss = 0.158792, step = 38101 (0.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.049\n",
      "INFO:tensorflow:loss = 0.181989, step = 38201 (0.645 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 167.484\n",
      "INFO:tensorflow:loss = 0.0398326, step = 38301 (0.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.591\n",
      "INFO:tensorflow:loss = 0.188759, step = 38401 (0.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.191\n",
      "INFO:tensorflow:loss = 0.16436, step = 38501 (0.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.546\n",
      "INFO:tensorflow:loss = 0.153995, step = 38601 (0.596 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.516\n",
      "INFO:tensorflow:loss = 0.268361, step = 38701 (0.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.513\n",
      "INFO:tensorflow:loss = 0.172215, step = 38801 (0.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.373\n",
      "INFO:tensorflow:loss = 0.299414, step = 38901 (0.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.162\n",
      "INFO:tensorflow:loss = 0.108119, step = 39001 (0.632 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.579\n",
      "INFO:tensorflow:loss = 0.249037, step = 39101 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.897\n",
      "INFO:tensorflow:loss = 0.30176, step = 39201 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.041\n",
      "INFO:tensorflow:loss = 0.153007, step = 39301 (0.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.086\n",
      "INFO:tensorflow:loss = 0.100607, step = 39401 (0.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 162.193\n",
      "INFO:tensorflow:loss = 0.119331, step = 39501 (0.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.654\n",
      "INFO:tensorflow:loss = 0.0332507, step = 39601 (0.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.606\n",
      "INFO:tensorflow:loss = 0.360831, step = 39701 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.318\n",
      "INFO:tensorflow:loss = 0.0825158, step = 39801 (0.714 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.089\n",
      "INFO:tensorflow:loss = 0.106358, step = 39901 (0.913 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into C:\\Users\\hasee\\AppData\\Local\\Temp\\tmpa2dqf_5m\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.103641.\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:487: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hasee\\AppData\\Local\\Temp\\tmpa2dqf_5m\\model.ckpt-40000\n",
      "WARNING:tensorflow:From D:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:487: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\hasee\\AppData\\Local\\Temp\\tmpa2dqf_5m\\model.ckpt-40000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "test_dat = pd.read_csv(base_path + 'test.csv')\n",
    "train_dat = pd.read_csv(base_path + 'train.csv')\n",
    "submission = pd.read_csv(base_path + 'sample_submission.csv')\n",
    "\n",
    "train_y = train_dat['target']\n",
    "train_x = train_dat.drop(['target', 'id'], axis = 1)\n",
    "test_dat = test_dat.drop(['id'], axis = 1)\n",
    "\n",
    "merged_dat = pd.concat([train_x, test_dat],axis=0)\n",
    "\n",
    "#change data to float32\n",
    "for c, dtype in zip(merged_dat.columns, merged_dat.dtypes): \n",
    "    if dtype == np.float64:     \n",
    "        merged_dat[c] = merged_dat[c].astype(np.float32)\n",
    "\n",
    "#one hot encode the categoricals\n",
    "cat_features = [col for col in merged_dat.columns if col.endswith('cat')]\n",
    "for column in cat_features:\n",
    "    temp=pd.get_dummies(pd.Series(merged_dat[column]))\n",
    "    merged_dat=pd.concat([merged_dat,temp],axis=1)\n",
    "    merged_dat=merged_dat.drop([column],axis=1)\n",
    "\n",
    "#standardize the scale of the numericals\n",
    "numeric_features = [col for col in merged_dat.columns if '_calc_' in  str(col)]\n",
    "numeric_features = [col for col in numeric_features if '_bin' not in str(col)]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_numerics = scaler.fit_transform(merged_dat[numeric_features])\n",
    "scaled_num_df = pd.DataFrame(scaled_numerics, columns =numeric_features )\n",
    "\n",
    "\n",
    "merged_dat = merged_dat.drop(numeric_features, axis=1)\n",
    "\n",
    "merged_dat = np.concatenate((merged_dat.values,scaled_num_df), axis = 1)\n",
    "\n",
    "train_x = merged_dat[:train_x.shape[0]]\n",
    "test_dat = merged_dat[train_x.shape[0]:]\n",
    "\n",
    "\n",
    "config = tf.contrib.learn.RunConfig(tf_random_seed=42)\n",
    "\n",
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(train_x)\n",
    "\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[150,150,150], n_classes=2,\n",
    "                                         feature_columns=feature_cols, config=config)\n",
    "\n",
    "dnn_clf.fit(train_x, train_y, batch_size=50, steps=40000)\n",
    "\n",
    "dnn_y_pred = dnn_clf.predict_proba(test_dat)\n",
    "dnn_y_pred_train = dnn_clf.predict_proba(train_x)\n",
    "\n",
    "\n",
    "dnn_out = list(dnn_y_pred)\n",
    "\n",
    "dnn_output = submission\n",
    "dnn_output['target'] = [x[1] for x in dnn_out]\n",
    "\n",
    "\n",
    "dnn_output.to_csv(base_path + 'test_dnn_predictions.csv', index=False, float_format='%.4f')\n",
    "\n",
    "train = pd.read_csv(base_path + 'train.csv')\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = train['id']\n",
    "sub['target'] = [x[1] for x in list(dnn_y_pred_train)]\n",
    "sub.to_csv(base_path + 'train_dnn_predictions.csv', index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. kinetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# \n",
    "train=pd.read_csv(base_path + 'train_p.csv')\n",
    "test=pd.read_csv(base_path + 'test_p.csv')\n",
    "#more about kinetic features  developed  by Daia Alexandru    here  on the next  blog  please  read  last article :\n",
    "#https://alexandrudaia.quora.com/\n",
    "\n",
    "##############################################creatinng   kinetic features for  train #####################################################\n",
    "def  kinetic(row):\n",
    "    probs=np.unique(row,return_counts=True)[1]/len(row)\n",
    "    kinetic=np.sum(probs**2)\n",
    "    return kinetic\n",
    "    \n",
    "\n",
    "first_kin_names=[col for  col in train.columns  if '_ind_' in col]\n",
    "subset_ind=train[first_kin_names]\n",
    "kinetic_1=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_1.append(k)\n",
    "second_kin_names= [col for  col in train.columns  if '_car_' in col and col.endswith('cat')]\n",
    "subset_ind=train[second_kin_names]\n",
    "kinetic_2=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_2.append(k)\n",
    "third_kin_names= [col for  col in train.columns  if '_calc_' in col and  not col.endswith('bin')]\n",
    "subset_ind=train[second_kin_names]\n",
    "kinetic_3=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_3.append(k)\n",
    "fd_kin_names= [col for  col in train.columns  if '_calc_' in col and  col.endswith('bin')]\n",
    "subset_ind=train[fd_kin_names]\n",
    "kinetic_4=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_4.append(k)\n",
    "train['kinetic_1']=np.array(kinetic_1)\n",
    "train['kinetic_2']=np.array(kinetic_2)\n",
    "train['kinetic_3']=np.array(kinetic_3)\n",
    "train['kinetic_4']=np.array(kinetic_4)\n",
    "\n",
    "############################################reatinng   kinetic features for  test###############################################################\n",
    "\n",
    "first_kin_names=[col for  col in test.columns  if '_ind_' in col]\n",
    "subset_ind=test[first_kin_names]\n",
    "kinetic_1=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_1.append(k)\n",
    "second_kin_names= [col for  col in test.columns  if '_car_' in col and col.endswith('cat')]\n",
    "subset_ind=test[second_kin_names]\n",
    "kinetic_2=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_2.append(k)\n",
    "third_kin_names= [col for  col in test.columns  if '_calc_' in col and  not col.endswith('bin')]\n",
    "subset_ind=test[second_kin_names]\n",
    "kinetic_3=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_3.append(k)\n",
    "fd_kin_names= [col for  col in test.columns  if '_calc_' in col and  col.endswith('bin')]\n",
    "subset_ind=test[fd_kin_names]\n",
    "kinetic_4=[]\n",
    "for row in range(subset_ind.shape[0]):\n",
    "    row=subset_ind.iloc[row]\n",
    "    k=kinetic(row)\n",
    "    kinetic_4.append(k)\n",
    "test['kinetic_1']=np.array(kinetic_1)\n",
    "test['kinetic_2']=np.array(kinetic_2)\n",
    "test['kinetic_3']=np.array(kinetic_3)\n",
    "test['kinetic_4']=np.array(kinetic_4)\n",
    "\n",
    "##################################################################end  of kinetics ############################################################################\n",
    "from sklearn import *\n",
    "import xgboost as xgb\n",
    "from multiprocessing import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from multiprocessing import *\n",
    "\n",
    "\n",
    "d_median = train.median(axis=0)\n",
    "d_mean = train.mean(axis=0)\n",
    "\n",
    "def transform_df(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    dcol = [c for c in df.columns if c not in ['id','target']]\n",
    "    df['ps_car_13_x_ps_reg_03'] = df['ps_car_13'] * df['ps_reg_03']\n",
    "    df['negative_one_vals'] = np.sum((df[dcol]==-1).values, axis=1)\n",
    "    for c in dcol:\n",
    "        if '_bin' not in c:\n",
    "            df[c+str('_median_range')] = (df[c].values > d_median[c]).astype(int)\n",
    "            df[c+str('_mean_range')] = (df[c].values > d_mean[c]).astype(int)\n",
    "    return df\n",
    "\n",
    "def multi_transform(df):\n",
    "    print('Init Shape: ', df.shape)\n",
    "    p = Pool(cpu_count())\n",
    "    df = p.map(transform_df, np.array_split(df, cpu_count()))\n",
    "    df = pd.concat(df, axis=0, ignore_index=True).reset_index(drop=True)\n",
    "    p.close(); p.join()\n",
    "    print('After Shape: ', df.shape)\n",
    "    return df\n",
    "\n",
    "def gini(y, pred):\n",
    "    g = np.asarray(np.c_[y, pred, np.arange(len(y)) ], dtype=np.float)\n",
    "    g = g[np.lexsort((g[:,2], -1*g[:,1]))]\n",
    "    gs = g[:,0].cumsum().sum() / g[:,0].sum()\n",
    "    gs -= (len(y) + 1) / 2.\n",
    "    return gs / len(y)\n",
    "\n",
    "def gini_xgb(pred, y):\n",
    "    #y = y.get_label()\n",
    "    return 'gini', gini(y, pred) / gini(y, y)\n",
    "\n",
    "params = {'eta': 0.02, 'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, 'objective': 'binary:logistic', 'eval_metric': 'auc', 'seed': 99, 'silent': True}\n",
    "x1, x2, y1, y2 = model_selection.train_test_split(train, train['target'], test_size=0.25, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.593995\tvalid-auc:0.589611\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 100 rounds.\n",
      "[50]\ttrain-auc:0.619989\tvalid-auc:0.617429\n",
      "[100]\ttrain-auc:0.625555\tvalid-auc:0.620998\n",
      "[150]\ttrain-auc:0.632562\tvalid-auc:0.624696\n",
      "[200]\ttrain-auc:0.639415\tvalid-auc:0.627961\n",
      "[250]\ttrain-auc:0.644596\tvalid-auc:0.630245\n",
      "[300]\ttrain-auc:0.649602\tvalid-auc:0.63258\n",
      "[350]\ttrain-auc:0.653737\tvalid-auc:0.634368\n",
      "[400]\ttrain-auc:0.657281\tvalid-auc:0.635386\n",
      "[450]\ttrain-auc:0.660653\tvalid-auc:0.636158\n",
      "[500]\ttrain-auc:0.663696\tvalid-auc:0.636715\n",
      "[550]\ttrain-auc:0.666269\tvalid-auc:0.637238\n",
      "[600]\ttrain-auc:0.668999\tvalid-auc:0.637537\n",
      "[650]\ttrain-auc:0.671485\tvalid-auc:0.637926\n",
      "[700]\ttrain-auc:0.673762\tvalid-auc:0.638012\n",
      "[750]\ttrain-auc:0.675872\tvalid-auc:0.638125\n",
      "[800]\ttrain-auc:0.677918\tvalid-auc:0.638414\n",
      "[850]\ttrain-auc:0.680071\tvalid-auc:0.638516\n",
      "[900]\ttrain-auc:0.682166\tvalid-auc:0.638499\n",
      "[950]\ttrain-auc:0.683935\tvalid-auc:0.638554\n",
      "[1000]\ttrain-auc:0.686109\tvalid-auc:0.638559\n",
      "[1050]\ttrain-auc:0.688061\tvalid-auc:0.638519\n",
      "[1100]\ttrain-auc:0.690022\tvalid-auc:0.638454\n",
      "Stopping. Best iteration:\n",
      "[1023]\ttrain-auc:0.686993\tvalid-auc:0.638599\n",
      "\n",
      "('gini', 0.27719771439209684)\n"
     ]
    }
   ],
   "source": [
    "#keep dist\n",
    "x1 = transform_df(x1)\n",
    "y1 = x1['target']\n",
    "x2 = transform_df(x2)\n",
    "y2 = x2['target']\n",
    "test = transform_df(test)\n",
    "\n",
    "col = [c for c in x1.columns if c not in ['id','target']]\n",
    "x1 = x1[col]\n",
    "x2 = x2[col]\n",
    "\n",
    "watchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\n",
    "model = xgb.train(params, xgb.DMatrix(x1, y1), 5000,  watchlist, verbose_eval=50, early_stopping_rounds=100)\n",
    "print(gini_xgb(model.predict(xgb.DMatrix(x2), ntree_limit=model.best_ntree_limit), y2))\n",
    "test['target'] = model.predict(xgb.DMatrix(test[col]), ntree_limit=model.best_ntree_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[['id','target']].to_csv(base_path + 'test_uberKinetics.csv', index=False, float_format='%.5f')\n",
    "train = transform_df(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['target'] = model.predict(xgb.DMatrix(train[col]), ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "train[['id','target']].to_csv(base_path + 'train_uberKinetics.csv', index=False, float_format='%.5f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 5. Stacking_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_path = \"C:\\\\Users\\\\hasee\\\\workspace\\\\Kaggle\\\\safe_driver\\\\\" # your folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# test files\n",
    "\n",
    "test_xgb = pd.read_csv(base_path + 'test_sub_xgb.csv')\n",
    "test_lgb = pd.read_csv(base_path + 'test_sub_lgb.csv')\n",
    "test_lgbrcv=pd.read_csv(base_path + 'test_sub_lgb_rand.csv')\n",
    "test_dnn = pd.read_csv(base_path + 'test_dnn_predictions.csv')\n",
    "test_up = pd.read_csv(base_path + 'test_submission.csv')\n",
    "test_cat = pd.read_csv(base_path + 'test_catboost_submission.csv')\n",
    "test_kin = pd.read_csv(base_path + 'test_uberKinetics.csv')\n",
    "test_gp = pd.read_csv(base_path + 'test_gpari.csv')\n",
    "\n",
    "test=pd.read_csv(base_path + 'test.csv')\n",
    "\n",
    "\n",
    "test = pd.concat([test, \n",
    "                   test_xgb[['target']].rename(columns = {'target' : 'xgb'}),\n",
    "                   test_lgb[['target']].rename(columns = {'target' : 'lgb'}),\n",
    "                   test_lgbrcv[['target']].rename(columns = {'target ' : 'lgbrcv'}),\n",
    "                   test_dnn[['target']].rename(columns = {'target' : 'dnn'}),\n",
    "                   test_up[['target']].rename(columns = {'target' : 'up'}),\n",
    "                   test_cat[['target']].rename(columns = {'target' : 'cat'}),\n",
    "                   test_kin[['target']].rename(columns = {'target' : 'kin'}),\n",
    "                   test_gp[['target']].rename(columns = {'target' : 'gp'})                   \n",
    "                  ], axis = 1)\n",
    "\n",
    "\n",
    "train_cols = ['xgb', 'lgb', 'lgbrcv','dnn', 'up', 'cat', 'kin', 'gp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lgbrcv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2392\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2393\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2394\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5239)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5085)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20405)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20359)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'lgbrcv'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-04f04231817b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### preprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_cols\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_rank'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;31m#.rank() #after rank the minimum item value is 1 and tne maximum is the number of elements\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2060\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2062\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2063\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2064\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2067\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2068\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2069\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2071\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1532\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1533\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1534\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1535\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3590\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3591\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2393\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2394\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2395\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2397\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5239)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5085)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20405)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas\\_libs\\hashtable.c:20359)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'lgbrcv'"
     ]
    }
   ],
   "source": [
    "### preprocess\n",
    "for t in train_cols:\n",
    "    test[t + '_rank'] = test[t]#.rank() #after rank the minimum item value is 1 and tne maximum is the number of elements\n",
    "\n",
    "\n",
    "test['target'] = (test['xgb_rank'] + test['lgb_rank'] +test['lgbrcv_rank']+ test['dnn_rank'] + test['up_rank'] + \\\n",
    "                 test['cat_rank'] + test['kin_rank'] + test['gp_rank']) / 8#(7 * test.shape[0])\n",
    "#final output\n",
    "test[['id', 'target']].to_csv(base_path + 'rank_avg.csv.gz', index = False, compression = 'gzip') \n",
    "                                                                           \n",
    "                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    8.0\n",
      "1    5.0\n",
      "2    7.0\n",
      "3    4.0\n",
      "4    2.0\n",
      "5    1.0\n",
      "6    3.0\n",
      "7    6.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "obj = pd.Series([8.275,6.486,7.643,4.537,2.178,0,4.3,6.9])\n",
    "print (obj.rank())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8.3\n",
       "1    6.5\n",
       "2    7.6\n",
       "3    4.5\n",
       "4    2.2\n",
       "5    0.0\n",
       "6    4.3\n",
       "7    6.9\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
